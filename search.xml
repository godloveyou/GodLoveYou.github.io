<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux下nohup文件过大问题解决方案]]></title>
    <url>%2F2019%2F11%2F11%2FLinux%E4%B8%8Bnohup%E6%96%87%E4%BB%B6%E8%BF%87%E5%A4%A7%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[文件过大可能对系统造成的影响 文件打开非常慢 系统线程被阻塞 无法正常运行（采集系统曾经碰到过） 解决方法1 直接指定到黑洞目录,在本地也不会保留,项目中一般都配置的有日志文件,所以这个文件其实是冗余的123#!/bin/bash#nohup java -Dfile.encoding=utf-8 -jar $JAVA_OPTS admin.jar &gt; admin.log &amp;nohup java -Dfile.encoding=utf-8 -jar $JAVA_OPTS admin.jar &gt; /dev/null &amp; 解决方法2 切割日志文件1234567891011#!/bin/sh#################启动日志切割服务#################this_path=$(cd `dirname $0`;pwd)cd $this_pathecho $this_pathcurrent_date=`date -d "-1 day" "+%Y%m%d"`echo $current_datesplit -b 65535000 -d -a 4 /home/.../nohup.out /home/.../log/log_$&#123;current_date&#125;_ cat /dev/null &gt; nohup.out split命令 split -b 65535000 -d -a 4 nohup.out ./log/log_${current_date}_ 这里使用split命令,将nouhup文件按指定大小切分(65535000b 大概60多M吧，可以自定义大小 )，并分成指定格式（-d -a 4以4位数字形式为后缀以从0000开始,具体可以百度split命令用法）,最终输出格式为log_20160610_0001]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nohup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序生成分享码]]></title>
    <url>%2F2019%2F11%2F01%2F%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E7%94%9F%E6%88%90%E5%88%86%E4%BA%AB%E7%A0%81%E5%8F%8A%E8%B7%B3%E8%BD%AC%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[1.小程序码介绍小程序开发文档:https://developers.weixin.qq.com/miniprogram/dev/api-backend/open-api/qr-code/wxacode.getUnlimited.html 微信小程序 允许开发者生成跳转到某个页面的小程序码, 在用户扫码后跳转到指定页面时，也可以附加参数,附加的参数在小程序端可以获取到 从微信小程序开发文档上我们可以了解到，目前微信支持两种二维码（左），小程序码和小程序二维码（右）。官方推荐使用小程序码，因为小程序码具有更好的辨识度。 官方提供生成小程序码的两种方式 方式一： 适用于 需要的码的数量相对较少的业务场景,通过该接口生成的小程序码，有数量限制,永久有效，(这种方式不能附带额外的自定义参数) 接口地址: https://api.weixin.qq.com/wxa/getwxacode?access_token=ACCESS_TOKEN 具体参数参考微信官方文档:[https://developers.weixin.qq.com/miniprogram/dev/api-backend/open-api/qr-code/wxacode.get.html] 方式二: 适用于使用数量极多的场景（可以附带额外的自定义参数）。 接口地址：https://api.weixin.qq.com/wxa/getwxacodeunlimit?access_token=ACCESS_TOKEN 具体参数参考微信官方文档：https://developers.weixin.qq.com/miniprogram/dev/api-backend/open-api/qr-code/wxacode.getUnlimited.html 注意: 两种方式均需要获取 ACCESS_TOEKN，微信提供的开发者工具中也 可以在线获取，https://mp.weixin.qq.com/debug/ 2. 后台获取小程序码DEMO（演示第一种获取方式,生成的二维码扫码后直接跳转到指定页面）123456789101112131415161718192021222324252627public class HttpUtilTest &#123; public static void main(String[] args) &#123; String token = "27_b7dbAFkuHIrKjeiYA05TOYoMlgD723P_lfMZwfhofQA_FcpXXZ3thuLOUmyFy9OZH9nXMvgMjm683SzVJa0w2MshxZ2TGT90aY7H2IxEdwtdLQoY4srLv3vbMZgZOVgAIATIP"; //使用第一种 获取方式获取小程序码 String url = "https://api.weixin.qq.com/wxa/getwxacode?access_token="+token; Map&lt;String,Object&gt; data = new HashMap&lt;String,Object&gt;(); Map&lt;String,Object&gt; color = new HashMap&lt;&gt;(); data.put("path","pages/quickly/quickly"); data.put("auto_color",false); data.put("width",450); color.put("r",0); color.put("g",0); color.put("b",0); data.put("line_color",color); HttpRequest request = HttpUtil.createPost(url); request.body(JSONUtil.toJsonStr(data)); HttpResponse response = request.execute(); //请求接口返回的图片的字节码，直接写入本地文件就可以 byte[] imgBytes = response.bodyBytes(); try &#123; OutputStream outputStream = new FileOutputStream(new File("h:/jumpToQuick.jpg")); IoUtil.write(outputStream,true,imgBytes); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3.前端请求获取小程序码因为第二中方法可生成的小程序码极多，所以我们一般会使用这种方法来获取小程序码。 今天主要像大家介绍一下第二种方法。 一般我们主要常用的参数是：scene（如果需要页面参数）、page和width。 page是页面地址，例如：’pages/index’。pages前面不能有斜杠 scene是参数，为字符串。比如要传入一个用户id=1234，要根据这个用户id来给当前页面返回不同的内容，那么scene参数就可以写成”1234”，多个参数按一定规则分开，如&amp;符号，第二个参数是recommendId=123则可以这样写”1234&amp;123”。我们来开一下代码：1234567891011121314151617181920212223Page(&#123; data:&#123;&#125;, getQrcode()&#123; wx.request(&#123; url: "https://www....com/weixin/get-qrcode",//域名省略 data: &#123; page:"pages/index", scene:"1234&amp;123", width:300 &#125;, header: &#123; 'content-type': 'application/x-www-form-urlencoded' &#125;, method: 'POST', dataType: 'json', success: function(res)&#123; let qrcodeUrl=res.data;//服务器小程序码地址 &#125;, fail: function()&#123;&#125;, complete: options.complete || function()&#123;&#125; &#125;) &#125;&#125;) 解析：get-qrcode接口是自己小程序后端的接口，前端调用此接口，传入相应参数，后台通过参数请求小程序接口获取到小程序码存到自己服务上，返回小程序码服务器地址。 3.用户扫码进入后的逻辑我们可以在onload生命周期中处理参数 onLoad:function(options){ if(options.scene){ let scene=decodeURIComponent(options.scene); //&amp;是我们定义的参数链接方式 let userId=scene.split(“&amp;”)[0]; let recommendId=scene.split(‘&amp;’)[1]; //其他逻辑处理。。。。。 }}]]></content>
      <categories>
        <category>小程序</category>
      </categories>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[No space left on device问题解决]]></title>
    <url>%2F2019%2F10%2F25%2FNo%20space%20left%20on%20device%2F</url>
    <content type="text"><![CDATA[最近采集器可以正常采集数据,但是数据一直未入库,后来试着停止数据库后启动时,mysql报错No space left on device解决 使用 df -h 命令查看磁盘使用情况如下： 问题发生时/dev/vda1磁盘使用了100%被完全占满,这个是删除数据后截的图 接着，使用 du -sh * 命令 在根目录查看每个文件使用情况 最后发现是myql占用了100多G,逐层使用du -sh *最后发现是业务数据库其中一个表,数据占了将近100G 删除该表数据后 问题解决]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot整合ActiveMq入门]]></title>
    <url>%2F2019%2F10%2F21%2Fspringboot%E6%95%B4%E5%90%88ActiveMq%2F</url>
    <content type="text"><![CDATA[1.下载activeMq并启动(版本apache-activemq-5.15.4解压运行)启动成功后管理路径是http://127.0.0.1:8161用户名密码admin/admin 2.springboot项目中加入activeMq依赖12345678910&lt;!--引入ActiveMq依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 启用JMS 的池化, 就一定要加上这个 jar--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt;&lt;/dependency&gt; 3. application.yml配置activeMq服务器的配置12345678910# MQ所在的服务器的地址spring.activemq.broker-url: tcp://127.0.0.1:61616# 是否使用内置的MQ， true 使用； fale 不使用spring.activemq.in-memory: false # 是否在回滚回滚消息之前停止消息传递。这意味着当启用此命令时，消息顺序不会被保留。spring.activemq.non-blocking-redelivery: false# 用户名spring.activemq.password: admin# 密码spring.activemq.user: admin 具体的配置信息解析12345678910111213141516171819202122232425262728293031323334353637spring.activemq.broker-url=tcp://127.0.0.1:61616# 在考虑结束之前等待的时间#spring.activemq.close-timeout=15s # 默认代理URL是否应该在内存中。如果指定了显式代理，则忽略此值。spring.activemq.in-memory=true # 是否在回滚回滚消息之前停止消息传递。这意味着当启用此命令时，消息顺序不会被保留。spring.activemq.non-blocking-redelivery=false# 密码spring.activemq.password=admin# 等待消息发送响应的时间。设置为0等待永远。spring.activemq.user=admin# 是否信任所有包#spring.activemq.packages.trust-all=# 要信任的特定包的逗号分隔列表（当不信任所有包时）#spring.activemq.packages.trusted=# 当连接请求和池满时是否阻塞。设置false会抛“JMSException异常”。#spring.activemq.pool.block-if-full=true# 如果池仍然满，则在抛出异常前阻塞时间。#spring.activemq.pool.block-if-full-timeout=-1ms# 是否在启动时创建连接。可以在启动时用于加热池。#spring.activemq.pool.create-connection-on-startup=true# 是否用Pooledconnectionfactory代替普通的ConnectionFactory。#spring.activemq.pool.enabled=false # 连接过期超时。#spring.activemq.pool.expiry-timeout=0ms# 连接空闲超时#spring.activemq.pool.idle-timeout=30s# 连接池最大连接数#spring.activemq.pool.max-connections=1# 每个连接的有效会话的最大数目。#spring.activemq.pool.maximum-active-session-per-connection=500# 当有&quot;JMSException&quot;时尝试重新连接#spring.activemq.pool.reconnect-on-exception=true# 在空闲连接清除线程之间运行的时间。当为负数时，没有空闲连接驱逐线程运行。#spring.activemq.pool.time-between-expiration-check=-1ms# 是否只使用一个MessageProducer#spring.activemq.pool.use-anonymous-producers=true 4.创建ActiveMqConfig1234567891011121314151617181920212223242526272829303132333435@Configuration public class ActivemqConfig &#123; @Bean(name = "topic-myqueue") public Queue queue() &#123; return new ActiveMQQueue("yw-advice-worker"); &#125; @Bean(name = "topic-company") public Topic topicCompany() &#123; return new ActiveMQTopic("topic-company"); &#125; @Bean(name = "topic-worker") public Topic topicWorker() &#123; return new ActiveMQTopic("topic-company"); &#125; // topic模式的ListenerContainer @Bean public JmsListenerContainerFactory&lt;?&gt; jmsListenerContainerTopic(ConnectionFactory activeMQConnectionFactory) &#123; DefaultJmsListenerContainerFactory bean = new DefaultJmsListenerContainerFactory(); bean.setPubSubDomain(true); bean.setConnectionFactory(activeMQConnectionFactory); return bean; &#125;// queue模式的ListenerContainer @Bean public JmsListenerContainerFactory&lt;?&gt; jmsListenerContainerQueue( ConnectionFactory activeMQConnectionFactory) &#123; DefaultJmsListenerContainerFactory bean = new DefaultJmsListenerContainerFactory(); bean.setConnectionFactory(activeMQConnectionFactory); return bean; &#125;&#125; 5.编写生产者测试1234567891011121314151617181920212223@RunWith(SpringRunner.class)@SpringBootTest(classes = ApiApplication.class)public class ActiveMqProducterTest &#123; @Autowired private JmsMessagingTemplate jmsTemplate; @Resource(name = "topic-company") private Topic adviceCompany; @Resource(name = "queue-yw") private Queue queueAdvice; @Test public void testProducter()&#123; jmsTemplate.convertAndSend(adviceCompany, "您有新的外卖订单,已为您自动接单"); &#125; @Test public void testSendQueue()&#123; jmsTemplate.convertAndSend(queueAdvice,"你好,我来自队列"); &#125;&#125; 6.编写消费者测试1234567891011121314@Component public class ActiveMqConsumer &#123; private final static Logger logger = LoggerFactory.getLogger(ActiveMqConsumer.class); @JmsListener(destination = "topic-company",containerFactory = "jmsListenerContainerTopic") public void receiveTopic(String msg) &#123; logger.info("接收到topic消息：&#123;&#125;",msg); &#125; @JmsListener(destination = "queue-yw",containerFactory = "jmsListenerContainerQueue") public void receiveQueue(String msg) &#123; logger.info("接收到queue-yw消息：&#123;&#125;",msg); &#125;&#125; 参考资料 (https://blog.csdn.net/qq_43652509/article/details/83926758) (https://blog.csdn.net/cs_hnu_scw/article/details/81040834)]]></content>
      <categories>
        <category>ActiveMq</category>
      </categories>
      <tags>
        <tag>ActiveMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP三次握手四次挥手]]></title>
    <url>%2F2019%2F10%2F08%2FTCP%20IP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[一、TCP报文格式 TCP报文格式图： 上图中有几个字段需要重点介绍下： （1）序号：Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。 （2）确认序号：Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。 （3）标志位：共6个，即URG、ACK、PSH、RST、SYN、FIN等，具体含义如下： （A）URG：紧急指针（urgent pointer）有效。 （B）ACK：确认序号有效。 （C）PSH：接收方应该尽快将这个报文交给应用层。 （D）RST：重置连接。 （E）SYN：发起一个新连接。 （F）FIN：释放一个连接。 三次握手用wireshark抓包分析 第一次握手 SYN 第二次握手 SYN,ACK 第三次握手 TCP 三次握手 示意图 Wireshark 抓包注意事项为了演示一个TCP三次握手建立连接的过程，我们通过 Chrome 访问一个网页。已知 HTTP 协议就是建立在TCP链接上的 比如访问以下的网址：http://toutiao.newmedia139.net/ 通过 Cmd 的 ping 命令获取 这个网站对应的 IP地址 183.136.236.13 确定 这个IP 有一个非常重要的好处，就是我们只需要 电脑 -&gt; 网站 的数据包 网站-&gt;电脑 的数据包 所以，可以使用Wireshark的显示过滤规则，只显示我们需要的数据，不然你一定看着满屏幕的数据抓狂的。 过滤规则如下：ip.src==183.136.236.13 or ip.dst==183.136.236.13 截图： 分析TCP握手包概览 通过图片，可以看到 先 进行了 TCP 三次传输 然后才 开始 HTTP 传输 第一次 客户端发送 SYN 报文 到服务器 第二次 ，服务器接收到 客户端的SYN 报文，回复 SYN + ACK 报文 第三次 ，客户端接收到服务端的 SYN+ACK 报文后，回复 ACK报文 注意：这里有个坑：Wireshark 显示的 Syn Ack的数目是不准确的 理论上，Syn 应该初始值是个随机数的，后面的要根据初始值增加 TCP 三次握手总结建立一个稳定的 双向 连接，最少需要 几次 通信呢？以打电话为例小明 给小红 打电话小明 ： 喂，小红 听得到么？小红： 嗯，我听到你说话了，你能听到我么？小明：我能听到你。 只有这三个传输都正确了，才能保障双方是 连通的 TCP 四次挥手由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。 CP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)。客户端或服务器均可主动发起挥手动作，在socket编程中，任何一方执行close()操作即可产生挥手操作。 （1）客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送。 （2）服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。和SYN一样，一个FIN将占用一个序号。 （3）服务器B关闭与客户端A的连接，发送一个FIN给客户端A。 （4）客户端A发回ACK报文确认，并将确认序号设置为收到序号加1。 TCP采用四次挥手关闭连接如图2所示。 抓包截图 其中 183.136.236.13 是服务器的ip可以看到 这一次挥手是由 服务器 发起的 第一次挥手 FIN +ACK 第二次挥手 ACK 第三次挥手 FIN +ACK 第四次挥手 ACK 总结TCP 由于是全双工的，断开链接需要四次挥手]]></content>
      <categories>
        <category>TCP</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置]]></title>
    <url>%2F2019%2F09%2F30%2Fnginx%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[windows下nginx配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 443; server_name www.sjjtcloud.com; client_max_body_size 15M; ssl on; ssl_certificate cert/2195340_www.sjjtcloud.com.pem; ssl_certificate_key cert/2195340_www.sjjtcloud.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; root D:/nginx-1.12.2/html; index index.html index.htm; try_files $uri $uri/ @router; &#125; location /ylzhy-api/api/ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8081; &#125; location /yw-api/api/ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8089; &#125; location /admin &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8090/yw-admin; &#125; &#125; server &#123; listen 80; server_name www.sjjtcloud.com sjjtcloud.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #rewrite ^(.*)$ https://$&#123;server_name&#125;$1 permanent; #rewrite ^(.*)$ https://$host$1 permanent; return 307 https://$server_name$request_uri; &#125; server &#123; listen 8082; server_name fileServer; charset utf-8; location ~ .*\.(gif|jpg|jpeg|png|mp4|pdf)$ &#123; expires 24h; root D://fileweb/; proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path d://fileweb/;#图片访问路径 proxy_redirect off; proxy_set_header Host $host:8082; client_max_body_size 10m; client_body_buffer_size 1280k; proxy_connect_timeout 900; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 40k; proxy_buffers 40 320k; proxy_busy_buffers_size 640k; proxy_temp_file_write_size 640k; &#125; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F19%2F%E9%87%87%E9%9B%86%E5%99%A8%E5%AE%A3%E4%BC%A0%E5%86%8C%2F</url>
    <content type="text"><![CDATA[采集器宣传册]]></content>
  </entry>
  <entry>
    <title><![CDATA[微信小程序获取openid]]></title>
    <url>%2F2019%2F08%2F28%2F%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%8E%B7%E5%8F%96openid%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920// 登录wx.login(&#123; success: res =&gt; &#123; // 发送 res.code 到后台换取 openId, sessionKey, unionId console.log(&quot;res: &quot;+JSON.stringify(res)) var code = res.code; wx.request(&#123; url: &apos;https://nilaile.easy.echosite.cn/yw-api/api/common/wechat/getOpenId&apos;, method:&apos;post&apos;, data:&#123; &apos;code&apos;: code, &apos;clientFlag&apos;:&apos;client_company&apos; &#125;, success:function(result)&#123; console.log(&quot;请求结果: &quot; + JSON.stringify(result.data)) &#125; &#125;) &#125;&#125;)]]></content>
      <categories>
        <category>微信小程序</category>
      </categories>
      <tags>
        <tag>微信小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7不能ping通主机,主机可以ping通虚拟机]]></title>
    <url>%2F2019%2F08%2F27%2FCentos7%E4%B8%8D%E8%83%BDping%E9%80%9A%E4%B8%BB%E6%9C%BA%2C%E4%B8%BB%E6%9C%BA%E5%8F%AF%E4%BB%A5ping%E9%80%9A%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[在VM中安装了一个 CentOS 7.4 系统 ，使用的是桥接模式，宿主机可以ping通虚拟机，虚拟机却ping不能宿主机。但是可以ping通外网域名，例如：www.baidu.com解决办法：更改windows防火墙设置打开windows防火墙–高级设置–入站规则：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vmware虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池的优雅关闭实践(转载)]]></title>
    <url>%2F2019%2F08%2F20%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BC%98%E9%9B%85%E5%85%B3%E9%97%AD%E5%AE%9E%E8%B7%B5(%E8%BD%AC%E8%BD%BD)%2F</url>
    <content type="text"><![CDATA[平时开发中，大家更多的关注的是线程池的创建、任务的提交和执行。往往会忽略线程池的关闭，甚至忘记调用shutdown()方法，导致内存溢出。大多知道需要调用shutdown()关闭线程池，也少研究其真正的关闭过程。 首先看源码中的一句注释： A pool that is no longer referenced in a program and has no remaining threads will be shutdown automatically.如果程序中不再持有线程池的引用，并且线程池中没有线程时，线程池将会自动关闭。 线程池自动关闭的两个条件：1、线程池的引用不可达；2、线程池中没有线程； 这里对于条件2解释一下，线程池中没有线程是指线程池中的所有线程都已运行完自动消亡。然而我们常用的FixedThreadPool的核心线程没有超时策略，所以并不会自动关闭。 展示两种不同线程池 不关闭 的情况： 1、FixedThreadPool 示例 1234567public static void main(String[] args) &#123; while(true) &#123; ExecutorService executorService = Executors.newFixedThreadPool(8); executorService.execute(() -&gt; System.out.println(&quot;running&quot;)); executorService = null; &#125;&#125; 输出结果： 123456789running......runningException in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method) at java.lang.Thread.start(Thread.java:714) at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:950) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1357) at test.PoolTest.main(PoolTest.java:29) 因为FixedThreadPool的核心线程不会自动超时关闭，使用时必须在适当的时候调用shutdown()方法。 2、 CachedThreadPool 示例 12345678910public static void main(String[] args) &#123; while(true) &#123; // 默认keepAliveTime为 60s ExecutorService executorService = Executors.newCachedThreadPool(); ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) executorService; // 为了更好的模拟，动态修改为1纳秒 threadPoolExecutor.setKeepAliveTime(1, TimeUnit.NANOSECONDS); threadPoolExecutor.execute(() -&gt; System.out.println(&quot;running&quot;)); &#125;&#125; 输出结果： 123456runningrunningrunningrunningrunning...... CachedThreadPool 的线程 keepAliveTime 默认为 60s ，核心线程数量为 0 ，所以不会有核心线程存活阻止线程池自动关闭。 详见 线程池之ThreadPoolExecutor构造 ，为了更快的模拟，构造后将 keepAliveTime 修改为1纳秒，相当于线程执行完马上会消亡，所以线程池可以被回收。实际开发中，如果CachedThreadPool 确实忘记关闭，在一定时间后是可以被回收的。但仍然建议显示关闭。 然而，线程池关闭的意义不仅仅在于结束线程执行，避免内存溢出，因为大多使用的场景并非上述示例那样 朝生夕死。线程池一般是持续工作的全局场景，如数据库连接池。 本文更多要讨论的是当线程池调用shutdown方法后，会经历些什么？思考一下几个问题： 是否可以继续接受新任务？继续提交新任务会怎样？ 等待队列里的任务是否还会执行？ 正在执行的任务是否会立即中断？ 问题1：是否可以继续接受新任务？继续提交新任务会怎样？ 123456public static void main(String[] args) &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(4, 4, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;()); executor.execute(() -&gt; System.out.println(&quot;before shutdown&quot;)); executor.shutdown(); executor.execute(() -&gt; System.out.println(&quot;after shutdown&quot;));&#125; 输出结果如下： 123456before shutdownException in thread &quot;main&quot; java.util.concurrent.RejectedExecutionException: Task PoolTest$$Lambda$2/142257191@3e3abc88 rejected from java.util.concurrent.ThreadPoolExecutor@6ce253f1[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1] at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369) at PoolTest.main(PoolTest.java:12) 当线程池关闭后，继续提交新任务会抛出异常。这句话也不够准确，不一定是抛出异常，而是执行拒绝策略，默认的拒绝策略是抛出异常。可参见 线程池之ThreadPoolExecutor构造 里面自定义线程池的例子，自定义了忽略策略，但被拒绝时并没有抛出异常。 问题2：等待队列里的任务是否还会执行？ 12345678910111213141516171819202122232425262728public class WaitqueueTest &#123; public static void main(String[] args) &#123; BlockingQueue&lt;Runnable&gt; workQueue = new LinkedBlockingQueue&lt;&gt;(); for(int i = 1; i &lt;= 100 ; i++)&#123; workQueue.add(new Task(String.valueOf(i))); &#125; ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 1, 10, TimeUnit.SECONDS, workQueue); executor.execute(new Task(&quot;0&quot;)); executor.shutdown(); System.out.println(&quot;workQueue size = &quot; + workQueue.size() + &quot; after shutdown&quot;); &#125; static class Task implements Runnable&#123; String name; public Task(String name) &#123; this.name = name; &#125; @Override public void run() &#123; for(int i = 1; i &lt;= 10; i++)&#123; System.out.println(&quot;task &quot; + name + &quot; is running&quot;); &#125; System.out.println(&quot;task &quot; + name + &quot; is over&quot;); &#125; &#125;&#125; 这个demo解释一下，我们用LinkedBlockingQueue构造了一个线程池，在线程池启动前，我们先将工作队列填充100个任务，然后执行task 0 后立即shutdown()线程池，来验证线程池关闭队列的任务运行状态。输出结果如下： 12345678......task 0 is runningtask 0 is overworkQueue size = 100 after shutdown //表示线程池关闭后，队列任然有100个任务task 1 is running......task 100 is runningtask 100 is over 从结果中我们可以看到，线程池虽然关闭，但是队列中的任务任然继续执行，所以用 shutdown()方式关闭线程池时需要考虑是否是你想要的效果。 如果你希望线程池中的等待队列中的任务不继续执行，可以使用shutdownNow()方法，将上述代码进行调整，如下： 123456789101112131415161718192021222324252627282930public class WaitqueueTest &#123; public static void main(String[] args) &#123; BlockingQueue&lt;Runnable&gt; workQueue = new LinkedBlockingQueue&lt;&gt;(); for(int i = 1; i &lt;= 100 ; i++)&#123; workQueue.add(new Task(String.valueOf(i))); &#125; ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 1, 10, TimeUnit.SECONDS, workQueue); executor.execute(new Task(&quot;0&quot;)); // shutdownNow有返回值，返回被抛弃的任务list List&lt;Runnable&gt; dropList = executor.shutdownNow(); System.out.println(&quot;workQueue size = &quot; + workQueue.size() + &quot; after shutdown&quot;); System.out.println(&quot;dropList size = &quot; + dropList.size()); &#125; static class Task implements Runnable&#123; String name; public Task(String name) &#123; this.name = name; &#125; @Override public void run() &#123; for(int i = 1; i &lt;= 10; i++)&#123; System.out.println(&quot;task &quot; + name + &quot; is running&quot;); &#125; System.out.println(&quot;task &quot; + name + &quot; is over&quot;); &#125; &#125;&#125; 输出结果如下： 12345678910111213task 0 is runningworkQueue size = 0 after shutdowntask 0 is runningtask 0 is runningtask 0 is runningtask 0 is runningtask 0 is runningtask 0 is runningtask 0 is runningtask 0 is runningtask 0 is runningdropList size = 100task 0 is over 从上述输出可以看到，只有任务0执行完毕，其他任务都被drop掉了，dropList的size为100。通过dropList我们可以对未处理的任务进行进一步的处理，如log记录，转发等； 问题3：正在执行的任务是否会立即中断？ 要验证这个问题，需要对线程的 interrupt 方法有一定了解。 推荐阅读 ——线程中断机制关于 interrupt 方法：首先，一个线程不应该由其他线程来强制中断或停止，而是应该由线程自己自行停止。所以，Thread.stop, Thread.suspend, Thread.resume 都已经被废弃了。而 Thread.interrupt 的作用其实也不是中断线程，而是「通知线程应该中断了」，具体到底中断还是继续运行，应该由被通知的线程自己处理。具体来说，当对一个线程，调用 interrupt() 时，① 如果线程处于被阻塞状态（例如处于sleep, wait, join 等状态），那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常。仅此而已。② 如果线程处于正常活动状态，那么会将该线程的中断标志设置为 true，仅此而已。被设置中断标志的线程将继续正常运行，不受影响。interrupt() 并不能真正的中断线程，需要被调用的线程自己进行配合才行。也就是说，一个线程如果有被中断的需求，那么就可以这样做。① 在正常运行任务时，经常检查本线程的中断标志位，如果被设置了中断标志就自行停止线程。② 在调用阻塞方法时正确处理InterruptedException异常。（例如，catch异常后就结束线程。） 12345678910111213141516171819202122232425262728public class InteruptTest &#123; public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 1, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;()); executor.execute(new Task(&quot;0&quot;)); Thread.sleep(1); executor.shutdown(); System.out.println(&quot;executor has been shutdown&quot;); &#125; static class Task implements Runnable &#123; String name; public Task(String name) &#123; this.name = name; &#125; @Override public void run() &#123; for (int i = 1; i &lt;= 100 &amp;&amp; !Thread.interrupted(); i++) &#123; Thread.yield(); System.out.println(&quot;task &quot; + name + &quot; is running, round &quot; + i); &#125; &#125; &#125;&#125; 输出结果如下： 123456789task 0 is running, round 1task 0 is running, round 2task 0 is running, round 3......task 0 is running, round 28executor has been shutdown......task 0 is running, round 99task 0 is running, round 100 为了体现在任务执行中打断，在主线程进行短暂 sleep ， task 中 调用 Thread.yield() ，出让时间片。从结果中可以看到，线程池被关闭后，正则运行的任务没有被 interrupt。说明shutdown()方法不会 interrupt 运行中线程。再将其改修改为shutdownNow() 后输出结果如下： 12345678task 0 is running, round 1task 0 is running, round 2......task 0 is running, round 56task 0 is running, round 57task 0 is running, round 58task 0 is running, round 59executor has been shutdown 修改为shutdownNow() 后，task任务没有执行完，执行到中间的时候就被 interrupt 后没有继续执行了。 总结，想要正确的关闭线程池，并不是简单的调用shutdown方法那么简单，要考虑到应用场景的需求，如何拒绝新来的请求任务？如何处理等待队列中的任务？如何处理正在执行的任务？想好这几个问题，在确定如何优雅而正确的关闭线程池。PS：线程被 interrupt 后，需要再run方法中单独处理 interrupted 状态，interrupt 更类似一个标志位，不会直接打断线程的执行。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows运维脚本]]></title>
    <url>%2F2019%2F08%2F20%2Fwindows%E6%A0%B9%E6%8D%AE%E7%AB%AF%E5%8F%A3%E5%8F%B7%E6%9D%80%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[windows根据端口号,查杀进程123456@echo offfor /f &quot;tokens=5&quot; %%i in (&apos;netstat -aon ^| findstr &quot;:8086&quot;&apos;) do ( set n=%%i)taskkill /f /pid %n%]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>运维脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NUC启动U盘制作]]></title>
    <url>%2F2019%2F08%2F19%2FNUC%E5%90%AF%E5%8A%A8%E7%9B%98%E5%88%B6%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[U盘制作步骤及镜像复制 CMD-&gt;diskpart DISKPART&gt; list disk 磁盘 ### 状态 大小 可用 Dyn Gpt 磁盘 0 联机 931 GB 1024 KB 磁盘 1 联机 119 GB 0 B 磁盘 2 联机 14 GB 0 B DISKPART&gt; select disk 2 磁盘 2 现在是所选磁盘。 DISKPART&gt; cleanDiskPart 成功地清除了磁盘。 DISKPART&gt; create partition primaryDiskPart 成功地创建了指定分区。 DISKPART&gt; select partition 1 分区 1 现在是所选分区。 DISKPART&gt; active DiskPart 将当前分区标为活动。 DISKPART&gt; format fs=ntfs quick 100 百分比已完成 DiskPart 成功格式化该卷。 将ISO镜像文件打开,然后将其中的8个文件,复制到刚刚做好的U盘中 开启BIOS按F12 选择UEFI即可]]></content>
      <categories>
        <category>启动U盘</category>
      </categories>
      <tags>
        <tag>NUC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池之ThreadPoolExecutor使用]]></title>
    <url>%2F2019%2F08%2F19%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[ThreadPoolExecutor构造方法 我们以最后一个构造方法（参数最多的那个），对其参数进行解释： 123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, // 1 int maximumPoolSize, // 2 long keepAliveTime, // 3 TimeUnit unit, // 4 BlockingQueue&lt;Runnable&gt; workQueue, // 5 ThreadFactory threadFactory, // 6 RejectedExecutionHandler handler ) &#123; //7 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 序号 名称 类型 含义 1 corePoolSize int 核心线程池大小 2 maximumPoolSize int 最大线程池大小 3 keepAliveTime long 线程最大空闲时间 4 unit TimeUnit 时间单位 5 workQueue BlockingQueue 线程等待队列 6 threadFactory ThreadFactory 线程创建工厂 7 handler RejectedExecutionHandler 拒绝策略 如果对这些参数作用有疑惑的请看 ThreadPoolExecutor概述。知道了各个参数的作用后，我们开始构造符合我们期待的线程池。首先看JDK给我们预定义的几种线程池： 预定义的线程池虽然这种创建线程池的方法比较简便，但是阿里巴巴开发规范中,明确指出禁止使用Executors来创建线程,因为这样创建线程池,有可能会导致OOM, 创建线程池应该使用ThreadPoolExecutor的方式, 其实这些创建线程池的方法,背后原理也是使用TreadPoolExecutor来创建的 12345678910【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors 返回的线程池对象的弊端如下：1）FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。2）CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 Executors创建线程池Executors创建线程池方法列表： 方法名 功能 newFixedThreadPool(int nThreads) 创建固定大小的线程池（请求队列不受限制） newSingleThreadExecutor() 创建只有一个线程的线程池（请求队列不受限制） newCachedThreadPool() 创建一个不限线程数上限的线程池，任何提交的任务都将立即执行（线程数不受限制） newScheduledThreadPool(int corePoolSize) 此线程池支持定时以及周期性执行任务的需求（线程数不受限制） 源码分析 FixedThreadPool 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; corePoolSize与maximumPoolSize相等，即其线程全为核心线程，是一个固定大小的线程池，是其优势； keepAliveTime = 0 该参数默认对核心线程无效，而FixedThreadPool全部为核心线程； workQueue 为LinkedBlockingQueue（无界阻塞队列），队列最大值为Integer.MAX_VALUE。如果任务提交速度持续大余任务处理速度，会造成队列大量阻塞。因为队列很大，很有可能在拒绝策略前，内存溢出。是其劣势； FixedThreadPool的任务执行是无序的； 适用场景：可用于Web服务瞬时削峰，但需注意长时间持续高峰情况造成的队列阻塞。 CachedThreadPool 12345 public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; corePoolSize = 0，maximumPoolSize = Integer.MAX_VALUE，即线程数量几乎无限制； keepAliveTime = 60s，线程空闲60s后自动结束。 workQueue 为 SynchronousQueue 同步队列，这个队列类似于一个接力棒，入队出队必须同时传递，因为CachedThreadPool线程创建无限制，不会有队列等待，所以使用SynchronousQueue； 适用场景：快速处理大量耗时较短的任务，如Netty的NIO接受请求时，可使用CachedThreadPool。 SingleThreadExecutor 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 咋一瞅，不就是newFixedThreadPool(1)吗？定眼一看，这里多了一层FinalizableDelegatedExecutorService包装，这一层有什么用呢，写个dome来解释一下： 12345678910 public static void main(String[] args) &#123; ExecutorService fixedExecutorService = Executors.newFixedThreadPool(1); ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) fixedExecutorService; System.out.println(threadPoolExecutor.getMaximumPoolSize()); threadPoolExecutor.setCorePoolSize(8); ExecutorService singleExecutorService = Executors.newSingleThreadExecutor();// 运行时异常 java.lang.ClassCastException// ThreadPoolExecutor threadPoolExecutor2 = (ThreadPoolExecutor) singleExecutorService; &#125; 对比可以看出，FixedThreadPool可以向下转型为ThreadPoolExecutor，并对其线程池进行配置，而SingleThreadExecutor被包装后，无法成功向下转型。因此，SingleThreadExecutor被定以后，无法修改，做到了真正的Single。 ScheduledThreadPool 123public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125; newScheduledThreadPool调用的是ScheduledThreadPoolExecutor的构造方法，而ScheduledThreadPoolExecutor继承了ThreadPoolExecutor，构造是还是调用了其父类的构造方法。 1234public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; 二、自定义线程池以下是自定义线程池，使用了有界队列，自定义ThreadFactory和拒绝策略的demo： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class ThreadTest &#123; public static void main(String[] args) throws InterruptedException, IOException &#123; int corePoolSize = 2; int maximumPoolSize = 4; long keepAliveTime = 10; TimeUnit unit = TimeUnit.SECONDS; BlockingQueue&lt;Runnable&gt; workQueue = new ArrayBlockingQueue&lt;&gt;(2); ThreadFactory threadFactory = new NameTreadFactory(); RejectedExecutionHandler handler = new MyIgnorePolicy(); ThreadPoolExecutor executor = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler); executor.prestartAllCoreThreads(); // 预启动所有核心线程 for (int i = 1; i &lt;= 10; i++) &#123; MyTask task = new MyTask(String.valueOf(i)); executor.execute(task); &#125; System.in.read(); //阻塞主线程 &#125; static class NameTreadFactory implements ThreadFactory &#123; private final AtomicInteger mThreadNum = new AtomicInteger(1); @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r, &quot;my-thread-&quot; + mThreadNum.getAndIncrement()); System.out.println(t.getName() + &quot; has been created&quot;); return t; &#125; &#125; public static class MyIgnorePolicy implements RejectedExecutionHandler &#123; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; doLog(r, e); &#125; private void doLog(Runnable r, ThreadPoolExecutor e) &#123; // 可做日志记录等 System.err.println( r.toString() + &quot; rejected&quot;);// System.out.println(&quot;completedTaskCount: &quot; + e.getCompletedTaskCount()); &#125; &#125; static class MyTask implements Runnable &#123; private String name; public MyTask(String name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; System.out.println(this.toString() + &quot; is running!&quot;); Thread.sleep(3000); //让任务执行慢点 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public String getName() &#123; return name; &#125; @Override public String toString() &#123; return &quot;MyTask [name=&quot; + name + &quot;]&quot;; &#125; &#125;&#125; 输出结果如下： image.png 其中线程线程1-4先占满了核心线程和最大线程数量，然后4、5线程进入等待队列，7-10线程被直接忽略拒绝执行，等1-4线程中有线程执行完后通知4、5线程继续执行。 总结，通过自定义线程池，我们可以更好的让线程池为我们所用，更加适应我的实际场景。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CenOS7.5使用crontab定时备份数据库脚本]]></title>
    <url>%2F2019%2F08%2F07%2FCenOS7.5%E4%BD%BF%E7%94%A8crontab%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E5%BA%93%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[1.编写备份脚本mysqlBackup.sh12345678910111213141516171819202122232425262728#!/bin/shDB_IP=localhostDB_PORT=3306DB_USER=root#密码 #＆这些需要转义加＼DB_PASSWORD=l\#cxhd3\&amp;0vxDB_NAME=businessDB_BACKUP_DIR=/home/backup/mysql#切换目录cd $DB_BACKUP_DIRday=`date +%Y%m%d`#删除rm -rf $daymkdir $daycd $dayecho &quot;================ 开始备份.. =================&quot;tables=(tb_user tb_dept)for table in $&#123;tables[@]&#125;;do backup_file_name=&quot;$&#123;table&#125;.sql&quot; mysqldump -h$&#123;DB_IP&#125; -u$&#123;DB_USER&#125; -p$&#123;DB_PASSWORD&#125; -P$&#123;DB_PORT&#125; $DB_NAME $table&gt;$backup_file_namedoneecho &quot;================ 结束备份.. =================&quot; 2.配置邮件配置(不配置的话,Crontab执行后邮件无法发送)12345678910111213vi /etc/postfix/main.cf发现配置为：inet_interfaces = localhostinet_protocols = all改成：inet_interfaces = allinet_protocols = all重新启动service postfix start 3.配置Crontab任务12345678$ crontab -eSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=rootHOME=/*/2 * * * * sh /home/backup/mysqlBackup.sh 4. 查看任务执行日志vim /var/log/cron 查看任务执行详情可以通过查看LINUX系统邮件,任务执行后Crontab会发送邮件给添加该任务的用户mail 常用命令12345mail 打开邮件列表mail p 查看邮件详情mail z 返回邮件列表mail d 删除邮件mail q 保存退出]]></content>
      <categories>
        <category>LINUX</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOs定时任务Crontab的使用]]></title>
    <url>%2F2019%2F08%2F07%2FCentOs%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1Crontab%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Linux 下通过crontab来执行定时任务,当安装完成操作系统之后，默认便会启动此任务调度命令。crond命令每分锺会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。 linux任务调度的工作主要分为以下两类： 1、系统执行的工作：系统周期性所要执行的工作，如备份系统数据、清理缓存 2、个人执行的工作：某个用户定期要做的工作，例如每隔10分钟检查邮件服务器是否有新信，这些工作可由每个用户自行设置 语法crontab [ -u user ] file或crontab [ -u user ] { -l | -r | -e } 参数说明 -u user：用来设定某个用户的crontab服务,这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。 file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件. crontab的文件格式 分 时 日 月 星期 要运行的命令 第1列分钟0～59第2列小时0～23（0表示子夜）第3列日1～31第4列月1～12第5列星期0～7（0和7表示星期天）第6列要运行的命令 常用方法列出crontab文件$ crontab -l 编辑crontab文件$ crontab -e可以像使用vi编辑其他任何文件那样修改crontab文件并退出。如果修改了某些条目或添加了新的条目，那么在保存该文件时， cron会对其进行必要的完整性检查。如果其中的某个域出现了超出允许范围的值，它会提示你。 我们在编辑crontab文件时，没准会加入新的条目 删除crontab文件$crontab -r 注解最好在crontab文件的每一个条目之上加入一条注释，这样就可以知道它的功能、运行时间，更为重要的是，知道这是哪位用户的定时作业。 1234567891011121314151617181920212223242526272829303132333435实例1：每1分钟执行一次myCommand * * * myCommand实例2：每小时的第3和第15分钟执行 3,15 * * * * myCommand 实例3：在上午8点到11点的第3和第15分钟执行 3,15 8-11 * * * myCommand实例4：每隔两天的上午8点到11点的第3和第15分钟执行 3,15 8-11 */2 * * myCommand实例5：每周一上午8点到11点的第3和第15分钟执行 3,15 8-11 * * 1 myCommand实例6：每晚的21:30重启smb 30 21 * * * /etc/init.d/smb restart实例7：每月1、10、22日的4 : 45重启smb 45 4 1,10,22 * * /etc/init.d/smb restart实例8：每周六、周日的1 : 10重启smb 10 1 * * 6,0 /etc/init.d/smb restart实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb 0,30 18-23 * * * /etc/init.d/smb restart实例10：每星期六的晚上11 : 00 pm重启smb 0 23 * * 6 /etc/init.d/smb restart实例11：每一小时重启smb * */1 * * * /etc/init.d/smb restart实例12：晚上11点到早上7点之间，每隔一小时重启smb 0 23-7 * * * /etc/init.d/smb restart 案例(每2分钟执行一次test.sh中脚本)123456SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=rootHOME=/*/2 * * * * sh /home/backup/test.sh 查看cron执行的日志1vim /var/log/cron 看到如下记录日志,发现linux在执行任务后向管理员发送了邮件,但是这个邮件没有发送成功 123456Aug 6 10:44:01 iZ3i4n96yv24gsZ CROND[2868]: (root) CMD (sh /home/backup/test.sh)Aug 6 10:44:01 iZ3i4n96yv24gsZ CROND[2867]: (root) MAIL (mailed 2802 bytes of output but got status 0x004b#012)Aug 6 10:45:01 iZ3i4n96yv24gsZ CROND[3976]: (root) CMD (sh /home/backup/test.sh)Aug 6 10:45:01 iZ3i4n96yv24gsZ CROND[3975]: (root) MAIL (mailed 2802 bytes of output but got status 0x004b#012)Aug 6 10:46:01 iZ3i4n96yv24gsZ CROND[5031]: (root) CMD (sh /home/backup/test.sh)Aug 6 10:46:01 iZ3i4n96yv24gsZ CROND[5030]: (root) MAIL (mailed 2802 bytes of output but got status 0x004b#012) ### 问题：如果想要查看详细的任务执行日志,要查看登录用户的邮箱,本地测试时使用的root用户, 查看发现无root用户的任何邮件 解決方式 查看mail的发送日志 vim /var/log/maillog 原因是 parameter inet_interfaces: no local interface found for ::1 123456Aug 6 10:42:01 iZ3i4n96yv24gsZ postfix/sendmail[584]: fatal: parameter inet_interfaces: no local interface found for ::1Aug 6 10:43:01 iZ3i4n96yv24gsZ postfix/sendmail[1817]: fatal: parameter inet_interfaces: no local interface found for ::1Aug 6 10:44:01 iZ3i4n96yv24gsZ postfix/sendmail[2870]: fatal: parameter inet_interfaces: no local interface found for ::1Aug 6 10:45:01 iZ3i4n96yv24gsZ postfix/sendmail[3978]: fatal: parameter inet_interfaces: no local interface found for ::1Aug 6 10:46:01 iZ3i4n96yv24gsZ postfix/sendmail[5033]: fatal: parameter inet_interfaces: no local interface found for ::1 通过google发现解决方式为 12345678910111213vi /etc/postfix/main.cf发现配置为：inet_interfaces = localhostinet_protocols = all改成：inet_interfaces = allinet_protocols = all重新启动service postfix start 再等待一个周期后,收到了定时任务推送的邮件,查看邮件内容,一切正常]]></content>
      <categories>
        <category>LINUX</category>
      </categories>
      <tags>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java面试系列问题(4)]]></title>
    <url>%2F2019%2F08%2F07%2F%E9%9D%A2%E8%AF%954%2F</url>
    <content type="text"><![CDATA[一、Java基础 为什么JVM调优经常会将-Xms和-Xmx参数设置成一样； Java线程池的核心属性以及处理流程； Java内存模型，方法区存什么； CMS垃圾回收过程； Full GC次数太多了，如何优化； 直接内存如何管理的； Java线程池的几个参数的意义和实现机制； Java线程池使用无界任务队列和有界任务队列的优劣对比； CountDownLatch和CyclicBarrier的区别； Java中有哪些同步方案（重量级锁、显式锁、并发容器、并发同步器、CAS、volatile、AQS等） 如果你的项目出现了内存泄露，怎么监控这个问题呢； 标记清除和标记整理的区别和优缺点，为何标记整理会发生stop the world； 线程池，如何根据CPU的核数来设计线程大小，如果是计算机密集型的呢，如果是IO密集型的呢？ 让你设计一个cache如何设计； String中hashcode是怎么实现的； JDK中哪些实现了单例模式？ 多个线程同时读写，读线程的数量远远⼤于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？ 线程池内的线程如果全部忙，提交⼀个新的任务，会发⽣什么？队列全部塞满了之后，还是忙，再提交会发⽣什么？ synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？ wait/notify/notifyAll⽅法需不需要被包含在synchronized块中？这是为什么？ ExecutorService你一般是怎么⽤的？是每个Service放一个还是个项目放一个？有什么好处？ 二、数据库 InnoDB的插入缓冲和两次写的概率和意义； 如果建了⼀个单列索引，查询的时候查出2列，会⽤到这个单列索引吗？（会用到） 如果建了⼀个包含多个列的索引，查询的时候只⽤了第⼀列，能不能⽤上这个索引？查三列呢？ 接上题，如果where条件后⾯带有⼀个 i + 5 &lt; 100 会使⽤到这个索引吗？ like %aaa%会使⽤索引吗? like aaa%呢? drop、truncate、delete的区别？ 平时你们是怎么监控数据库的? 慢SQL是怎么排查的？（慢查询日志） 你们数据库是否⽀持emoji表情，如果不⽀持，如何操作?选择什么编码方式？如果支持一个表情占几个字节?(utf8mb4)； 如果查询很慢，你会想到的第⼀个⽅式是什么？（数据库索引） 三、Linux基础 Linux下可以在/proc目录下可以查看CPU的核心数等；cat /proc/下边会有很多系统内核信息可供显示； 说一下栈的内存是怎么分配的； Linux各个目录有了解过吗？/etc、/bin、/dev、/lib、/sbin这些常见的目录主要作用是什么？ 说一下栈帧的内存是怎么分配的； Linux下排查某个死循环的线程； 动态链接和静态链接的区别； 进程的内存分布； 如何查找一个进程打开所有的文件； 说一下常使用的协议及其对应的端口； 为什么会有内核态，保护模式你知道吗? 文件是怎么在磁盘上存储的？ 有了进程为何还要线程呢，不同进程和线程他们之间有什么不同。（进程是资源管理的最小单位，线程是程序执行的最小单位。在操作系统设计上，从进程演化出线程，最主要的目的就是更好的支持SMP以及减小（进程/线程）上下文切换开销。） InnoDB聚集索引B+树叶子节点和磁盘什么顺序相同; 文件系统，进程管理和调度，内存管理机制、虚地址保护模式； 四、网络基础 HTTP1.0和HTTP1.1的区别； DHCP如何实现分配IP的； 发现阶段（DHCP客户端在网络中广播发送DHCP DISCOVER请求报文，发现DHCP服务器，请求IP地址租约）、提供阶段（DHCP服务器通过DHCP OFFER报文向DHCP客户端提供IP地址预分配）、选择阶段（DHCP客户端通过DHCP REQUEST报文确认选择第一个DHCP服务器为它提供IP地址自动分配服务）和确认阶段（被选择的DHCP服务器通过DHCP ACK报文把在DHCP OFFER报文中准备的IP地址租约给对应DHCP客户端）。 OSI七层模型，每层都说下自己的理解和知道的，说的越多越好； 五、框架相关 Servlet如何保证单例模式,可不可以编程多例的哪？ Dubbo请求流程以及原理； Spring框架如何实现事务的； 如果一个接⼝有2个不同的实现, 那么怎么来Autowire一个指定的实现？(可以使用Qualifier注解限定要注入的Bean，也可以使用Qualifier和Autowire注解指定要获取的bean，也可以使用Resource注解的name属性指定要获取的Bean) Spring框架中需要引用哪些jar包，以及这些jar包的用途； Spring Boot没有放到web容器⾥为什么能跑HTTP服务？ Spring中循环注入是什么意思，可不可以解决，如何解决； Spring的声明式事务 @Transaction注解⼀般写在什么位置? 抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚? MyBatis怎么防止SQL注入； Tomcat本身的参数你⼀般会怎么调整？ 了解哪几种序列化协议？如何选择合适的序列化协议； Redis渐进式rehash过程？ 比如我有个电商平台，做每日订单的异常检测，服务端代码应该写；]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java面试系列问题(3)]]></title>
    <url>%2F2019%2F08%2F07%2F%E9%9D%A2%E8%AF%953%2F</url>
    <content type="text"><![CDATA[一、基础题 怎么解决Hash冲突；（开放地址法、链地址法、再哈希法、建立公共溢出区等） 写出一个必然会产生死锁的伪代码； Spring IoC涉及到的设计模式；（工厂模式、单利模式。。） toString()方法什么情况下需要重写； 判断对象相等时，什么情况下只需要重写 equals()，什么情况下需要重写 equals(),hashcode()？ Set内存放的元素为什么不可以重复，内部是如何保证和实现的？ 如何保证分布式缓存的一致性(分布式缓存一致性hash算法?)？分布式session实现？ Java 8流式迭代的好处？ 项目中用到的JDK的哪些特性？ 说一下TreeMap的实现原理？红黑树的性质？红黑树遍历方式有哪些？如果key冲突如何解决？setColor()方法在什么时候用？什么时候会进行旋转和颜色转换？ Spring的bean的创建时机？依赖注入的时机？ ArrayList和LinkList的删除一个元素的时间复杂度；（ArrayList是O(N)，LinkList是O(1)）； CopyOnWriteArrayList是什么； 序列化和反序列化底层如何实现的（ObjectOutputStream 、ObjectInputStream、 readObject writeObject）； 如何调试多线程的程序； 一个线程连着调用start两次会出现什么情况？（由于状态只有就绪、阻塞、执行，状态是无法由执行转化为执行的，所以会报不合法的状态！） HashMap在什么时候时间复杂度是O（1），什么时候是O（n），什么时候又是O（logn）； wait方法能不能被重写？（wait是final类型的，不可以被重写，不仅如此，notify和notifyall都是final类型的），wait能不能被中断； 一个Controller调用两个Service，这两Service又都分别调用两个Dao，问其中用到了几个数据库连接池的连接？ 二、网络基础 HTTP、TCP、UDP的区别和联系； TCP和UDP各自的优势，知道哪些使用UDP协议的成功案例； TCP和UDP各用了底层什么协议； 单个UDP报文最大容量； 单个TCP报文最大容量； TCP报头格式、UDP报头格式； Server遭遇SYN Flood应当怎么处理； Web开发中如何防范XSS？ 拆包和粘包的问题，如何解决，如果我们的包没有固定长度的话，我们的应用程序应该如何解决； 三、操作系统 为什么要内存对齐； 为什么会有大端小端，htol这一类函数的作用； top显示出来的系统信息都是什么含义；（重要！） Linux地址空间，怎么样进行寻址的； Linux如何查找目录或者文件的； 四、分布式其他 分库与分表带来的分布式困境与应对之策； Solr如何实现全天24小时索引更新； 五、Redis Redis插槽的分配（key的有效部分使用CRC16算法计算出哈希值，再将哈希值对16384取余，得到插槽值）; Redis主从是怎么选取的（一种是主动切换，另一种是使用sentinel自动方式）; Redis复制的过程; Redis队列应用场景； Redis主节点宕机了怎么办，还有没有同步的数据怎么办; 六、系统设计开放性题目 秒杀系统设计，超卖怎么搞; 你们的图片时怎么存储的，对应在数据库中时如何保存图片的信息的？ 假如成都没有一座消防站，现在问你要建立几座消防站，每个消防站要配多少名消防官兵，多少辆消防车，请你拿出一个方案； 基于数组实现一个循环阻塞队列； 常见的ipv4地址的展现形式如“168.0.0.1”，请实现ip地址和int类型的相互转换。（使用位移的方式） 现网某个服务部署在多台Liunx服务器上，其中一台突然出现CPU 100%的情况，而其他服务器正常，请列举可能导致这种情况发生的原因？如果您遇到这样的情况，应如何定位？内存？CPU？发布？debug？请求量？ 七、大数据量问题（后边会有专题单独讨论） 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？ 海量日志数据，提取出某日访问百度次数最多的那个IP； 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。 此话题后边会有专门的文章探讨，如果有等不及的小伙伴，可以移步参考： 1、https://blog.csdn.net/v_july_v/article/details/6279498 2、https://blog.csdn.net/v_july_v/article/details/7382693 八、逻辑思维题 有两根粗细均匀的香（烧香拜佛的香），每一根烧完都花一个小时，怎么样能够得到15min？ 假定你有8个撞球，其中有1个球比其他的球稍重,如果只能利用天平来断定哪一个球重,要找到较重的球,要称几次?（2次）； 实验室里有1000个一模一样的瓶子，但是其中的一瓶有毒。可以用实验室的小白鼠来测试哪一瓶是毒药。如果小白鼠喝掉毒药的话，会在一个星期的时候死去，其他瓶子里的药水没有任何副作用。请问最少用多少只小白鼠可以在一个星期以内查出哪瓶是毒药；（答案是10只） 假设有一个池塘，里面有无穷多的水。现有2个空水壶，容积分别为5升和6升。问题是如何只用这2个水壶从池塘里取得3升的水；]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java面试系列问题(2)]]></title>
    <url>%2F2019%2F08%2F07%2F%E9%9D%A2%E8%AF%952%2F</url>
    <content type="text"><![CDATA[一、Java相关 Arraylist与LinkedList默认空间是多少； Arraylist与LinkedList区别与各自的优势List 和 Map 区别； 谈谈HashMap，哈希表解决hash冲突的方法； 为什么要重写hashcode()和equals()以及他们之间的区别与关系； Object的hashcode()是怎么计算的？ 若hashcode方法永远返回1或者一个常量会产生什么结果？ Java Collections和Arrays的sort方法默认的排序方法是什么； 引用计数法与GC Root可达性分析法区别； 浅拷贝和深拷贝的区别； String s=”abc”和String s=new String(“abc”)区别； HashSet方法里面的hashcode存在哪，如果重写equals不重写hashcode会怎么样？ 反射的作用与实现原理； Java中的回调机制； 模板方法模式； 开闭原则说一下； 发布/订阅使用场景； KMP算法（一种改进的字符串匹配算法）； JMM里边的原子性、可见性、有序性是如何体现出来的，JMM中内存屏障是什么意思， 二、多线程 AtomicInteger底层实现原理； synchronized与ReentraLock哪个是公平锁； CAS机制会出现什么问题； 用过并发包下边的哪些类； 一个线程连着调用start两次会出现什么情况？ wait方法能不能被重写，wait能不能被中断； 线程池的实现？四种线程池？重要参数及原理？任务拒接策略有哪几种？ 线程状态以及API怎么操作会发生这种转换； 常用的避免死锁方法； 三、JVM Minor GC与Full GC分别在什么时候发生？什么时候触发Full GC; GC收集器有哪些？CMS收集器与G1收集器的特点。 Java在什么时候会出现内存泄漏； Java中的大对象如何进行存储； rt.jar被什么类加载器加载，什么时间加载； 自己写的类被什么加载，什么时间加载； 自己写的两个不同的类是被同一个类加载器加载的吗？为什么？ 为什么新生代内存需要有两个Survivor区？ 几种常用的内存调试工具：jmap、jstack、jconsole； 类加载的五个过程：加载、验证、准备、解析、初始化； G1停顿吗，CMS回收步骤，CMS为什么会停顿，停顿时间； 栈主要存的数据是什么，堆呢？ 堆分为哪几块，比如说新生代老生代，那么新生代又分为什么？ 软引用和弱引用的使用场景（软引用可以实现缓存，弱引用可以用来在回调函数中防止内存泄露）； 四、数据库 数据库索引，什么是全文索引，全文索引中的倒排索引是什么原理； 数据库最佳左前缀原则是什么？ 数据库的三大范式； 悲观锁和乐观锁的原理和应用场景； 左连接、右连接、内连接、外连接、交叉连接、笛卡儿积等； 一般情况下数据库宕机了如何进行恢复（什么是Write Ahead Log机制，什么是Double Write机制，什么是Check Point）； 什么是redo日志、什么是undo日志； 数据库中的隔离性是怎样实现的；原子性、一致性、持久性又是如何实现的； 什么是组合索引，组合索引什么时候会失效； 关系型数据库和非关系型数据库区别； 数据库死锁如何解决； MySQL并发情况下怎么解决（通过事务、隔离级别、锁）； MySQL中的MVCC机制是什么意思，根据具体场景，MVCC是否有问题； MySQL数据库的隔离级别，以及如何解决幻读； 五、缓存服务器 Redis中zSet跳跃表问题； Redis的set的应用场合？ Redis高级特性了解吗？ Redis的pipeline有什么用处？ Redis集群宕机如何处理，怎么样进行数据的迁移； Redis的集群方案； Redis原子操作怎么用比较好； Redis过期策略是怎么实现的呢？ 六、SSM相关 Spring中@Autowired和@Resource注解的区别？ Spring声明一个 bean 如何对其进行个性化定制； MyBatis有什么优势； MyBatis如何做事务管理； 七、操作系统 Linux静态链接和动态链接； 什么是IO多路复用模型（select、poll、epoll）； Linux中的grep管道用处？Linux的常用命令？ 操作系统中虚拟地址、逻辑地址、线性地址、物理地址的概念及区别； 内存的页面置换算法； 内存的页面置换算法； 进程调度算法，操作系统是如何调度进程的； 父子进程、孤儿进程、僵死进程等概念； fork进程时的操作； kill用法，某个进程杀不掉的原因（僵死进程；进入内核态，忽略kill信号）； 系统管理命令（如查看内存使用、网络情况）； find命令、awk使用； Linux下排查某个死循环的线程； 八、网络相关 数据链路层是做什么的? 数据链路层的流量控制？ 网络模型的分层、IP和Mac地址在那个层、TCP和HTTP分别在那个层； TCP滑动窗口； TCP为什么可靠； TCP的同传，拆包与组装包是什么意思； Https和Http有什么区别； Http 为什么是无状态的； TCP三次握手，为什么不是三次，为什么不是四次； TCP的拥塞控制、流量控制详细说明？ Http1.0和Http2.0的区别； 两个不同ip地址的计算机之间如何通信； 地址解析协议ARP； OSI七层模型分别对应着五层模型的哪一部分； TCP三次握手数据丢失了怎么办？那如果后面又找到了呢？ 九、分布式相关 消息队列使用的场景介绍和作用（应用耦合、异步消息、流量削锋等）； 如何解决消息队列丢失消息和重复消费问题； Kafka使用过吗，什么是幂等性？怎么保证一致性，持久化怎么做，分区partition的理解，LEO是什么意思，如何保证多个partition之间数据一致性的（ISR机制），为什么Kafka可以这么快（基于磁盘的顺序读写）； 异步队列怎么实现； 你项目的并发是多少？怎么解决高并发问题？单机情况下Tomcat的并发大概是多少，MySQL的并发大致是多少？ 什么是C10K问题； 高并发情况下怎么办； 分布式理论，什么是CAP理论，什么是Base理论，什么是Paxos理论； 分布式协议的选举算法； 说一下你对微服务的理解，与SOA的区别； Dubbo的基本原理，RPC，支持哪些通信方式，服务的调用过程； Dubbo如果有一个服务挂掉了怎么办； 分布式事务，操作两个表不在一个库，如何保证一致性。 分布式系统中，每台机器如何产生一个唯一的随机值； 系统的量级、pv、uv等； 什么是Hash一致性算法？分布式缓存的一致性，服务器如何扩容（哈希环）； 正向代理、反向代理； 什么是客户端负载均衡策略、什么是服务器端负载均衡策略； 如何优化Tomcat，常见的优化方式有哪些； Nginx的Master和Worker，Nginx是如何处理请求的； 十、系统设计相关 如何防止表单重复提交（Token令牌环等方式）； 有一个url白名单，需要使用正则表达式进行过滤，但是url量级很大，大概亿级，那么如何优化正则表达式？如何优化亿级的url匹配呢？ 常见的Nginx负载均衡策略；已有两台Nginx服务器了，倘若这时候再增加一台服务器，采用什么负载均衡算法比较好？ 扫描二维码登录的过程解析； 如何设计一个生成唯一UUID的算法？ 实现一个负载均衡的算法，服务器资源分配为70%、20%、10%； 有三个线程T1 T2 T3，如何保证他们按顺序执行； 三个线程循环输出ABCABCABC…. 十一、安全相关 什么是XSS攻击，XSS攻击的一般表现形式有哪些？如何防止XSS攻击；]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java面试系列问题(1)]]></title>
    <url>%2F2019%2F08%2F07%2F%E9%9D%A2%E8%AF%951%2F</url>
    <content type="text"><![CDATA[1. final, finally, finalize 的区别 final它是java中的一个关键字和修饰符,用于声明属性,方法，类，分别标书修饰的属性不可变,方法不可覆盖,类不可继承 finally是异常处理语句结构的一部分，表示总是执行,使用 finally 可以维护对象的内部状态，并可以清理非内存资源 finallize这个方法是Object类的一个方法，因此所有类都继承了它,当垃圾收集器确定某个对象不再被引用时，会调用该方法做清理工作,如果想要执行自定义的清理工作，可以在子类中覆盖该方法. 2. Exception、Error、运行时异常与一般异常有何异同https://blog.csdn.net/m0_37531231/article/details/79502778(参考) Error层次结构描述了java运行时系统的内部错误和资源耗尽错误。大多数错误与代码编写者执行的操作无关，而表示代码运行时 JVM（Java 虚拟机）出现的问题 Exceprion这个层次结构又分解为连个分支：一个分支派生于RuntimeException；另一个分支包含其他异常。划分两个分支的规则是：由程序错误导致的异常属于RuntimeException；而程序本身没有没有问题，但由于像I/O错误这类异常导致的异常属于其他异常 3. 请写出5种常见到的runtime exceptionNullpointerExection IndexOutOfBoundsException NumberFormatException FileNotFoundException EofException 4. int 和 Integer 有什么区别，Integer的值缓存范围int是java中基本数据类型，Integer是对象类型,它是int的包装类java对于-128到127之间的数，会进行缓存 5.包装类，装箱和拆箱Java中的基本类型功能简单，不具备对象的特性，为了使基本类型具备对象的特性，所以出现了包装类，就可以像操作对象一样操作基本类型数据 装箱就是 自动将基本数据类型转换为包装器类型；拆箱就是 自动将包装器类型转换为基本数据类型。 123java5之前如果要定义一个值为10的Integer对象 必须这样定义 Integer i = new Integer(10)Integer i = 10; //装箱int n = i; //拆箱 6.String、StringBuilder、StringBuffer1.执行速度StringBuilder &gt; StringBuffer &gt; String 操作少量数据用String, 单线程下操作大量字符串数据用StringBuilder, 多线程下操作大量数据用StringBuffer 7.重载和重写的区别重载(Overload):方法名称相同, 参数个数或类型不同，可以有不同的返回类型,可以有不同的访问修饰符,可以抛出不同的异常. 重写(Override):参数列表与被重写的方法相同，返回类型与被重写的方法一致，访问修饰符要大于被重写方法的修饰符 8.抽象类和接口有什么区别1.抽象类可以有默认的方法实现,接口完全是抽象的不存在方法实现2.抽象类可以有构造器, 接口没有构造器3.抽象类的修饰符可以是public,protected,default; 接口默认都是public,不能使用其他修饰符4.抽象类比接口速度更快，因为接口需要寻找它的实现类5.抽象类可以继承1个类并可以实现多个接口， 接口只能实现接口 不能继承接口 9.说说反射的用途及实现反射是java的特征之一, 通过反射我们可以在程序运行时获知程序的每个属性和方法用途: 反射最重要的用途就是开发各种通用框架 很多框架（比如 Spring）都是配置化的（比如通过 XML文件配置 JavaBean，Action之类的），为了保证框架的通用性，他们可能根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射——运行时动态加载需要加载的对象。举一个例子，在运用Struts 2框架的开发中我们一般会在struts.xml里去配置Action，比如 1234&lt;action name=&quot;login&quot; class=&quot;org.ScZyhSoft.test.action.SimpleLoginAction&quot; method=&quot;execute&quot;&gt; &lt;result&gt;/shop/shop-index.jsp&lt;/result&gt; &lt;result name=&quot;error&quot;&gt;login.jsp&lt;/result&gt; &lt;/action&gt; 配置文件与Action建立了一种映射关系，当View层发出请求时，请求会被StrutsPrepareAndExecuteFilter拦截，然后StrutsPrepareAndExecuteFilter会去动态地创建Action实例。——比如我们请求login.action，那么StrutsPrepareAndExecuteFilter就会去解析struts.xml文件，检索action中name为login的Action，并根据class属性创建SimpleLoginAction实例，并用invoke方法来调用execute方法，这个过程离不开反射。对与框架开发人员来说，反射虽小但作用非常大，它是各种容器实现的核心。而对于一般的开发者来说，不深入框架开发则用反射用的就会少一点，不过了解一下框架的底层机制有助于丰富自己的编程思想，也是很有益的。 10.说说自定义注解的场景及实现场景：日志管理，缓存处理，权限验证等实现：在需要验证的地方增加一个切面，通过反射获取方法所包含的注解，比如包含自定义的注解，就进行相应的功能处理 11.HTTP请求的GET与POST方式的区别GET请求：请求参数会被拼接到URL后,可以拼接的长度受限制，而且如果有敏感信息 相对是不安全的POST请求: 为了克服GET请求的限制，post传递参数会被放入请求体中，可以发送的参数数目不受限制，因为外部不可见，因此相对安全 12.Session与Cookie区别session是基于服务端的会话管理，用于跟踪用户状态 这个数据可以保存在内存中，数据库中或者集群中cookie是基于客户端的会话管理,数据保存在客户端中 13.列出自己常用的JDK包java.util. java.io. 14.MVC设计思想MODEL模型用来封装业务逻辑，VIEW 视图用来实现表示逻辑，Controller 控制器用来协调模型与视图(视图要通过控制器来调用模型，模型返回的处理结果也要先交给控制器，由控制器来选择合适的视图来显示 处理结果)。这种设计思想 可以使各个层之间相互独立 又能相互协作，可以是业务逻辑与我们表现层视图进行解耦，有利于分工合作及快速开发 15.equals与==的区别equals和==的第一个区别就是 他们一个是方法，一个是运算符，它们比较的都是物理地址 而不是值得比较Java 语言里的 equals方法其实是交给开发者去覆写的，让开发者自己去定义满足什么条件的两个Object是equal的 由于String对象中重写了equals方法 当物理地址不同时，会进一步比较值，所以比较字符串时我们是用equals方法如果我们要重写一个对象比如Student的equals方法，必须要同时重写equals() 和hashcode()方法,因为只重写equals方法是无法改变hashcode值的 而比较时首先比较的就是hashcode，所以我们通常是在编辑器中 右键-&gt;source-&gt;generate hashcode() and equals() 来实现。 16.什么是Java序列化和反序列化，如何实现Java序列化？或者请解释Serializable 接口的作用 序列化：把对象转换为字节序列的过程 反序列化: 把字节序列转化为对象的过程对象序列化用途：1.将对象字节序列永久保存在硬盘上 通常保存在一个文件中2.在网络上传送对象的字节序列 java.io.ObjectOutputStream代表对象输出流，它的writeObject(Object obj)方法可对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中。 java.io.ObjectInputStream代表对象输入流，它的readObject()方法从一个源输入流中读取字节序列，再把它们反序列化为一个对象，并将其返回。 123ObjectOutputStream oo = new ObjectOutputStream(new FileOutputStream(new File("E:/Person.txt"))); oo.writeObject(person); System.out.println("Person对象序列化成功！"); 17.Object类中常见的方法，为什么wait notify会放在Object里边？简单说：因为synchronized中的这把锁可以是任意对象，所以任意对象都可以调用wait()和notify()；所以wait和notify属于Object。 专业说：因为这些方法在操作同步线程时，都必须要标识它们操作线程的锁，只有同一个锁上的被等待线程，可以被同一个锁上的notify唤醒，不可以对不同锁中的线程进行唤醒。也就是说，等待和唤醒必须是同一个锁。而锁可以是任意对象，所以可以被任意对象调用的方法是定义在object类中。 18.Java的平台无关性如何体现出来的 Java程序则编译为字节码。字节码本身不能运行，因为它不是原生代码。字节码只能够在Java虚拟机（JVM）上运行 JVM是一个原生应用程序，它负责解释字节码。通过使用JVM可用在众多的平台上（这也就是Java可以做到平台无关性的原因），Sun公司将Java变成了跨平台的语言。如下图模型，完全相同的字节码可以在已经开发了JVM的任何操作系统上运行 19.JDK和JRE的区别 JDK（Java Development Kit）JDK是整个JAVA的核心，包括了Java运行环境JRE（Java Runtime Envirnment）、一堆Java工具（javac/java/jdb等）和Java基础的类库 Java Runtime Environment（JRE）他就是java运行环境 并不是一个开发环境，所以没有包含任何开发工具 20.Java 8有哪些新特性 Lambda表达式和函数式接口,它允许我们将函数当成参数传递给某个方法 接口的默认方法（default修饰) 21.Java常见集合ArrayList,LinkedList,HashMap,HashTable,Set,HashSet,TreeSet 22.List 和 Set 区别 1.List,Set都实现了Collection接口 2.List它是一个有序的集合输出顺序就是插入顺序，可以允许插入重复对象，可以插入null元素，常用的实现有ArrayList,LinkedList,Vector 3.Set 是一一个无序的容器(存入和取出顺序不一定一致)，不允许插入重复对象,常用实现HashSet,LinkedHashSet,TreeSet 23.HashSet如何保证数据唯一性？HashSet底层数据接口是哈希表,怎样保证数据唯一性呢？它是通过HashCode和equals来完成的，如果元素的Hashcode值相同,才会判断equals是否为true,如果hashcode值不同，不会调用equals方法 在java的集合中，判断两个对象是否相等的规则是:判断两个对象的hashCode否相等 如果相等 就认为两个对象不相等，完毕 如果不相等，调用对象的equals()方法判断是否相等，如果不相等，认为两个对象也不相等 为什么要通过hashCode()和equlas()两条规则呢? 因为hashCode()相等时 equlas()也可能不相等，String,Double类都重写了hashCode()方法和equlas()方法，我们自己定义的对象也可以重写hashCode()和equlas()方法 24.List 和 Map 区别List是有顺序的集合，Map是通过键值对存取的容器,Key和Value一一对应Set,List都继承自Collection接口,List接口有三个实现类：ArrayList，Vector，LinkedListHashMap,HashTable实现了 Map&lt;E,V&gt;接口 25.Arraylist 与 LinkedList 区别ArrayList,LinkedList是List接口的两个实现类，他们都实现了List接口的方法,只是实现的方式不同 ArrayList它是以数组的方式来实现的,数组的特性是可以使用索引的方式来快速定位对象的位置,因此对于快速的随机取得对象的需求,使用ArrayList实现执行效率上会比较好LinkedList是采用链表的方式来实现List接口的,它本身有自己特定的方法，如: addFirst(),addLast(),getFirst(),removeFirst()等. 由于是采用链表实现的,因此在进行insert和remove动作时在效率上要比ArrayList要好得多!适合用来实现Stack(堆栈)与Queue(队列),前者先进后出，后者是先进先出. 26.在删除可插入对象的动作时，为什么ArrayList的效率会比较低呢?ArrayList是使用数组实现的,若要从数组中删除或插入某一个对象，需要移动后段的数组元素，从而会重新调整索引顺序,调整索引顺序会消耗一定的时间，所以速度上就会比LinkedList要慢许多. 相反,LinkedList是使用链表实现的,若要从链表中删除或插入某一个对象,只需要改变前后对象的引用即可 27.ArrayList 与 Vector 区别List接口有三个实现类：ArrayList，Vector，LinkedList1） Vector的方法都是同步的(Synchronized),是线程安全的(thread-safe)，而ArrayList的方法不是，由于线程的同步必然要影响性能，因此,ArrayList的性能比Vector好。2） 当Vector或ArrayList中的元素超过它的初始大小时,Vector会将它的容量翻倍,而ArrayList只增加50%的大小，这样,ArrayList就有利于节约内存空间。 28.HashMap 和 Hashtable 的区别1)HashMap线程不安全，HashTable线程安全，HashMap性能要好一点儿2)HashMap中key和value可以为null, HashTable中key和value都不能为null 29.HashSet 和 HashMap 区别1) HashSet实现了Set接口，它不允许集合中出现重复元素。当我们提到HashSet时，第一件事就是在将对象存储在 HashSet之前，要确保重写hashCode（）方法和equals（）方法，这样才能比较对象的值是否相等，确保集合中没有 储存相同的对象2) HashMap实现了Map接口 Map接口对键值对进行映射。HashMap中根据key来计算hashcode, HashSet中使用成员对象来计算HashCode,对于两个对象来说hashCode值可能相同，因此如果两个对象hashcode相同的情况下会继续调用equals()方法判断对象的相等性，相等返回true,否则返回false. 30. HashMap 和 ConcurrentHashMap 的区别1) ConcurrentHashMap是线程安全的 具体是怎么实现线程安全的呢，肯定不可能是每个方法加synchronized，那样就变成了HashTable。它引入了一个“分段锁”的概念，具体可以理解为把一个大的Map拆分成N个小的HashTable，根据key.hashCode()来决定把key放到哪个HashTable中 2）在ConcurrentHashMap中，就是把Map分成了N个Segment，put和get的时候，都是现根据key.hashCode()算出放到哪个Segment中 31.Java中native方法使用场景？1）在方法中调用一些不是由java语言写的代码。 2）在方法中用java语言直接操纵计算机硬件。 33.JVM运行时内存区域划分 1.程序计数器（线程私有）程序计数器 通常占用很小的一块儿内存, 它用于存放当前线程执行的字节码的行号指示器为什么需要程序计数器呢？因为java虚拟机中多线程是通过线程不断切换获得CPU执行时间进行的，为了处理器切换线程时能够回到之前所执行的位置, 每个线程都要有一个程序计数器,记录当前线程执行的字节码位置,所以是线程私有的. 2.java虚拟机栈(线程私有)虚拟机栈描述的是Java 方法执行的内存模型：每个方法被执 行的时候都会同时创建一个栈帧（Stack Frame ①）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 注意：1.局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用 两种异常1.StackOverflowError 如果线程申请的栈深度大于虚拟机允许的栈深度时，抛出这个错误2.OutOfMemoryError 当虚拟机栈扩展时 无法申请到足够的内存 就会抛出这个错误. 3.本地方法栈 (Native Method Stacks) 线程私有本地方法栈与虚拟机栈所发挥的作用是非常相似的,区别就是 虚拟机栈为执行的java方法服务，而本地方法栈为虚拟机使用到的Native方法(本地方法)服务 4.java堆（线程共享）Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的 唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存主要用来存放对象实例和数组，它是垃圾收集器管理的主要区域 5.方法区（非堆内存）Non-heap（线程共享）用于存储被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据根据Java 虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError 异常 运行时常量池运行时常量池是方法区的一部分，主要存储编译期生成的各种字面量和符号引用 JVM如何设置参数Linux下 在catalina.sh中设置如下参数JAVA_OPTS=”-Xms128m -Xmx512m -XX:PermSize=128m -XX:MaxPermSize=256m” Xms jvm初始分配的堆内存大小 Xmx jvm最大允许分配的堆内存，按需分配 XX:PermSize jvm初始分配的非堆内存大小 XX:MaxPermSize jvm最大允许分配的非堆内存 34.常见的设计模式35.设计模式的的六大原则及其含义（参考: https://www.cnblogs.com/dolphin0520/p/3919839.html） 单一职责原则 单一职责原则告诉我们：一个类不能太“累”！在软件系统中，一个类（大到模块，小到方法）承担的职责越多，它被复用的可能性就越小，而且一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离，将不同的职责封装在不同的类中，即将不同的变化原因封装在不同的类中，如果多个职责总是同时发生改变则可将它们封装在同一类中 开闭原则 一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展 里氏替换原则 里氏代换原则是实现开闭原则的重要方式之一，由于使用基类对象的地方都可以使用子类对象，因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象 依赖倒置原则 抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程 接口隔离原则 使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口 迪米特原则 一个软件实体应当尽可能少地与其他实体发生相互作用 如果一个系统符合迪米特法则，那么当其中某一个模块发生修改时，就会尽量少地影响其他模块，扩展会相对容易，这是对软件实体之间通信的限制，迪米特法则要求限制软件实体之间通信的宽度和深度。迪米特法则可降低系统的耦合度，使类与类之间保持松散的耦合关系。 36.常见的单例模式以及各种实现方式的优缺点，哪一种最好，手写常见的单利模式1234567public class Singleton &#123; private static final Singleton singleton = new Singleton(); private Singleton()&#123;&#125; public static synchronized Singleton getInstance()&#123; return singleton; &#125;&#125; 37.什么是长连接和短连接 HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。 IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠地传递数据包，使得网络上接收端收到发送端所发出的所有包，并且顺序与发送顺序一致。TCP协议是可靠的、面向连接的 在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。### 38.三次握手和四次挥手、为什么挥手需要四次参考博文: https://blog.csdn.net/qzcsu/article/details/72861891![Tcp三次握手示意图](http://pam1kb0ai.bkt.clouddn.com/tcp%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.png)第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。完成三次握手，客户端与服务器开始传送数据，在上述过程中，还有一些重要的概念：未连接队列在三次握手协议中，服务器维护一个未连接队列，该队列为每个客户端的SYN包（syn=j）开设一个条目，该条目表明服务器已收到SYN包，并向客户发出确认，正在等待客户的确认包。这些条目所标识的连接在服务器处于SYN_RECV状态，当服务器收到客户的确认包时，删除该条目，服务器进入ESTABLISHED状态。&gt; 问题1：为什么TCP客户端最后还要发送一次确认呢？ &gt; 一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。&gt; 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接---### TCP四次挥手![四次挥手](http://pam1kb0ai.bkt.clouddn.com/tcp%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png)&gt;数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于ESTABLISHED状态，然后客户端主动关闭，服务器被动关闭。对于一个已经建立的连接，TCP使用改进的三次握手来释放连接（使用一个带有FIN附加标记的报文段）。TCP关闭连接的步骤如下：第一步，当主机A的应用程序通知TCP数据已经发送完毕时，TCP向主机B发送一个带有FIN附加标记的报文段（FIN表示英文finish）。第二步，主机B收到这个FIN报文段之后，并不立即用FIN报文段回复主机A，而是先向主机A发送一个确认序号ACK，同时通知自己相应的应用程序：对方要求关闭连接（先发送ACK的目的是为了防止在这段时间内，对方重传FIN报文段）。第三步，主机B的应用程序告诉TCP：我要彻底的关闭连接，TCP向主机A送一个FIN报文段。第四步，主机A收到这个FIN报文段后，向主机B发送一个ACK表示连接彻底释放。### 为什么连接的时候是三次握手，关闭的时候却是四次握手？答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，&quot;你发的FIN报文我收到了&quot;。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。二、数据存储和消息队列### 39.MySQL 索引使用的注意事项 &gt; 索引只是提高效率的一个方式，如果mysql有大数据量的表，就要花时间研究建立最优的索引，或优化查询语句1. 索引不会包含有NULL的列 只要列中包含有NULL值，都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此符合索引就是无效的)2. 索引列排序 mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作，尽量不要包含多个列的排序，如果需要最好给这些列建复合索引3. like语句操作 一般情况下不鼓励使用like操作，如果非使用不可，注意正确的使用方式。like ‘%aaa%’不会使用索引，而like ‘aaa%’可以使用索引。4. 不要在列上进行运算5. 不使用NOT IN 、&lt;&gt;、！=操作，但&lt;,&lt;=，=，&gt;,&gt;=,BETWEEN,IN是可以用到索引的6. 索引要建立在经常进行select操作的字段上7. 索引要建立在值比较唯一的字段上8. 对于那些定义为text、image和bit数据类型的列不应该增加索引。因为这些列的数据量要么相当大，要么取值很少 9. 在where和join中出现的列需要建立索引10. where的查询条件里有不等号(where column != …),mysql将无法使用索引11. 如果where查询条件里使用了函数(如：where DAY(column)=…),mysql将无法使用索引 ### 40.索引类型 及如何创建索引，删除搜索引 索引类型: * UNIQUE(唯一索引) 不可出现相同的值,可以有null值 * INDEX(普通索引) 可以出现相同的值 * PROMARY KEY(主键索引) 不允许出现相同的值 * fulltext index(全文索引) 可以针对值中的某个单词，但效率不高 * 组合索引: 实质上是是将多个字段建到一个索引里，列值的组合必须唯一 创建索引: 创建表时同时创建索引 CREATE INDEX index_name ON table_name(username(length));2.创建表后创建索 //唯一索引 alter table table_name add unique (column_list); //主键索引 alter table table_name add primary key (column_list); 12 删除索引: drop index index_name on table_name; alter table table_name drop index index_name; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253### 40.DDL、DML、DCL分别指什么?* DDL:数据定义语言 DDL用来创建数据库中的各种对象-----表、视图 * DML:数据操纵语言 用于insert,update,delete* DCL:数据库控制语言 用来授予或回收访问数据库的某种特权，并控制数据库操纵事务发生的时间及效果### 41.数据库的几大范式 第一范式: 每一列属性都是不可再分的属性值，确保每一列的原子性 第二范式: 每一行的数据只能与其中一列相关，即一行数据只做一件事。只要数据列中出现数据重复，就要把表拆分开来 第三范式: 数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。像：a--&gt;b--&gt;c 属性之间含有这样的关系，是不符合第三范式的。 总结：三大范式只是一般设计数据库的基本理念，可以建立冗余较小、结构合理的数据库。如果有特殊情况，当然要特殊对待，数据库设计最重要的是看需求跟性能，需求&gt;性能&gt;表结构。所以不能一味的去追求范式建立数据库 ### 42.说说分库与分表设计&gt;分库分表基本思想:Sharding的基本思想就要把一个数据库切分成多个部分放到不同的数据库(server)上，从而缓解单一数据库的性能问题。不太严格的讲，对于海量数据的数据库，如果是因为表多而数据多，这时候适合使用垂直切分，即把关系紧密（比如同一模块）的表切分出来放在一个server上。如果表并不多，但每张表的数据非常多，这时候适合水平切分，即把表的数据按某种规则（比如按ID散列）切分到多个数据库(server)上。当然，现实中更多是这两种情况混杂在一起，这时候需要根据实际情况做出选择，也可能会综合使用垂直与水平切分，从而将原有数据库切分成类似矩阵一样可以无限扩充的数据库(server)阵列。 ### 43.说说 SQL 优化之道1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： `select id from t where num is null ` 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： `select id from t where num=0 ` 3.应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 4.应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： ```select id from t where num=10 or num=20``` 可以这样查询： ```select id from t where num=10``` union all ```select id from t where num=20``` 5.in 和 not in 也要慎用，否则会导致全表扫描，如： ```select id from t where num in(1,2,3)``` 对于连续的数值，能用 between 就不要用 in 了： ```select id from t where num between 1 and 3``` 6.下面的查询也将导致全表扫描： ```select id from t where name like &apos;%abc%&apos; 7.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： id from t where num/212应改为: ```select id from t where num=100*2 8.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where substring(name,1,3)=&#39;abc&#39; –name以abc开头的id应改为: select id from t where name like &#39;abc%&#39; 9.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 10.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 11.不要写一些没有意义的查询，如需要生成一个空表结构： select col1,col2 into #t from t where 1=0这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(...) 12.很多时候用 exists 代替 in 是一个好的选择： select num from a where num in(select num from b)用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 13.并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 14.索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 15.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 16.尽可能的使用 varchar 代替 char ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索，在一个相对较小的字段内搜索效率显效率显然要高些。 17.任何地方都不要使用 select from t ，用具体的字段列表代替“”，不要返回用不到的任何字段。 18.避免频繁创建和删除临时表，以减少系统表资源的消耗。 19.临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 20.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 21.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 22.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 23.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 24.与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 25.尽量避免大事务操作，提高系统并发能力。 26.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 44.MySQL遇到的死锁问题、如何排查与解决在数据库中有两种基本的锁类型：排它锁（Exclusive Locks，即X锁）和共享锁（Share Locks，即S锁）。当数据对象被加上排它锁时，其他的事务不能对它读取和修改。加了共享锁的数据对象可以被其他事务读取，但不能修改。数据库利用这两 种基本的锁类型来对数据库的事务进行并发控制。死锁的第一种情况 一个用户A 访问表A(锁住了表A),然后又访问表B；另一个用户B 访问表B(锁住了表B)，然后企图访问表A；这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了。 解决方法： 这种死锁比较常见，是由于程序的BUG产生的，除了调整的程序的逻辑没有其它的办法。仔细分析程序的逻辑，对于数据库的多表操作时，尽量按照相同的顺序进 行处理，尽量避免同时锁定两个资源，如操作A和B两张表时，总是按先A后B的顺序处理， 必须同时锁定两个资源时，要保证在任何时刻都应该按照相同的顺序来锁定资源。 死锁的第二种情况 用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户B里的独占锁由于A 有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升的独占锁也就不可能释放共享锁，于是出现了死锁。这种死锁比较隐蔽，但在稍大点的项 目中经常发生。如在某项目中，页面上的按钮点击后，没有使按钮立刻失效，使得用户会多次快速点击同一按钮，这样同一段代码对数据库同一条记录进行多次操 作，很容易就出现这种死锁的情况。 解决方法： 1、对于按钮等控件，点击后使其立刻失效，不让用户重复点击，避免对同时对同一条记录操作。2、使用乐观锁进行控制。乐观锁大多是基于数据版本（Version）记录机制实现。即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是 通过为数据库表增加一个“version”字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数 据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。乐观锁机制避免了长事务中的数据 库加锁开销（用户A和用户B操作过程中，都没有对数据库数据加锁），大大提升了大并发量下的系统整体性能表现。Hibernate 在其数据访问引擎中内置了乐观锁实现。需要注意的是，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户更新操作不受我们系统的控制，因此可能会造 成脏数据被更新到数据库中。3、使用悲观锁进行控制。悲观锁大多数情况下依靠数据库的锁机制实现，如Oracle的Select … for update语句，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。如一个金融系统， 当某个操作员读取用户的数据，并在读出的用户数据的基础上进行修改时（如更改用户账户余额），如果采用悲观锁机制，也就意味着整个操作过程中（从操作员读 出数据、开始修改直至提交修改结果的全过程，甚至还包括操作员中途去煮咖啡的时间），数据库记录始终处于加锁状态，可以想见，如果面对成百上千个并发，这 样的情况将导致灾难性的后果。所以，采用悲观锁进行控制时一定要考虑清楚。 死锁的第三种情况 如果在事务中执行了一条不满足条件的update语句，则执行全表扫描，把行级锁上升为表级锁，多个这样的事务执行后，就很容易产生死锁和阻塞。类似的情 况还有当表中的数据量非常庞大而索引建的过少或不合适的时候，使得经常发生全表扫描，最终应用系统会越来越慢，最终发生阻塞或死锁。 解决方法：SQL语句中不要使用太复杂的关联多表的查询；使用“执行计划”对SQL语句进行分析，对于有全表扫描的SQL语句，建立相应的索引进行优化。 5．小结总体上来说，产生内存溢出与锁表都是由于代码写的不好造成的，因此提高代码的质量是最根本的解决办法。有的人认为先把功能实现，有BUG时再在测试阶段进 行修正，这种想法是错误的。正如一件产品的质量是在生产制造的过程中决定的，而不是质量检测时决定的，软件的质量在设计与编码阶段就已经决定了，测试只是 对软件质量的一个验证，因为测试不可能找出软件中所有的BUG。 45.存储引擎的 InnoDB与MyISAM区别，优缺点，使用场景主要区别: * 1.MyISAM是非事务安全型的，而InnoDB是事务安全型的。 * 2.MyISAM是表级锁，而InnoDB是行级锁 * 3.MyISAM支持全文类型索引，而InnoDB不支持全文索引 MyISAM适合：(1)做很多count 的计算；(2)插入不频繁，查询非常频繁；(3)没有事务。InnoDB适合：(1)可靠性要求比较高，或者要求事务；(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况 46.limit 20000 加载很慢怎么解决`select * from table limit m,n` 其中m是指记录开始的index，表示每次开始的索引。默认从0开始，表示第一条记录n是指从第m+1条开始，取n条。 如：select * from tablename limit 2,4即取出第3条至第6条，4条记录 解决方法:当一个数据库表过于庞大，LIMIT offset, length中的offset值过大，则SQL查询语句会非常缓慢，你需增加order by，并且order by字段需要建立索引 47.常见的几种分布式ID的设计方案生成ID的方法有很多，适应不同的场景、需求以及性能要求。所以有些比较复杂的系统会有多个ID生成的策略。下面就介绍一些常见的ID生成策略 48.如何选择合适的分布式主键方案 数据库自增ID数据库自增长序列或字段，最常见的方式。由数据库维护，数据库唯一。 优点：简单，代码方便，性能可以接受。数字ID天然排序，对分页或者需要排序的结果很有帮助。缺点：不同数据库语法和实现不同，数据库迁移的时候或多数据库版本支持的时候需要处理。在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。在性能达不到要求的情况下，比较难于扩展。如果遇见多个系统需要合并或者涉及到数据迁移会相当痛苦。分表分库的时候会有麻烦。优化方案：针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。比如：Master1 生成的是 1，4，7，10，Master2生成的是2,5,8,11 Master3生成的是 3,6,9,12。这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。 UUID常见的方式,128位。可以利用数据库也可以利用程序生成，一般来说全球唯一。 优点：简单，代码方便。全球唯一，在遇见数据迁移，系统数据合并，或者数据库变更等情况下，可以从容应对。缺点：没有排序，无法保证趋势递增。UUID往往是使用字符串存储，查询的效率比较低。存储空间比较大，如果是海量数据库，就需要考虑存储量的问题。传输数据量大 不可读。 优化方案：为了解决UUID不可读，可以使用UUID to Int64的方法 GUIDGUID：是微软对UUID这个标准的实现。UUID还有其它各种实现，不止GUID一种。优缺点同UUID。 Redis49.Redis 有哪些数据类型，可参考《Redis常见的5种不同的数据类型详解》50.Redis 内部结构51.Redis 使用场景52.Redis 集群方案与实现53.Redis 为什么是单线程的？54.缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级55.使用缓存的合理性问题56.Redis常见的回收策略消息队列56.消息队列的使用场景57.消息的重发补偿解决思路58.消息的幂等性解决思路59.消息的堆积解决思路60.自己如何实现消息队列61.如何保证消息的有序性SSM/Servlet62.Servlet的生命周期在Servlet产生到消亡的过程中，有三个生命周期函数，初始化方法init(),处理客户请求的方法service(),终止方法destroy() init() 在一个Servlet的生命周期中，init方法只会被执行一次，之后无论用户执行多少次请求，都不会在调用该方法。 关于init方法的执行时机，有两种方式可选，一般的是在服务器启动后第一个用户请求改Servlet是调用，你也可以设置该Servlet在服务器启动后自动执行。 init方法负责简单的创建或者加载一些数据，这些数据将用于该Servlet的整个生命周期中 service方法 当一个客户请求改Servlet时，实际的处理工作全部有service方法来完成，service方法用来处理客户端的请求，并生成格式化数据返回给客户端。 每一次请求服务器都会开启一个新的线程并执行一次service方法，service根据客户端的请求类型，调用doGet、doPost等方法。 service是由web容器来调用的，我们无需对service具体内容做任何处理，service会自动的根据客户端的请求类型去调用doGet、doPost等方法，所以我们只需要做好doGet、doPost方法的实现就可以了。 destroy方法 该方法在整个生命周期中，也是只会被调用一次，在Servlet对象被销毁是调用，在servlet中，我们可以做一些资源的释放等操作，执行destory方法之后的servlet对象，会等待jvm虚拟机的垃圾回收机制择时回收。 63.转发与重定向的区别在servlet中转发的语句为： request.getRequestDispatcher(&quot;xxx.jsp&quot;).forward(request,response); 在servlet中重定向的语句为： request.sendRedirect(&quot;xxx.jsp&quot;); 转发的过程：客户端浏览器发送请求，web服务器接收请求再进行在内部跳转，什么意思呢，也就是说，跳转只能在自己所在的web容器下的url，而不能跳转出去其他的url。 重定向的过程：客户端发送请求，web服务器接收该请求后发送302状态码响应并且发送新的一个地址（location）给客户端浏览器，客户端接收到302则自动再发送一个新的请求，而这个请求就是新的location，既然是客户端发送的一个请求，就对web容器的request没关系了，它可以任意跳转到所有location。\其实它们最本质的区别就是，转发只需要一次的请求，仅仅是一次客户端的request，而重定向则需要两次请求，一次是客户端request，服务器响应后返回302给客户端浏览器，再由客户端浏览器再发一次请求。 64.BeanFactory 和 ApplicationContext 有什么区别BeanFactory：是spring中比较原始的Factory,是Spring里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能；原始的BeanFactory无法支持spring的许多插件，如AOP功能、Web应用等 ApplicationContext：应用上下文，继承BeanFactory接口，它是Spring的一各更高级的容器，提供了更多的有用的功能；ApplicationContext ctx = new ClassPathXmlAppliationContext(&quot;applicationContext.xml&quot;);1) 国际化（MessageSource） 2) 访问资源，如URL和文件（ResourceLoader） 3) 载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层 4) 消息发送、响应机制（ApplicationEventPublisher） 5) AOP（拦截器） 两者区别:BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化，这样，我们就不能发现一些存在的Spring的配置问题。而ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。 65.Spring Bean 的生命周期66.Spring IOC 如何实现Spring中Bean的作用域，默认的是哪一个说说 Spring AOP、Spring AOP 实现原理 动态代理（CGLib 与 JDK）、优缺点、性能对比、如何选择 Spring 事务实现方式、事务的传播机制、默认的事务类别 Spring 事务底层原理 Spring事务失效（事务嵌套），JDK动态代理给Spring事务埋下的坑，可参考《JDK动态代理给Spring事务埋下的坑！》 如何自定义注解实现功能 Spring MVC 运行流程 Spring MVC 启动流程 Spring 的单例实现原理 Spring 框架中用到了哪些设计模式 Spring 其他产品（Srping Boot、Spring Cloud、Spring Secuirity、Spring Data、Spring AMQP 等） 有没有用到Spring Boot，Spring Boot的认识、原理 MyBatis的原理 可参考《为什么会有Spring》 可参考《为什么会有Spring AOP》 分布式Session 分布式方案 Session 分布式处理 分布式锁的应用场景、分布式锁的产生原因、基本概念 分布是锁的常见解决方案 分布式事务的常见解决方案 集群与负载均衡的算法与实现 说说分库与分表设计，可参考《数据库分库分表策略的具体实现方案》 分库与分表带来的分布式困境与应对之策 4.3、Dubbo 什么是Dubbo，可参考《Dubbo入门》 什么是RPC、如何实现RPC、RPC 的实现原理，可参考《基于HTTP的RPC实现》 Dubbo中的SPI是什么概念 Dubbo的基本原理、执行流程 五、微服务 5.1、微服务 前后端分离是如何做的？ 微服务哪些框架 Spring Could的常见组件有哪些？可参考《Spring Cloud概述》 领域驱动有了解吗？什么是领域驱动模型？充血模型、贫血模型 JWT有了解吗，什么是JWT，可参考《前后端分离利器之JWT》https://blog.csdn.net/bntx2jsqfehy7/article/details/79224042 你怎么理解 RESTful 说说如何设计一个良好的 API 如何理解 RESTful API 的幂等性 如何保证接口的幂等性 微服务的优缺点，可参考《微服务批判》 微服务与 SOA 的区别 如何拆分服务、水平分割、垂直分割 如何应对微服务的链式调用异常 如何快速追踪与定位问题 如何保证微服务的安全、认证 5.2、安全问题如何防范常见的Web攻击、如何方式SQL注入 服务端通信安全攻防 HTTPS原理剖析、降级攻击、HTTP与HTTPS的对比]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows/mac下图床神器]]></title>
    <url>%2F2019%2F08%2F07%2F%E5%9B%BE%E5%BA%8A%E7%A5%9E%E5%99%A8%2F</url>
    <content type="text"><![CDATA[windows下图床神器价格: 免费平台: WINDOW官网: 图床神器MPIC MAC下图床神器价格: 免费(自定义图床需要购买高级版，RMB 58/年)平台: Mac官网: 图床神器 iPic | Toolinbox下载: AppStore 使用教程官网写得很详细了，点击这里 去官网看吧~]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>图床神器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云常用文档]]></title>
    <url>%2F2019%2F08%2F07%2F%E9%98%BF%E9%87%8C%E4%BA%91%E5%B8%B8%E7%94%A8%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[阿里云常用文档升级云盘后扩展分区阿里云升级云盘后,升级云盘后，默认是没有挂载的,需要进行一些配置才能够生效,针对windows和linux有不同的操作方式文档地址(https://help.aliyun.com/document_detail/111738.html?spm=a2c4g.11186623.6.768.64ba216c45ccBV)]]></content>
      <categories>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>阿里云文档</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么要使用spring?]]></title>
    <url>%2F2019%2F08%2F07%2F%E7%AC%AC%E4%B8%80%E7%AB%A0spring%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[spring是一个开源的应用框架,目的是帮我们简化企业级应用程序的开发,spring帮助我们创建对象，管理对象之间的依赖,spring还有框架粘合剂的作用，帮我们整合各种我们需要的框架如hibernate,mybatis，struts2等. Spring能帮我们做什么？ sping帮助我们通过配置文件或者注解创建对象，管理对象之间的依赖关系. spring的AOP（面向切面编程）帮我们无耦合的实现日志记录，权限控制，性能统计等功能 spring帮助我们管理数据库事物，获取连接，关闭连接的工作交由spring来完成 spring提供了第三方数据访问框架的无缝集成(hibernate,mybatis,JPA)SPRING-JDBCB本身还提供了一套jdbc访问模板 spring提供了第三方web框架的无缝集成(struts2,JSF),spring本身也提供了一套spring-mvc框架方便web层搭建 spring能够帮我们更好的与JAVA EE整合(JAVA MAIL,任务调度,缓存)等 如何学好要学好Spring，首先要明确Spring是个什么东西，能帮我们做些什么事情，知道了这些然后做个简单的例子，这样就基本知道怎么使用Spring了。Spring核心是IoC容器，所以一定要透彻理解什么是IoC容器，以及如何配置及使用容器，其他所有技术都是基于容器实现的；理解好IoC后，接下来是面向切面编程，首先还是明确概念，基本配置，最后是实现原理，接下来就是数据库事务管理，其实Spring管理事务是通过面向切面编程实现的，所以基础很重要，IoC容器和面向切面编程搞定后，其余都是基于这俩东西的实现，学起来就更加轻松了。要学好Spring不能急，一定要把基础打牢，基础牢固了，这就是磨刀不误砍柴工。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前后端工程师的目标]]></title>
    <url>%2F2019%2F08%2F07%2F%E5%89%8D%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E7%9B%AE%E6%A0%87%2F</url>
    <content type="text"><![CDATA[术业有专攻，前后端的发展都越来越高深，你想什么都会，那你毕竟什么都不精. JAVA后端工程师 把精力放在java基础，设计模式，jvm原理，spring+springmvc原理及源码，linux，mysql事务隔离与锁机制，mongodb，http/tcp，多线程，分布式架构（dubbo，dubbox，spring cloud），弹性计算架构，微服务架构（springboot+zookeeper+docker+jenkins），java性能优化，以及相关的项目管理 后端追求的是：三高（高并发，高可用，高性能），安全，存储，业务等等 * 前端工程师 把精力放在html5，css3，jquery，angularjs，bootstrap，reactjs，vuejs，webpack，less/sass，gulp，nodejs，Google V8引擎，javascript多线程，模块化，面向切面编程，设计模式，浏览器兼容性，性能优化等等。 前端追求的是：页面表现，速度流畅，兼容性，用户体验等等。]]></content>
      <categories>
        <category>全栈</category>
      </categories>
      <tags>
        <tag>计划</tag>
        <tag>目标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内网穿透端口映射网站]]></title>
    <url>%2F2019%2F08%2F07%2F%E5%87%A0%E4%B8%AA%E5%86%85%E7%BD%91%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E6%9C%8D%E5%8A%A1%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[目前在使用的 http://ngrok.io == http://ngrok.com http://natapp.cn/ http://ngrok.2bdata.com/ http://www.ngrok.cc/ http://www.nat123.com/ 路由侠 http://www.luyouxia.com/ WeNAT https://www.wezoz.com/ 目前使用的ngrok的穿透工具 （http://ngrok.io）登录账户: blog.nilaile.cn@gmail.com 安装: 解压ngrok安装程序 命令行进入ngrok目录,执行 1$ ngrok authtoken 你的token(注册账号成功后再access) 使用 命令行进入ngrok目录,执行以下命令即可1$ ngrok http 8086(你要绑定的本地端口号) ngrok还提供了了一个web统计页面访问 http://127.0.0.1:4041]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>内网映射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用nginx做反代时遇到413 Request Entity Too Large的解决方法]]></title>
    <url>%2F2019%2F08%2F07%2F%E4%BD%BF%E7%94%A8nginx%E5%81%9A%E5%8F%8D%E4%BB%A3%E6%97%B6%E9%81%87%E5%88%B0413-Request-Entity-Too-Large%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[https://www.cnblogs.com/jiaoyiping/p/5638096.html https://blog.csdn.net/qq_36949907/article/details/79182363 https://www.cnblogs.com/wanghx-0713/p/8080571.htmlMysql时间差函数SELECT TIMESTAMPDIFF(MONTH,’2009-10-01’,’2009-09-01’);interval可是：SECOND 秒 SECONDSMINUTE 分钟 MINUTESHOUR 时间 HOURSDAY 天 DAYSMONTH 月 MONTHSYEAR 年 YEARS]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里FastJson如何处理返回值中nulll值问题]]></title>
    <url>%2F2019%2F08%2F07%2F%E4%BD%BF%E7%94%A8FastJson%E5%85%A8%E5%B1%80%E5%A4%84%E7%90%86%E8%BF%94%E5%9B%9E%E5%80%BC%E4%B8%ADnulll%E5%80%BC%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[springBoot项目,全局处理策略 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Configurationpublic class HttpMessageConverterConfig &#123; @Bean public HttpMessageConverters fastJsonHttpMessageConverters() &#123; //1、定义一个convert转换消息的对象 FastJsonHttpMessageConverter fastConverter = new FastJsonHttpMessageConverter(); //2、添加fastjson的配置信息 FastJsonConfig fastJsonConfig = new FastJsonConfig(); SerializerFeature[] serializerFeatures = new SerializerFeature[]&#123; // 输出key是包含双引号 // SerializerFeature.QuoteFieldNames, // 是否输出为null的字段,若为null 则显示该字段 // SerializerFeature.WriteMapNullValue, // 数值字段如果为null，则输出为0 SerializerFeature.WriteNullNumberAsZero, // List字段如果为null,输出为[],而非null SerializerFeature.WriteNullListAsEmpty, // 字符类型字段如果为null,输出为&quot;&quot;,而非null SerializerFeature.WriteNullStringAsEmpty, // Boolean字段如果为null,输出为false,而非null SerializerFeature.WriteNullBooleanAsFalse, // Date的日期转换器 SerializerFeature.WriteDateUseDateFormat, // 循环引用 SerializerFeature.DisableCircularReferenceDetect, &#125;; fastJsonConfig.setSerializerFeatures(serializerFeatures); fastJsonConfig.setCharset(Charset.forName(&quot;UTF-8&quot;)); //3、在convert中添加配置信息 fastConverter.setFastJsonConfig(fastJsonConfig); //4、将convert添加到converters中 HttpMessageConverter&lt;?&gt; converter = fastConverter; return new HttpMessageConverters(converter); &#125;&#125; 作为工具方法 单独使用JSON.toJsonString转换对象为json字符串时用法 1234567891011121314151617181920SerializerFeature[] serializerFeatures = new SerializerFeature[]&#123; // 输出key是包含双引号 //SerializerFeature.QuoteFieldNames, // 是否输出为null的字段,若为null 则显示该字段 //SerializerFeature.WriteMapNullValue, // 数值字段如果为null，则输出为0 SerializerFeature.WriteNullNumberAsZero, // List字段如果为null,输出为[],而非null SerializerFeature.WriteNullListAsEmpty, // 字符类型字段如果为null,输出为&quot;&quot;,而非null SerializerFeature.WriteNullStringAsEmpty, // Boolean字段如果为null,输出为false,而非null SerializerFeature.WriteNullBooleanAsFalse, // Date的日期转换器 SerializerFeature.WriteDateUseDateFormat, // 循环引用 SerializerFeature.DisableCircularReferenceDetect&#125;; //重点在这里,这种设计真的挺灵活的String content = JSON.toJSONString(body,serializerFeatures);]]></content>
      <categories>
        <category>fastJson</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乡愁]]></title>
    <url>%2F2019%2F08%2F07%2F%E4%B9%A1%E6%84%81%2F</url>
    <content type="text"><![CDATA[有家的地方没有工作，有工作的地方没有家，他乡容不了灵魂，故乡安置不了肉身。从此便有了漂泊，有了远方,有了乡愁,有了无尽的牵挂]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>乡愁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javaweb项目为什么要前后端分离？为什么要解耦（转载）]]></title>
    <url>%2F2019%2F08%2F07%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[前言 前后端分离已成为互联网项目开发的业界标准使用方式，通过nginx+tomcat的方式（也可以中间加一个nodejs）有效的进行解耦，并且前后端分离会为以后的大型分布式架构、弹性计算架构、微服务架构、多端化服务（多种客户端，例如：浏览器，车载终端，安卓，IOS等等）打下坚实的基础。这个步骤是系统架构从猿进化成人的必经之路。 核心思想是前端html页面通过ajax调用后端的restuful api接口并使用json数据进行交互。 （名词解释：在互联网架构中，web服务器：一般指像nginx，apache这类的服务器，他们一般只能解析静态资源。应用服务器：一般指像tomcat，jetty，resin这类的服务器可以解析动态资源也可以解析静态资源，但解析静态资源的能力没有web服务器好。 一般都是只有web服务器才能被外网访问，应用服务器只能内网访问。）术业有专攻（开发人员分离） 以前的JavaWeb项目大多数都是java程序员又当爹又当妈，又搞前端（ajax/jquery/js/html/css等等），又搞后端（java/mysql/oracle等等）。 随着时代的发展，渐渐的许多大中小公司开始把前后端的界限分的越来越明确，前端工程师只管前端的事情，后端工程师只管后端的事情。正所谓术业有专攻，一个人如果什么都会，那么他毕竟什么都不精。 大中型公司需要专业人才，小公司需要全才，但是对于个人职业发展来说，我建议是分开。 对于后端java工程师：把精力放在java基础，设计模式，jvm原理，spring+springmvc原理及源码，linux，mysql事务隔离与锁机制，mongodb，http/tcp，多线程，分布式架构（dubbo，dubbox，spring cloud），弹性计算架构，微服务架构（springboot+zookeeper+docker+jenkins），java性能优化，以及相关的项目管理等等。后端追求的是：三高（高并发，高可用，高性能），安全，存储，业务等等。 对于前端工程师：把精力放在html5，css3，jquery，angularjs，bootstrap，reactjs，vuejs，webpack，less/sass，gulp，nodejs，Google V8引擎，javascript多线程，模块化，面向切面编程，设计模式，浏览器兼容性，性能优化等等。前端追求的是：页面表现，速度流畅，兼容性，用户体验等等。 偏头痛杨原创文章，禁止转载，版权必究。 术业有专攻，这样你的核心竞争力才会越来越高，正所谓你往生活中投入什么，生活就会反馈给你什么。并且两端的发展都越来越高深，你想什么都会，那你毕竟什么都不精。 通过将team分成前后端team，让两边的工程师更加专注各自的领域，独立治理，然后构建出一个全栈式的精益求精的team。原始人时代（各种耦合） 几曾何时，我们的JavaWeb项目都是使用了若干后台框架，springmvc/struts + spring + spring jdbc/hibernate/mybatis 等等。 大多数项目在java后端都是分了三层，控制层（controller/action），业务层（service/manage），持久层（dao）。控制层负责接收参数，调用相关业务层，封装数据，以及路由&amp;渲染到jsp页面。然后jsp页面上使用各种标签（jstl/el/struts标签等）或者手写java表达式（&lt;%=%&gt;）将后台的数据展现出来，玩的是MVC那套思路。 我们先看这种情况：需求定完了，代码写完了，测试测完了，然后呢？要发布了吧？你需要用maven或者eclipse等工具把你的代码打成一个war包，然后把这个war包发布到你的生产环境下的web容器（tomcat/jboss/weblogic/websphere/jetty/resin）里，对吧？ 发布完了之后，你要启动你的web容器，开始提供服务，这时候你通过配置域名，dns等等相关，你的网站就可以访问了（假设你是个网站）。那我们来看，你的前后端代码是不是全都在那个war包里？包括你的js，css，图片，各种第三方的库，对吧？ 好，下面在浏览器中输入你的网站域名（www.xxx.com），之后发生了什么？（这个问题也是很多公司的面试题）我捡干的说了啊，基础不好的童鞋请自己去搜。 浏览器在通过域名通过dns服务器找到你的服务器外网ip,将http请求发送到你的服务器，在tcp 3次握手之后（http下面是tcp/ip），通过tcp协议开始传输数据，你的服务器得到请求后，开始提供服务，接收参数，之后返回你的应答给浏览器，浏览器再通过content-type来解析你返回的内容，呈现给用户。 那么我们来看，我们先假设你的首页中有100张图片，此时，用户的看似一次http请求，其实并不是一次，用户在第一次访问的时候，浏览器中不会有缓存，你的100张图片，浏览器要连着请求100次http请求（有人会跟我说http长连短连的问题，不在这里讨论），你的服务器接收这些请求，都需要耗费内存去创建socket来玩tcp传输（消耗你服务器上的计算资源）。 偏头痛杨原创文章，禁止转载，版权必究。 重点来了，这样的话，你的服务器的压力会非常大，因为页面中的所有请求都是只请求到你这台服务器上，如果1个人还好，如果10000个人并发访问呢（先不聊服务器集群，这里就说是单实例服务器），那你的服务器能扛住多少个tcp连接？你的带宽有多大？你的服务器的内存有多大？你的硬盘是高性能的吗？你能抗住多少IO？你给web服务器分的内存有多大？会不会宕机？ 这就是为什么，越是大中型的web应用，他们越是要解耦。理论上你可以把你的数据库+应用服务+消息队列+缓存+用户上传的文件+日志+等等都扔在一台服务器上，你也不用玩什么服务治理，也不用做什么性能监控，什么报警机制等等，就乱成一锅粥好了。但是这样就好像是你把鸡蛋都放在一个篮子里，隐患非常大。如果因为一个子应用的内存不稳定导致整个服务器内存溢出而hung住，那你的整个网站就挂掉了。 如果出意外挂掉，而恰好这时你们的业务又处于井喷式发展高峰期，那么恭喜你，业务成功被技术卡住，很可能会流失大量用户，后果不堪设想。注意：技术一定是要走在业务前面的，否则你将错过最佳的发展期哟，亲~ 此外，你的应用全部都耦合在一起，相当于一个巨石，当服务端负载能力不足时，一般会使用负载均衡的方式，将服务器做成集群，这样其实你是在水平扩展一块块巨石，性能加速度会越来越低，要知道，本身负载就低的功能or模块是没有必要水平扩展的，在本文中的例子就是你的性能瓶颈不在前端，那干嘛要水平扩展前端呢？？？还有发版部署上线的时候，我明明只改了后端的代码，为什么要前端也跟着发布呢？？？（引用：《架构探险-轻量级微服务架构》，黄勇） 正常的互联网架构，是都要拆开的，你的web服务器集群，你的应用服务器集群+文件服务器集群+数据库服务器集群+消息队列集群+缓存集群等等。JSP的痛点 以前的javaWeb项目大多数使用jsp作为页面层展示数据给用户，因为流量不高，因此也没有那么苛刻的性能要求，但现在是大数据时代，对于互联网项目的性能要求是越来越高，因此原始的前后端耦合在一起的架构模式已经逐渐不能满足我们，因此我们需要需找一种解耦的方式，来大幅度提升我们的负载能力。 1.动态资源和静态资源全部耦合在一起，服务器压力大，因为服务器会收到各种http请求，例如css的http请求，js的，图片的等等。一旦服务器出现状况，前后台一起玩完，用户体验极差。 2.UI出好设计图后，前端工程师只负责将设计图切成html，需要由java工程师来将html套成jsp页面，出错率较高（因为页面中经常会出现大量的js代码），修改问题时需要双方协同开发，效率低下。 3.jsp必须要在支持java的web服务器里运行（例如tomcat，jetty，resin等），无法使用nginx等（nginx据说单实例http并发高达5w，这个优势要用上），性能提不上来。 4.第一次请求jsp，必须要在web服务器中编译成servlet，第一次运行会较慢。 5.每次请求jsp都是访问servlet再用输出流输出的html页面，效率没有直接使用html高（是每次哟，亲~）。 6.jsp内有较多标签和表达式，前端工程师在修改页面时会捉襟见肘，遇到很多痛点。 7.如果jsp中的内容很多，页面响应会很慢，因为是同步加载。 8.需要前端工程师使用java的ide（例如eclipse），以及需要配置各种后端的开发环境，你们有考虑过前端工程师的感受吗。 基于上述的一些痛点，我们应该把整个项目的开发权重往前移，实现前后端真正的解耦！偏头痛杨原创文章，禁止转载，版权必究。开发模式 以前老的方式是：1.产品经历/领导/客户提出需求2.UI做出设计图3.前端工程师做html页面4.后端工程师将html页面套成jsp页面（前后端强依赖，后端必须要等前端的html做好才能套jsp。如果html发生变更，就更痛了，开发效率低）5.集成出现问题6.前端返工7.后端返工8.二次集成9.集成成功10.交付 新的方式是：1.产品经历/领导/客户提出需求2.UI做出设计图3.前后端约定接口&amp;数据&amp;参数4.前后端并行开发（无强依赖，可前后端并行开发，如果需求变更，只要接口&amp;参数不变，就不用两边都修改代码，开发效率高）5.前后端集成6.前端页面调整7.集成成功8.交付 请求方式 以前老的方式是：1.客户端请求2.服务端的servlet或controller接收请求（后端控制路由与渲染页面，整个项目开发的权重大部分在后端）3.调用service,dao代码完成业务逻辑4.返回jsp5.jsp展现一些动态的代码 新的方式是：1.浏览器发送请求2.直接到达html页面（前端控制路由与渲染页面，整个项目开发的权重前移）3.html页面负责调用服务端接口产生数据（通过ajax等等，后台返回json格式数据，json数据格式因为简洁高效而取代xml）4.填充html，展现动态效果，在页面上进行解析并操作DOM。（有兴趣的童鞋可以访问一下阿里巴巴等大型网站，然后按一下F12，监控一下你刷新一次页面，他的http是怎么玩的，大多数都是单独请求后台数据，使用json传输数据，而不是一个大而全的http请求把整个页面包括动+静全部返回过来） 偏头痛杨原创文章，禁止转载，版权必究。总结一下新的方式的请求步骤：大量并发浏览器请求—&gt;web服务器集群(nginx)—&gt;应用服务器集群(tomcat)—&gt;文件/数据库/缓存/消息队列服务器集群同时又可以玩分模块，还可以按业务拆成一个个的小集群，为后面的架构升级做准备。 前后分离的优势 1.可以实现真正的前后端解耦，前端服务器使用nginx。前端/WEB服务器放的是css，js，图片等等一系列静态资源（甚至你还可以css，js，图片等资源放到特定的文件服务器，例如阿里云的oss，并使用cdn加速），前端服务器负责控制页面引用&amp;跳转&amp;路由，前端页面异步调用后端的接口，后端/应用服务器使用tomcat（把tomcat想象成一个数据提供者），加快整体响应速度。（这里需要使用一些前端工程化的框架比如nodejs，react，router，react，redux，webpack） 2.发现bug，可以快速定位是谁的问题，不会出现互相踢皮球的现象。页面逻辑，跳转错误，浏览器兼容性问题，脚本错误，页面样式等问题，全部由前端工程师来负责。接口数据出错，数据没有提交成功，应答超时等问题，全部由后端工程师来解决。双方互不干扰，前端与后端是相亲相爱的一家人。 3.在大并发情况下，我可以同时水平扩展前后端服务器，比如淘宝的一个首页就需要2000+台前端服务器做集群来抗住日均多少亿+的日均pv。（去参加阿里的技术峰会，听他们说他们的web容器都是自己写的，就算他单实例抗10万http并发，2000台是2亿http并发，并且他们还可以根据预知洪峰来无限拓展，很恐怖，就一个首页。。。） 4.减少后端服务器的并发/负载压力除了接口以外的其他所有http请求全部转移到前端nginx上，接口的请求调用tomcat，参考nginx反向代理tomcat。且除了第一次页面请求外，浏览器会大量调用本地缓存。 5.即使后端服务暂时超时或者宕机了，前端页面也会正常访问，只不过数据刷不出来而已。 6.也许你也需要有微信相关的轻应用，那样你的接口完全可以共用，如果也有app相关的服务，那么只要通过一些代码重构，也可以大量复用接口，提升效率。（多端应用） 7.页面显示的东西再多也不怕，因为是异步加载。 8.nginx支持页面热部署，不用重启服务器，前端升级更无缝。 9.增加代码的维护性&amp;易读性（前后端耦在一起的代码读起来相当费劲）。 10.提升开发效率，因为可以前后端并行开发，而不是像以前的强依赖。 11.在nginx中部署证书，外网使用https访问，并且只开放443和80端口，其他端口一律关闭（防止黑客端口扫描），内网使用http，性能和安全都有保障。 12.前端大量的组件代码得以复用，组件化，提升开发效率，抽出来！注意事项 1.在开需求会议的时候，前后端工程师必须全部参加，并且需要制定好接口文档，后端工程师要写好测试用例（2个维度），不要让前端工程师充当你的专职测试，推荐使用chrome的插件postman或soapui或jmeter，service层的测试用例拿junit写。ps：前端也可以玩单元测试吗？ 2.上述的接口并不是java里的interface，说白了调用接口就是调用你controler里的方法。 3.加重了前端团队的工作量，减轻了后端团队的工作量，提高了性能和可扩展性。 4.我们需要一些前端的框架来解决类似于页面嵌套，分页，页面跳转控制等功能。（上面提到的那些前端框架）。 5.如果你的项目很小，或者是一个单纯的内网项目，那你大可放心，不用任何架构而言，但是如果你的项目是外网项目，呵呵哒。 6.以前还有人在使用类似于velocity/freemarker等模板框架来生成静态页面，仁者见仁智者见智。 7.这篇文章主要的目的是说jsp在大型外网java web项目中被淘汰掉，可没说jsp可以完全不学，对于一些学生朋友来说，jsp/servlet等相关的java web基础还是要掌握牢的，不然你以为springmvc这种框架是基于什么来写的？ 8.如果页面上有一些权限等等相关的校验，那么这些相关的数据也可以通过ajax从接口里拿。 9.对于既可以前端做也可以后端做的逻辑，我建议是放到前端，为什么？因为你的逻辑需要计算资源进行计算，如果放到后端去run逻辑，则会消耗带宽&amp;内存&amp;cpu等等计算资源，你要记住一点就是服务端的计算资源是有限的，而如果放到前端，使用的是客户端的计算资源，这样你的服务端负载就会下降（高并发场景）。类似于数据校验这种，前后端都需要做！ 10.前端需要有机制应对后端请求超时以及后端服务宕机的情况，友好的展示给用户。 扩展阅读 1.其实对于js，css，图片这类的静态资源可以考虑放到类似于阿里云的oss这类文件服务器上（如果是普通的服务器&amp;操作系统，存储在到达pb级的文件后，或者单个文件夹内的文件数量达到3-5万，io会有很严重的性能问题），再在oss上配cdn（全国子节点加速），这样你页面打开的速度像飞一样， 无论你在全国的哪个地方，并且你的nginx的负载会进一步降低。 2.如果你要玩轻量级微服务架构，要使用nodejs做网关，用nodejs的好处还有利于seo优化，因为nginx只是向浏览器返回页面静态资源，而国内的搜索引擎爬虫只会抓取静态数据，不会解析页面中的js，这使得应用得不到良好的搜索引擎支持。同时因为nginx不会进行页面的组装渲染，需要把静态页面返回到浏览器，然后完成渲染工作，这加重了浏览器的渲染负担。浏览器发起的请求经过nginx进行分发，URL请求统一分发到nodejs，在nodejs中进行页面组装渲染；API请求则直接发送到后端服务器，完成响应。 3.如果遇到跨域问题，spring4的CORS可以完美解决，但一般使用nginx反向代理都不会有跨域问题，除非你把前端服务和后端服务分成两个域名。JSONP的方式也被淘汰掉了。 4.如果想玩多端应用，注意要去掉tomcat原生的session机制，要使用token机制，使用缓存（因为是分布式系统），做单点，对于token机制的安全性问题，可以搜一下jwt。 5.前端项目中可以加入mock测试（构造虚拟测试对象来模拟后端，可以独立开发和测试），后端需要有详细的测试用例，保证服务的可用性与稳定性。总结 前后端分离并非仅仅只是一种开发模式，而是一种架构模式（前后端分离架构）。千万不要以为只有在撸代码的时候把前端和后端分开就是前后端分离了。需要区分前后端项目前端项目与后端项目是两个项目，放在两个不同的服务器，需要独立部署，两个不同的工程，两个不同的代码库，不同的开发人员。前后端工程师需要约定交互接口，实现并行开发，开发结束后需要进行独立部署，前端通过ajax来调用http请求调用后端的restful api。前端只需要关注页面的样式与动态数据的解析&amp;渲染，而后端专注于具体业务逻辑。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>系统架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows安装Nginx]]></title>
    <url>%2F2019%2F08%2F07%2Fwindows%E5%AE%89%E8%A3%85nginx%2F</url>
    <content type="text"><![CDATA[1. 官方下载NGINX download2.解压运行1234cd c:\unzip nginx-1.12.2.zipcd nginx-1.12.2start nginx 3. 命令行查看命令行运行 tasklist 可以看到nginx的两个进程 123456C:\nginx-1.12.2&gt;tasklist /fi &quot;imagename eq nginx.exe&quot; Image Name PID Session Name Session# Mem Usage=============== ======== ============== ========== ============ nginx.exe 652 Console 0 2 780 K nginx.exe 1332 Console 0 3 112 K 有两个进程,一个进程是master进程 另一个是worker进程, 如果进程没有启动成功，可以查看日志文件 logs\error.log Nginx常用命令 命令 Model start nginx 启动 nginx -s stop 迅速退出 nginx -s quit 优雅的退出 nginx -s reload 修改配置文件后重载]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>NGINX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows基于NGINX配置HTTPS证书]]></title>
    <url>%2F2019%2F08%2F07%2Fwindows%E9%85%8D%E7%BD%AEhttps%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[下载解压nginx的windows版本 （笔者使用的版本是nginx-1.12.2版)官方下载链接具体 从阿里云获取那个免费的HTTPS证书 Nginx的config路径下创建cert文件夹，将证书解压到该目录下，证书一般是两个文件，分别是**.key和 ***.pem 修改配置文件如下 1234567891011121314151617181920212223242526272829303132333435363738394041server &#123; listen 443; server_name localhost; ssl on; ssl_certificate cert/2195340_www.baidu.com.pem; #替换为自己的证书文件 ssl_certificate_key cert/2195340_www.baidu.com.key;#替换为自己的证书文件 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; root D:/nginx-1.12.2/html; index index.html index.htm; try_files $uri $uri/ @router; &#125; location /admin &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8083/admin; &#125;&#125; server &#123; listen 80; server_name www.nilaile.com nilaile.com; #这里改为自己的域名,多个域名空格分开 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; rewrite ^(.*)$ https://$&#123;server_name&#125;$1 permanent; &#125;]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>NGINX</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F08%2F07%2Fswaggr%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[/** swagger使用规范 之所以设定规范是为了能够让swagger被正确运用以便达到替代传统接口文档和解决传统文档的痛点的两个目的. * 传统接口文档中对于每个请求参数都有详细的描述, 前端对于多数请求参数都能准确理解, 但是在编写这份使用规范前swagger未被正确运用 已造成前端无法准确理解请求参数的含义,增加了不必要的沟通成本. * 传统接口文档对于每个模块之间的分类很明确, 前端能够快速查找到对应模块的接口文档, 但是在编写这份使用规范前swagger未被正确运用 导致每个模块名称仅被描述为”xxx-controller”,前端无法快速查找到对应模块的接口文档同时也增加了不必要的沟通成本. 传统接口文档对于请求响应都有code来表明当前请求的状况, 可根据对应的code来完成相应操作, 但是在编写这份使用规范前swagger未被正确运用, 导致前端无法准确理解目前所使用的Http code所代表的含义, 从而增加了不必要的沟通成本. * 为了解决以上三个存在的问题从而达到易维护和消除不必要的沟通成本的目的, 请各位同事严格遵守以下规范. 若有不同的想法,欢迎提出讨论并完善该规范. * 1.controller中对于path及form类型参数的使用规范 请查看示例{@link com.hikedu.backend.swaggerexample.ExampleController#pathAndFormParamsStandard(String)} * 2.controller中对于code的使用及描述规范 使用Http code并通过注解@ApiResponse来完成描述, 并根据对应的情况在ResponseEntity对象中返回. 请查看示例中的@Responses注解的用法 {@link com.hikedu.backend.swaggerexample.ExampleController#pathAndFormParamsStandard(String)} * 3.禁止直接使用Model来作为controller的接收参数, 而是创建对应的DTO来接收参数. 之所以禁止是因为如下几个原因: 1.model的意义是在controller、service、dao、View层来传递数据, 所以尽量保证model功能的单一, 以避免产生不必要的复杂度. 2.使用model因为存在诸如createdAt, updatedAt等不必要的字段并不适合作为controller的入参. 3.model因其本身的意义不能添加太多和model功能不相干的属性以达到使用model作为controller参数的目的. 因此有必要创建DTO来作为controller的参数. 使用详见{@link com.hikedu.backend.model.dto.ExampleDTO} * 4.controller中对于使用对象接收参数的使用规范 在当前规范未实施前, 所有的以对象接收的参数的字段含义对于前端来讲是模糊不清的. 因此有必要对对象中的每个属性做描述,以便前端能够理解参数的含义. 示例见{@link com.hikedu.backend.model.dto.ExampleDTO}中的参数注解 和{@link com.hikedu.backend.swaggerexample.ExampleController#objectParamsStandard(ExampleDTO)} * 5.响应的model数据添加说明 未实施当前规范前, 所有的响应数据均没有说明, 前端无法理解响应数据中参数的含义, 因此有必要在响应的model中为每个参数添加说明 示例见如下两处 {@link com.hikedu.backend.model.dto.ExampleResponseDataDTO} {@link ExampleController#responseDataStandard()} * @author himly z1399956473@gamil.com 2018.8.20 */]]></content>
  </entry>
  <entry>
    <title><![CDATA[next主题配置文件]]></title>
    <url>%2F2019%2F08%2F07%2Fnext%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813# ===============================================================# ========================= ATTENTION! ==========================# ===============================================================# NexT repository is moving here: https://github.com/theme-next# ===============================================================# It&apos;s rebase to v6.0.0 and future maintenance will resume there# ===============================================================# ---------------------------------------------------------------# Theme Core Configuration Settings# ---------------------------------------------------------------# Set to true, if you want to fully override the default configuration.# Useful if you don&apos;t want to inherit the theme _config.yml configurations.override: false# ---------------------------------------------------------------# Site Information Settings# ---------------------------------------------------------------# To get or check favicons visit: https://realfavicongenerator.net# Put your favicons into `hexo-site/source/` (recommend) or `hexo-site/themes/next/source/images/` directory.# Default NexT favicons placed in `hexo-site/themes/next/source/images/` directory.# And if you want to place your icons in `hexo-site/source/` root directory, you must remove `/images` prefix from pathes.# For example, you put your favicons into `hexo-site/source/images` directory.# Then need to rename &amp; redefine they on any other names, otherwise icons from Next will rewrite your custom icons in Hexo.favicon: small: /images/favicon-16x16-next.png medium: /images/favicon-32x32-next.png apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xml# Set default keywords (Use a comma to separate)keywords: &quot;Hexo, NexT&quot;# Set rss to false to disable feed link.# Leave rss as empty to use site&apos;s feed link.# Set rss to specific value if you have burned your feed already.rss:footer: # Specify the date when the site was setup. # If not defined, current year will be used. #since: 2015 # Icon between year and copyright info. icon: user # If not defined, will be used `author` from Hexo main config. copyright: # ------------------------------------------------------------- # Hexo link (Powered by Hexo). powered: true theme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: true # Version info of NexT after scheme info (vX.X.X). version: true # ------------------------------------------------------------- # Any custom text can be defined here. #custom_text: Hosted by &lt;a target=&quot;_blank&quot; href=&quot;https://pages.github.com&quot;&gt;GitHub Pages&lt;/a&gt;# ---------------------------------------------------------------# SEO Settings# ---------------------------------------------------------------# Canonical, set a canonical link tag in your hexo, you could use it for your SEO of blog.# See: https://support.google.com/webmasters/answer/139066# Tips: Before you open this tag, remember set up your URL in hexo _config.yml ( ex. url: http://yourdomain.com )canonical: true# Change headers hierarchy on site-subtitle (will be main site description) and on all post/pages titles for better SEO-optimization.seo: false# If true, will add site-subtitle to index page, added in main hexo config.# subtitle: Subtitleindex_with_subtitle: false# ---------------------------------------------------------------# Menu Settings# ---------------------------------------------------------------# When running the site in a subdirectory (e.g. domain.tld/blog), remove the leading slash from link value (/archives -&gt; archives).# Usage: `Key: /link/ || icon`# Key is the name of menu item. If translate for this menu will find in languages - this translate will be loaded; if not - Key name will be used. Key is case-senstive.# Value before `||` delimeter is the target link.# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, question icon will be loaded.menu: home: / || home #about: /about/ || user tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap commonweal: /404.html || heartbeat# Enable/Disable menu icons.menu_icons: enable: true# ---------------------------------------------------------------# Scheme Settings# ---------------------------------------------------------------# Schemes#scheme: Musescheme: Mist#scheme: Pisces#scheme: Gemini# ---------------------------------------------------------------# Sidebar Settings# ---------------------------------------------------------------# Social Links.# Usage: `Key: permalink || icon`# Key is the link label showing to end users.# Value before `||` delimeter is the target permalink.# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, globe icon will be loaded.social: GitHub: https://github.com/godloveyou || github E-Mail: mailto:823939100@gmail.com || envelope #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skypesocial_icons: enable: true icons_only: false transition: false# Blog rollslinks_icon: linklinks_title: Linkslinks_layout: block#links_layout: inline#links: #Title: http://example.com/# Sidebar Avatar# in theme directory(source/images): /images/avatar.gif# in site directory(source/uploads): /uploads/avatar.gifavatar: /images/author.png# Table Of Contents in the Sidebartoc: enable: true # Automatically add list number to toc. number: true # If true, all words will placed on next lines if header width longer then sidebar width. wrap: false# Creative Commons 4.0 International License.# http://creativecommons.org/# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero#creative_commons: by-nc-sa#creative_commons:sidebar: # Sidebar Position, available value: left | right (only for Pisces | Gemini). position: left #position: right # Sidebar Display, available value (only for Muse | Mist): # - post expand on posts automatically. Default. # - always expand for all pages automatically # - hide expand only when click on the sidebar toggle icon. # - remove Totally remove sidebar including sidebar toggle. display: post #display: always #display: hide #display: remove # Sidebar offset from top menubar in pixels (only for Pisces | Gemini). offset: 12 # Back to top in sidebar (only for Pisces | Gemini). b2t: false # Scroll percent label in b2t button. scrollpercent: false # Enable sidebar on narrow view (only for Muse | Mist). onmobile: false# ---------------------------------------------------------------# Post Settings# ---------------------------------------------------------------# Automatically scroll page to section which is under &lt;!-- more --&gt; mark.scroll_to_more: true# Automatically saving scroll position on each post/page in cookies.save_scroll: false# Automatically excerpt description in homepage as preamble text.excerpt_description: true# Automatically Excerpt. Not recommend.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: false length: 150# Post meta display settingspost_meta: item_text: true created_at: true updated_at: false categories: true# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: false min2read: false totalcount: false separated_meta: true# Wechat Subscriber#wechat_subscriber: #enabled: true #qcode: /path/to/your/wechatqcode ex. /uploads/wechat-qcode.jpg #description: ex. subscribe to my blog by scanning my public wechat account# Reward#reward_comment: Donate comment here#wechatpay: /images/wechatpay.jpg#alipay: /images/alipay.jpg#bitcoin: /images/bitcoin.png# Declare license on postspost_copyright: enable: false license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/# ---------------------------------------------------------------# Misc Theme Settings# ---------------------------------------------------------------# Reduce padding / margin indents on devices with narrow width.mobile_layout_economy: false# Android Chrome header panel color ($black-deep).android_chrome_color: &quot;#222&quot;# Custom Logo.# !!Only available for Default Scheme currently.# Options:# enabled: [true/false] - Replace with specific image# image: url-of-image - Images&apos;s urlcustom_logo: enabled: false image:# Code Highlight theme# Available value:# normal | night | night eighties | night blue | night bright# https://github.com/chriskempson/tomorrow-themehighlight_theme: normal# ---------------------------------------------------------------# Font Settings# - Find fonts on Google Fonts (https://www.google.com/fonts)# - All fonts set here will have the following styles:# light, light italic, normal, normal italic, bold, bold italic# - Be aware that setting too much fonts will cause site running slowly# - Introduce in 5.0.1# ---------------------------------------------------------------# CAUTION! Safari Version 10.1.2 bug: https://github.com/iissnan/hexo-theme-next/issues/1844# To avoid space between header and sidebar in Pisces / Gemini themes recommended to use Web Safe fonts for `global` (and `logo`):# Arial | Tahoma | Helvetica | Times New Roman | Courier New | Verdana | Georgia | Palatino | Garamond | Comic Sans MS | Trebuchet MS# ---------------------------------------------------------------font: enable: false # Uri of fonts host. E.g. //fonts.googleapis.com (Default). host: # Font options: # `external: true` will load this font family from `host` above. # `family: Times New Roman`. Without any quotes. # `size: xx`. Use `px` as unit. # Global font settings used on &lt;body&gt; element. global: external: true family: Lato size: # Font settings for Headlines (h1, h2, h3, h4, h5, h6). # Fallback to `global` font settings. headings: external: true family: size: # Font settings for posts. # Fallback to `global` font settings. posts: external: true family: # Font settings for Logo. # Fallback to `global` font settings. logo: external: true family: size: # Font settings for &lt;code&gt; and code blocks. codes: external: true family: size:# ---------------------------------------------------------------# Third Party Services Settings# ---------------------------------------------------------------# MathJax Supportmathjax: enable: false per_page: false cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML# Han Support docs: https://hanzi.pro/han: false# Swiftype Search API Key #swiftype_key: jYY_fsKS5TYycYSCJas6# Baidu Analytics IDbaidu_analytics: f7d714ed33bfd150a4e166afae0d03d3# Duoshuo ShortName#duoshuo_shortname:# Disqusdisqus: enable: false shortname: count: true# Hypercomments#hypercomments_id:# changyanchangyan: enable: true appid: cyto4vUae appkey: fbae73d15fb09500171cf0adae584a71# Valine.# You can get your appid and appkey from https://leancloud.cn# more info please open https://valine.js.orgvaline: enable: false appid: # your leancloud application appid appkey: # your leancloud application appkey notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: Just go go # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size# Support for youyan comments system.# You can get your uid from http://www.uyan.cc#youyan_uid: your uid# Support for LiveRe comments system.# You can get your uid from https://livere.com/insight/myCode (General web site)#livere_uid: your uid# Gitment# Introduction: https://imsun.net/posts/gitment-introduction/# You can get your Github ID from https://api.github.com/users/&lt;Github username&gt;gitment: enable: false mint: true # RECOMMEND, A mint on Gitment, to support count, language and proxy_gateway count: true # Show comments count in post meta area lazy: false # Comments lazy loading with a button cleanly: false # Hide &apos;Powered by ...&apos; on footer, and more language: # Force language, or auto switch by theme github_user: # MUST HAVE, Your Github ID github_repo: # MUST HAVE, The repo you use to store Gitment comments client_id: # MUST HAVE, Github client id for the Gitment client_secret: # EITHER this or proxy_gateway, Github access secret token for the Gitment proxy_gateway: # Address of api proxy, See: https://github.com/aimingoo/intersect redirect_protocol: # Protocol of redirect_uri with force_redirect_protocol when mint enabled# Baidu Share# Available value:# button | slide# Warning: Baidu Share does not support https.baidushare: truetype: button# Share# This plugin is more useful in China, make sure you known how to use it.# And you can find the use guide at official webiste: http://www.jiathis.com/.# Warning: JiaThis does not support https.#jiathis: ##uid: Get this uid from http://www.jiathis.com/#add_this_id:# Share#duoshuo_share: true# NeedMoreShare2# This plugin is a pure javascript sharing lib which is useful in China.# See: https://github.com/revir/need-more-share2# Also see: https://github.com/DzmVasileusky/needShareButton# iconStyle: default | box# boxForm: horizontal | vertical# position: top / middle / bottom + Left / Center / Right# networks: Weibo,Wechat,Douban,QQZone,Twitter,Linkedin,Mailto,Reddit,# Delicious,StumbleUpon,Pinterest,Facebook,GooglePlus,Slashdot,# Technorati,Posterous,Tumblr,GoogleBookmarks,Newsvine,# Evernote,Friendfeed,Vkontakte,Odnoklassniki,Mailruneedmoreshare2: enable: false postbottom: enable: false options: iconStyle: box boxForm: horizontal position: bottomCenter networks: Weibo,Wechat,Douban,QQZone,Twitter,Facebook float: enable: false options: iconStyle: box boxForm: horizontal position: middleRight networks: Weibo,Wechat,Douban,QQZone,Twitter,Facebook# Google Webmaster tools verification setting# See: https://www.google.com/webmasters/#google_site_verification:# Google Analytics#google_analytics:# Bing Webmaster tools verification setting# See: https://www.bing.com/webmaster/#bing_site_verification:# Yandex Webmaster tools verification setting# See: https://webmaster.yandex.ru/#yandex_site_verification:# CNZZ count#cnzz_siteid:# Application Insights# See https://azure.microsoft.com/en-us/services/application-insights/# application_insights:# Make duoshuo show UA# user_id must NOT be null when admin_enable is true!# you can visit http://dev.duoshuo.com get duoshuo user id.duoshuo_info: ua_enable: true admin_enable: false user_id: 0 #admin_nickname: Author# Post widgets &amp; FB/VK comments settings.# ---------------------------------------------------------------# Facebook SDK Support.# https://github.com/iissnan/hexo-theme-next/pull/410facebook_sdk: enable: false app_id: #&lt;app_id&gt; fb_admin: #&lt;user_id&gt; like_button: #true webmaster: #true# Facebook comments plugin# This plugin depends on Facebook SDK.# If facebook_sdk.enable is false, Facebook comments plugin is unavailable.facebook_comments_plugin: enable: false num_of_posts: 10 # min posts num is 1 width: 100% # default width is 550px scheme: light # default scheme is light (light or dark)# VKontakte API Support.# To get your AppID visit https://vk.com/editapp?act=createvkontakte_api: enable: false app_id: #&lt;app_id&gt; like: true comments: true num_of_posts: 10# Star rating support to each article.# To get your ID visit https://widgetpack.comrating: enable: false id: #&lt;app_id&gt; color: fc6423# ---------------------------------------------------------------# Show number of visitors to each article.# You can visit https://leancloud.cn get AppID and AppKey.leancloud_visitors: enable: false app_id: #&lt;app_id&gt; app_key: #&lt;app_key&gt;# Another tool to show number of visitors to each article.# visit https://console.firebase.google.com/u/0/ to get apiKey and projectId# visit https://firebase.google.com/docs/firestore/ to get more information about firestorefirestore: enable: false collection: articles #required, a string collection name to access firestore database apiKey: #required projectId: #required bluebird: false #enable this if you want to include bluebird 3.5.1(core version) Promise polyfill# Show PV/UV of the website/page with busuanzi.# Get more information on http://ibruce.info/2015/04/04/busuanzi/busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: &lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; site_uv_footer: # custom pv span for the whole site site_pv: true site_pv_header: &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; site_pv_footer: # custom pv span for one page only page_pv: true page_pv_header: &lt;i class=&quot;fa fa-file-o&quot;&gt;&lt;/i&gt; page_pv_footer:# Tencent analytics ID# tencent_analytics:# Tencent MTA ID# tencent_mta:# Enable baidu push so that the blog will push the url to baidu automatically which is very helpful for SEObaidu_push: false# Google Calendar# Share your recent schedule to others via calendar page## API Documentation:# https://developers.google.com/google-apps/calendar/v3/reference/events/listcalendar: enable: false calendar_id: &lt;required&gt; api_key: &lt;required&gt; orderBy: startTime offsetMax: 24 offsetMin: 4 timeZone: showDeleted: false singleEvents: true maxResults: 250# Algolia Searchalgolia_search: enable: false hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: &quot;We didn&apos;t find any results for the search: $&#123;query&#125;&quot; hits_stats: &quot;$&#123;hits&#125; results found in $&#123;time&#125; ms&quot;# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1# ---------------------------------------------------------------# Tags Settings# ---------------------------------------------------------------# External URL with BASE64 encrypt &amp; decrypt.# Usage: &#123;% exturl text url &quot;title&quot; %&#125;# Alias: &#123;% extlink text url &quot;title&quot; %&#125;exturl: false# Note tag (bs-callout).note: # Note tag style values: # - simple bs-callout old alert style. Default. # - modern bs-callout new (v2-v3) alert style. # - flat flat callout style with background, like on Mozilla or StackOverflow. # - disabled disable all CSS styles import of note tag. style: simple icons: false border_radius: 3 # Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6). # Offset also applied to label tag variables. This option can work with disabled note tag. light_bg_offset: 0# Label tag.label: true# Tabs tag.tabs: enable: true transition: tabs: false labels: true border_radius: 0#! ---------------------------------------------------------------#! DO NOT EDIT THE FOLLOWING SETTINGS#! UNLESS YOU KNOW WHAT YOU ARE DOING#! ---------------------------------------------------------------# Use velocity to animate everything.motion: enable: true async: false transition: # Transition variants: # fadeIn | fadeOut | flipXIn | flipXOut | flipYIn | flipYOut | flipBounceXIn | flipBounceXOut | flipBounceYIn | flipBounceYOut # swoopIn | swoopOut | whirlIn | whirlOut | shrinkIn | shrinkOut | expandIn | expandOut # bounceIn | bounceOut | bounceUpIn | bounceUpOut | bounceDownIn | bounceDownOut | bounceLeftIn | bounceLeftOut | bounceRightIn | bounceRightOut # slideUpIn | slideUpOut | slideDownIn | slideDownOut | slideLeftIn | slideLeftOut | slideRightIn | slideRightOut # slideUpBigIn | slideUpBigOut | slideDownBigIn | slideDownBigOut | slideLeftBigIn | slideLeftBigOut | slideRightBigIn | slideRightBigOut # perspectiveUpIn | perspectiveUpOut | perspectiveDownIn | perspectiveDownOut | perspectiveLeftIn | perspectiveLeftOut | perspectiveRightIn | perspectiveRightOut post_block: fadeIn post_header: slideDownIn post_body: slideDownIn coll_header: slideLeftIn # Only for Pisces | Gemini. sidebar: slideUpIn# Fancyboxfancybox: true# Progress bar in the top during page loading.pace: false# Themes list:#pace-theme-big-counter#pace-theme-bounce#pace-theme-barber-shop#pace-theme-center-atom#pace-theme-center-circle#pace-theme-center-radar#pace-theme-center-simple#pace-theme-corner-indicator#pace-theme-fill-left#pace-theme-flash#pace-theme-loading-bar#pace-theme-mac-osx#pace-theme-minimal# For example# pace_theme: pace-theme-center-simplepace_theme: pace-theme-minimal# Canvas-nestcanvas_nest: false# three_wavesthree_waves: false# canvas_linescanvas_lines: false# canvas_spherecanvas_sphere: false# Only fit scheme Pisces# Canvas-ribbon# size: The width of the ribbon.# alpha: The transparency of the ribbon.# zIndex: The display level of the ribbon.canvas_ribbon: enable: false size: 300 alpha: 0.6 zIndex: -1# Script Vendors.# Set a CDN address for the vendor you want to customize.# For example# jquery: https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js# Be aware that you should use the same version as internal ones to avoid potential problems.# Please use the https protocol of CDN files when you enable https on your site.vendors: # Internal path prefix. Please do not edit it. _internal: lib # Internal version: 2.1.3 jquery: # Internal version: 2.1.5 # See: http://fancyapps.com/fancybox/ fancybox: fancybox_css: # Internal version: 1.0.6 # See: https://github.com/ftlabs/fastclick fastclick: # Internal version: 1.9.7 # See: https://github.com/tuupola/jquery_lazyload lazyload: # Internal version: 1.2.1 # See: http://VelocityJS.org velocity: # Internal version: 1.2.1 # See: http://VelocityJS.org velocity_ui: # Internal version: 0.7.9 # See: https://faisalman.github.io/ua-parser-js/ ua_parser: # Internal version: 4.6.2 # See: http://fontawesome.io/ fontawesome: # Internal version: 1 # https://www.algolia.com algolia_instant_js: algolia_instant_css: # Internal version: 1.0.2 # See: https://github.com/HubSpot/pace # Or use direct links below: # pace: //cdn.bootcss.com/pace/1.0.2/pace.min.js # pace_css: //cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-flash.min.css pace: pace_css: # Internal version: 1.0.0 # https://github.com/hustcc/canvas-nest.js canvas_nest: # three three: # three_waves # https://github.com/jjandxa/three_waves three_waves: # three_waves # https://github.com/jjandxa/canvas_lines canvas_lines: # three_waves # https://github.com/jjandxa/canvas_sphere canvas_sphere: # Internal version: 1.0.0 # https://github.com/zproo/canvas-ribbon canvas_ribbon: # Internal version: 3.3.0 # https://github.com/ethantw/Han han: # needMoreShare2 # https://github.com/revir/need-more-share2 needMoreShare2:# Assetscss: cssjs: jsimages: images# Theme versionversion: 5.1.4]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>next主题</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F08%2F07%2FoneMall%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[oneMall项目环境Mysql5.7安装位置: 192.168.1.34(虚拟机)安装方式: docker用户名: root密码: 123456端口 13306：3306（docker中Mysql端口采用的默认3306,映射外部端口未13306） Zookeeper安装位置: 192.168.1.34(虚拟机)安装方式: docker端口: 2181 RocketMq安装位置: 192.168.1.34(虚拟机)安装方式: 直接安装（/root/rocketmq)端口: 9876 elasticsearch2.5安装位置: 192.168.1.34(虚拟机)安装方式: 直接安装端口: 9200安装的插件: elasticsearch-analyzer-ik(中文分词插件)]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux文件系统]]></title>
    <url>%2F2019%2F08%2F07%2Flinux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Linux文件系统文件管理命令123456789101112131415161718192021df -hl 查看磁盘剩余空间df -h 查看每个根路径的分区大小du -sh [目录名] 返回该目录的大小du -sm [文件夹] 返回该文件夹总M数du -h [目录名] 查看指定文件夹下的所有文件大小（包含子文件夹）查看硬盘的分区 #sudo fdisk -l查看IDE硬盘信息 #sudo hdparm -i /dev/hda查看STAT硬盘信息 #sudo hdparm -I /dev/sda 或 #sudo apt-get install blktool #sudo blktool /dev/sda id查看硬盘剩余空间 #df -h #df -H查看目录占用空间 #du -hs 目录名优盘没法卸载 #sync fuser -km /media/usbdisk 查看磁盘剩余空间 12345678[root@iZ3i4n96yv24gsZ collector]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 158G 20G 131G 13% /devtmpfs 7.8G 0 7.8G 0% /devtmpfs 7.8G 0 7.8G 0% /dev/shmtmpfs 7.8G 656K 7.8G 1% /runtmpfs 7.8G 0 7.8G 0% /sys/fs/cgrouptmpfs 1.6G 0 1.6G 0% /run/user/0 查看目录各个文件占用的大小 1234567891011121314[root@iZ3i4n96yv24gsZ usr]# du -sh * 513M bin 4.0K etc 4.0K games 9.6M include 369M java 571M lib 378M lib64 48M libexec 2.6G local 464M sbin 306M share 105M src 0 tmp]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F08%2F07%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[查看端口占用情况netstat -tunlp |grep 8082 jar包后台运行$ nohup java -Dfile.encoding=utf-8 -jar rr-api.jar &amp; //nohup 意思是不挂断运行命令,当账户退出或终端关闭时,程序仍然运行//当用 nohup 命令执行作业时，缺省情况下该作业的所有输出被重定向到nohup.out的文件中//除非另外指定了输出文件 jobs: 列出所有后台执行的作业，并且每个作业前面都有个编号。$ jobs kill -9 进程号 （杀死进程） 作业管理 将“当前”作业放到后台“暂停”：ctrl+z 观察当前后台作业状态： jobs参数： -l 除了列出作业号之外同时列出PID -r：列出仅在后台运行（run）的作业 -s：仅列出暂停的作业 将后台作业拿到前台处理： fg fg %jobnumber (%可有可无) 让作业在后台运行： bgctrl+z让当前作业到后台去暂停， bg 作业号就可以在后台run 管理后台作业：kill我们可以让一个已经在后台的作业继续执行，也可以让该作业使用fg拿到前台。如果直接删除该作业，或者让作业重启，需要给作业发送信号。kill -signal %jobnumber参数：kill -l 列出当前kill能够使用的信号signal：表示给后台的作业什么指示，用man 7 signal可知-1（数字）：重新读取一次参数的设置文件（类似reload）-2：表示与由键盘输入ctrl-c同样的动作-9：立刻强制删除一个作业-15：以正常方式终止一项作业。与-9不一样。]]></content>
  </entry>
  <entry>
    <title><![CDATA[jenkins配置部署启动springboot项目]]></title>
    <url>%2F2019%2F08%2F07%2Fjenkins%E9%85%8D%E7%BD%AE%E9%83%A8%E7%BD%B2%E5%90%AF%E5%8A%A8springboot%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[1. jenkins连接远程ssh服务器需要安装一个ssh plugin插件 2. 配置一个全局凭证,就是连接远程服务器的用户名密码 3.在Jenkins系统设置–》SSH remote hosts–》下配置一个ssh服务器 4. 新建任务,输入要执行的脚本 Jenkins配置的脚本：12345#!/bin/bashecho &quot;stop collector&quot;sh /home/deploy/stop.shecho &quot;start collector&quot;sh /home/deploy/start.sh stop.sh脚本如下12345678#!/bin/bashecho &quot;Stopping tooldin-mq&quot;pid=`ps -ef | grep admin.jar | grep -v grep | awk &apos;&#123;print $2&#125;&apos;`if [ -n &quot;$pid&quot; ]then echo &quot;kill -9 的pid:&quot; $pid kill -9 $pidfi start.sh脚本如下123#!/bin/bashsource /etc/profile # 注意这行代码nohup java -Dfile.encoding=utf-8 -jar /home/deploy/admin.jar &gt; /usr/local/collector/admin.log &amp; 遇到的问题在Jenkins中执行该新建的任务时,系统一直无法启动成功,stop.sh脚本确实执行成功了但是项目一直未在后台启动成功 解决思路 先是按照网上的教程更改了jenkins中配置的执行脚本,防止jenkins进程结束后杀死子进程,更改后测试无效123456#!/bin/bashBUILD_ID=DONTKILLMEecho &quot;stop collector&quot;sh /home/deploy/stop.shecho &quot;start collector&quot;sh /home/deploy/start.sh 然后把 start.sh 错误输出指向标准输出 12#!/bin/bashnohup java -jar /home/deploy/admin.jar &gt; /home/deploy/admin.log 2&gt;&amp;1 &amp; 然后在jenkins中启动任务,然后cat admin.log中打印出了错误的日志 1nohup: failed to run command `java&apos;: No such file or directory 看到这个错误，猜想多半是由于java未配置环境变量，但是服务器环境变量确实正常，输入java –version可以看到是能够正常响应的,最终只能在start.sh脚本中增加 source /etc/profile 最后特别感谢饺子哥的帮助]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot以jar包启动,打包到测试服务器,中文乱码,数据库乱码]]></title>
    <url>%2F2019%2F08%2F07%2Fjar%E5%8C%85%E5%90%AF%E5%8A%A8%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[原因windows启动的jar的时候给Java虚拟机设置编码默认不是utf-8, 所以乱码,同时连接插入到数据库的很多数据也是乱码, linux系统的服务器编码默认是utf-8，对于是windows的服务器默认不是utf-8。所以在启动的时候需要设置编码方式。 解决方案: 启动jar包时设置编码如下所示：java -Dfile.encoding=utf=8 -java -Dfile.encoding=utf-8 -jar rr-api.jar]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>中文乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins安装]]></title>
    <url>%2F2019%2F08%2F07%2Fjenkins%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装环境 安装环境 centos7.5,jdk1.8参考博客: https://www.jianshu.com/p/180fb11a5b96 安装步骤注意: 安装前需要确认一下系统是否已经安装并配置好java环境变量1.下载依赖1sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo 2.导入秘钥1sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key 3.安装1yum install jenkins 4.查看安装路径1rpm -ql jenkins 5.修改默认端口号1vi /etc/sysconfig/jenkins 找到JENKINS_PORT=”8080”,修改为自己的端口号如8090 6.启动jenkins1systemctl start jenkins 7.如果启动报如下错误,需要修改jenkins的配置文件1Starting Jenkins bash: /usr/bin/java: No such file or directory 修改Jenkins启动配置文件，指定java安装路径。1vim /etc/init.d/jenkins 打开配置文件后找到candidates这行，在下面增加自己的java安装路径123456789candidates=&quot;/usr/java/jdk1.8/bin/java ## 这里 增加自己的java安装路径，下面的不用动/etc/alternatives/java/usr/lib/jvm/java-1.8.0/bin/java/usr/lib/jvm/jre-1.8.0/bin/java/usr/lib/jvm/java-1.7.0/bin/java/usr/lib/jvm/jre-1.7.0/bin/java/usr/bin/java&quot; 相关目录说明123456jenkins相关目录释义：1. /usr/lib/jenkins/：jenkins安装目录，war包会放在这里。2. /etc/sysconfig/jenkins：jenkins配置文件，“端口”，“JENKINS_HOME”等都可以在这里配置。3. /var/lib/jenkins/：默认的JENKINS_HOME。4. /var/log/jenkins/jenkins.log：jenkins日志文件。5. /etc/init.d/jenkins： jenkins启动配置文件这里需要配置java安装目录 常用命令1.启动123方法1: java -jar /usr/lib/jenkins/jenkins.war --httpPort=8090方法2： service jenkins start方法3: systemctl start jenkins 浏览器访问 http://localhost:8090 输入初始密码即可初始密码路径位于1/var/lib/jenkins/secrets/initialAdminPassword 2.停止1service jenkins stop 3.查看运行状态1service jenkins start]]></content>
      <categories>
        <category>JAVA运维工具</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker远程连接配置]]></title>
    <url>%2F2019%2F08%2F07%2Fdocker%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[无CA认证方式(不安全,建议用于测试环境） 修改服务器配置，开放Docker的远程连接访问 123[root@localhost ~]# vim /usr/lib/systemd/system/docker.service 将ExecStart属性value值改为/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock 重启docker 12[root@localhost ~]# systemctl daemon-reload [root@localhost ~]# systemctl restart docker 开启阿里云和本地的防火墙中 放行2375 端口 远程通过IDEA测试OK CA 认证方式(安全访问方式适用于生产环境)文件总览├── ca-key.pem # 妥善保管，连接时用不到├── ca.pem # clent &amp; server├── ca.srl # 用不到├── cert.pem # client├── client.csr # 请求文件├── extfile.cnf # 配置文件├── key.pem # client├── server-cert.pem # server├── server.csr # 请求文件└── server-key.pem # server 生成步骤 创建ca文件夹，存放CA私钥和公钥 12[root@localhost ~]# mkdir -p /usr/local/ca[root@localhost ~]# cd /usr/local/ca/ 生成 CA 私钥 (需要连续输入两次相同的密码) 1[root@localhost ca]# openssl genrsa -aes256 -out ca-key.pem 4096 生成 CA 公钥.输入上一步中设置的密码,然后输入(国家、省、市、组织名称等) 1[root@localhost ca]# openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem 生成服务器私钥 server-key.pem 1[root@localhost ca]# openssl genrsa -out server-key.pem 4096 用私钥生成证书请求文件(重点) 1[root@localhost ca]# openssl req -subj &quot;/CN=47.105.199.230&quot; -sha256 -new -key server-key.pem -out server.csr 把下面命令中的$Host换成你自己服务器外网的IP或者域名openssl req -subj &quot;/CN=$HOST&quot; -sha256 -new -key server-key.pem -out server.csr 比如 IP:openssl req -subj &quot;/CN=192.168.1.106&quot; -sha256 -new -key server-key.pem -out server.csr 域名: openssl req -subj &quot;/CN=www.baidu.com&quot; -sha256 -new -key server-key.pem -out server.csr 用 CA 来签署证书(也就是配置白名单) 1[root@localhost ca]# echo subjectAltName = IP:192.168.1.106,IP:0.0.0.0 &gt;&gt; extfile.cnf 注意事项:这里就是配置白名单, 制定你接下来要允许那些ip可以连接到服务器的docker，因为已经是ssl连接，所以我推荐配置0.0.0.0,也就是所有ip都可以连接(但只有拥有证书的才可以连接成功)，这样配置好之后公司其他人也可以使用。如果你不想这样，那你可以配置ip，用逗号分隔开。下面的$Host依旧是你服务器外网的IP或者域名，请自行替换。 如果你填写的是ip地址的话命令如下 echo subjectAltName = IP:$HOST,IP:0.0.0.0 &gt;&gt; extfile.cnf如果你填写的是域名的话命令如下 echo subjectAltName = DNS:$HOST,IP:0.0.0.0 &gt;&gt; extfile.cnf我这里使用局域网进行测试 执行命令, 将Docker守护程序密钥的扩展使用属性设置为仅用于服务器身份验证 1[root@localhost ca]# echo extendedKeyUsage = serverAuth &gt;&gt; extfile.cnf 执行命令，并输入之前设置的密码，生成签名证书 12345[root@localhost ca]# openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \-CAcreateserial -out server-cert.pem -extfile extfile.cnfSignature oksubject=/CN=192.168.1.106Getting CA Private KeyEnter pass phrase for ca-key.pem: 生成客户端私钥(key.pem) 到时候把生成好的几个公钥私钥拷出去即可 1[root@localhost ca]# openssl genrsa -out key.pem 4096 用私钥生成证书请求文件 1[root@localhost ca]# openssl req -subj &apos;/CN=client&apos; -new -key key.pem -out client.csr 执行命令，要使密钥适合客户端身份验证，请创建扩展配置文件 1[root@localhost ca]# echo extendedKeyUsage = clientAuth &gt;&gt; extfile.cnf 用 CA 来签署证书,生成cert.pem(需要输入前面设置的密码,生成签名证书) 1[root@localhost ca]# openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \-CAcreateserial -out cert.pem -extfile extfile.cnf 删除不需要的文件，两个证书签名请求 1[root@localhost ca]# rm -v client.csr server.csr 修改权限，要保护您的密钥免受意外损坏，请删除其写入权限。要使它们只能被您读取，更改文件模式 12$ chmod -v 0400 ca-key.pem key.pem server-key.pem$ chmod -v 0444 ca.pem server-cert.pem cert.pem 归集服务器证书 把 ca.pem server-cert.pem server-key.pem 三个文件移动到服务端 /etc/docker/ 文件夹中。 修改Docker配置(使Docker守护程序仅接受来自提供CA信任的证书的客户端的连接() 修改docker.service [root@localhost ca]# vim /lib/systemd/system/docker.service 修改该文件Service标签下的ExecStart 12345678910[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by docker#重点#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock（原来的）ExecStart=/usr/bin/dockerd（改为这样）# -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock （上面行从-H开始换行注释起来） 修改/etc/docker/daemon.json 123456789101112&#123;"registry-mirrors": ["https://26t763ap.mirror.aliyuncs.com"], "tlsverify": true, "tlscert": "/etc/docker/server-cert.pem", "tlskey": "/etc/docker/server-key.pem", "tlscacert": "/etc/docker/ca.pem", "hosts":[ "unix:///var/run/docker.sock", "tcp://0.0.0.0:2376" ]&#125;~ 重新加载daemon并重启docker 12[root@localhost ~]# systemctl daemon-reload [root@localhost ~]# systemctl restart docker 阿里云或本地防火墙要放行2376 端口 通过FTP把客户端需要的 pem文件下载到本地 将 ca.pem cert.pem key.pem 三个文件通过 scp 下载到本地 IDEA 中配置证书及路径（如下图） 注意: 改为 2376 端口以后，要使用https地址,不能再使用 tcp 地址 正确的: https://47.105.199.230:2376 错误的: tcp://47.105.199.230:2376 [^参考文章][^参考文章]: https://blog.csdn.net/ChineseYoung/article/details/83107353]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker远程访问</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cron表达式详解]]></title>
    <url>%2F2019%2F08%2F07%2Fcron%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Cron表达式是一个字符串，字符串以5或6个空格隔开，分为6或7个域，每一个域代表一个含义，Cron有如下两种语法格式： （1） Seconds Minutes Hours DayofMonth Month DayofWeek Year （2） Seconds Minutes Hours DayofMonth Month DayofWeek 结构 corn从左到右（用空格隔开）： 秒 分 小时 月份中的日期 月份 星期中的日期 年份 各字段的含义 字段 允许值 允许的特殊字符 秒(Seconds) 0~59的整数 , - * / 四个字符 分(Minutes) 0~59的整数 , - * / 四个字符 小时(Hours) 0~23的整数 , - * / 四个字符 日期(DayofMonth) 1~31的整数 ,- * ? / L W C 八个字符 月份(Month) 1~12的整数或者 JAN-DEC , - * / 四个字符 星期(DayofWeek) 1~7的整数或者 SUN-SAT （1=SUN） , - * ? / L C # 八个字符 年(Year) 可选，留空 1970~2099 , - * / 四个字符 注意事项： 每一个域都使用数字，但还可以出现如下特殊字符，它们的含义是： （1）：表示匹配该域的任意值。假如在Minutes域使用, 即表示每分钟都会触发事件。 （2）?：只能用在DayofMonth和DayofWeek两个域。它也匹配域的任意值，但实际不会。因为DayofMonth和DayofWeek会相互影响。例如想在每月的20日触发调度，不管20日到底是星期几，则只能使用如下写法： 13 13 15 20 ?, 其中最后一位只能用？，而不能使用，如果使用*表示不管星期几都会触发，实际上并不是这样。 （3）-：表示范围。例如在Minutes域使用5-20，表示从5分到20分钟每分钟触发一次 （4）/：表示起始时间开始触发，然后每隔固定时间触发一次。例如在Minutes域使用5/20,则意味着5分钟触发一次，而25，45等分别触发一次. （5）,：表示列出枚举值。例如：在Minutes域使用5,20，则意味着在5和20分每分钟触发一次。 （6）L：表示最后，只能出现在DayofWeek和DayofMonth域。如果在DayofWeek域使用5L,意味着在最后的一个星期四触发。 （7）W:表示有效工作日(周一到周五),只能出现在DayofMonth域，系统将在离指定日期的最近的有效工作日触发事件。例如：在 DayofMonth使用5W，如果5日是星期六，则将在最近的工作日：星期五，即4日触发。如果5日是星期天，则在6日(周一)触发；如果5日在星期一到星期五中的一天，则就在5日触发。另外一点，W的最近寻找不会跨过月份 。 （8）LW:这两个字符可以连用，表示在某个月最后一个工作日，即最后一个星期五。 （9）#:用于确定每个月第几个星期几，只能出现在DayofMonth域。例如在4#2，表示某月的第二个星期三。 三、常用表达式例子 （1）0 0 2 1 ? 表示在每月的1日的凌晨2点调整任务 （2）0 15 10 ? * MON-FRI 表示周一到周五每天上午10:15执行作业 （3）0 15 10 ? 6L 2002-2006 表示2002-2006年的每个月的最后一个星期五上午10:15执行作 （4）0 0 10,14,16 ? 每天上午10点，下午2点，4点 （5）0 0/30 9-17 ? 朝九晚五工作时间内每半小时 （6）0 0 12 ? * WED 表示每个星期三中午12点 （7）0 0 12 ? 每天中午12点触发 （8）0 15 10 ? 每天上午10:15触发 （9）0 15 10 ? 每天上午10:15触发 （10）0 15 10 ? * 每天上午10:15触发 （11）0 15 10 ? 2005 2005年的每天上午10:15触发 （12）0 14 * ? 在每天下午2点到下午2:59期间的每1分钟触发 （13）0 0/5 14 ? 在每天下午2点到下午2:55期间的每5分钟触发 （14）0 0/5 14,18 ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 （15）0 0-5 14 ? 在每天下午2点到下午2:05期间的每1分钟触发 （16）0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发 （17）0 15 10 ? * MON-FRI 周一至周五的上午10:15触发 （18）0 15 10 15 * ? 每月15日上午10:15触发 （19）0 15 10 L * ? 每月最后一日的上午10:15触发 （20）0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发 （21）0 15 10 ? * 6L 2002-2005 2002年至2005年的每月的最后一个星期五上午10:15触发 （22）0 15 10 ? * 6#3 每月的第三个星期五上午10:15触发 注： （1）有些子表达式能包含一些范围或列表 例如：子表达式（天（星期））可以为 “MON-FRI”，“MON，WED，FRI”，“MON-WED,SAT” “*”字符代表所有可能的值 因此，“”在子表达式（月）里表示每个月的含义，“”在子表达式（天（星期））表示星期的每一天 “/”字符用来指定数值的增量 例如：在子表达式（分钟）里的“0/15”表示从第0分钟开始，每15分钟在子表达式（分钟）里的“3/20”表示从第3分钟开始，每20分钟（它和“3，23，43”）的含义一样 “？”字符仅被用于天（月）和天（星期）两个子表达式，表示不指定值 当2个子表达式其中之一被指定了值以后，为了避免冲突，需要将另一个子表达式的值设为“？” “L” 字符仅被用于天（月）和天（星期）两个子表达式，它是单词“last”的缩写 但是它在两个子表达式里的含义是不同的。 在天（月）子表达式中，“L”表示一个月的最后一天 在天（星期）自表达式中，“L”表示一个星期的最后一天，也就是SAT 如果在“L”前有具体的内容，它就具有其他的含义了 例如：“6L”表示这个月的倒数第６天，“FRIL”表示这个月的最一个星期五 注意：在使用“L”参数时，不要指定列表或范围，因为这会导致问题]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>定时任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centOS ssh连接 一段时间无操作连接自动断开问题]]></title>
    <url>%2F2019%2F08%2F07%2FcentOS-ssh%E8%BF%9E%E6%8E%A5-%E4%B8%80%E6%AE%B5%E6%97%B6%E9%97%B4%E6%97%A0%E6%93%8D%E4%BD%9C%E8%BF%9E%E6%8E%A5%E8%87%AA%E5%8A%A8%E6%96%AD%E5%BC%80%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[解决方法： 1 修改 /etc/ssh/sshd_config 文件执行命令：vi /etc/ssh/sshd_config 中间部分有： ClientAliveInterval 0ClientAliveCountMax 3改为： ClientAliveInterval 60 ClientAliveCountMax 60 修改后如下用图： ClientAliveInterval指定了服务器端向客户端请求消息的时间间隔, 默认是0, 不发送.而ClientAliveInterval 60表示每分钟发送一次, 然后客户端响应, 这样就保持长连接了 ClientAliveCountMax表示服务器发出请求后客户端没有响应的次数达到一定值, 就自动断开 。 2重启sshd （必须的否则无效）执行命令：/bin/systemctl restart sshd.service我有在网上找这个问题的解决方法，有的只改参数，没有讲重启sshd。有的说了但是呢在我的机子上命令不能用，例如：/etc/init.d/sshdstart /etc/rc.d/init.d/sshd restart]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F08%2F07%2Fcenos7.5%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[cenos7.5下载地址http://archive.kernel.org/centos-vault/7.5.1804/isos/x86_64/]]></content>
  </entry>
  <entry>
    <title><![CDATA[android版本API对应关系]]></title>
    <url>%2F2019%2F08%2F07%2Fandroid%E7%89%88%E6%9C%ACAPI%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[code name Version API level Q Preview API level Q Pie 9.0 API level 28 Oreo 8.1 API level 27 Oreo 8.0 API level 26 Nougat 7.1 API level 25 Nougat 7.0 API level 24 Marshmallow 6.0 API level 23 Lollipop 5.1 API level 22 Lollipop 5.0 API level 21 KitKat 4.4 - 4.4.4 API level 19 Jelly Bean 4.3.x API level 18 Jelly Bean 4.2.x API level 17 Jelly Bean 4.1.x API level 16 Ice Cream Sandwich 4.0.3 - 4.0.4 API level 15, NDK 8 Ice Cream Sandwich 4.0.1 - 4.0.2 API level 14, NDK 7 Honeycomb 3.2.x API level 13 Honeycomb 3.1 API level 12, NDK 6 Honeycomb 3.0 API level 11 Gingerbread 2.3.3 - 2.3.7 API level 10 Gingerbread 2.3 - 2.3.2 API level 9, NDK 5 Froyo 2.2.x API level 8, NDK 4 Eclair 2.1 API level 7, NDK 3 Eclair 2.0.1 API level 6 Eclair 2.0 API level 5 Donut 1.6 API level 4, NDK 2 Cupcake 1.5 API level 3, NDK 1 (no code name) 1.1 API level 2 (no code name) 1.0 API level 1]]></content>
      <categories>
        <category>android</category>
      </categories>
      <tags>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql存储emoji表情错误问题]]></title>
    <url>%2F2019%2F08%2F07%2FMysql%E5%AD%98%E5%82%A8emoji%E8%A1%A8%E6%83%85%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题: 插入emoji表情字符串时,数据库抛出下面的异常信息:1Incorrect string value: &apos;\xF0\x9F\x98\x81&apos; for column &apos;job&apos; at row 23 解决方法 ： windows服务器修改my.ini配置文件,修改编码 1234[mysql] default-character-set=utf8mb4[mysqld] character-set-server=utf8mb4 重启Mysql服务 先查看数据库的编码方式： 1show variables like &apos;%char%&apos;; 修改整个表的编码方式： 1alter table user convert to character set utf8mb4 collate utf8mb4_bin; 修改某个字段的编码方式：1ALTER TABLE user_patient MODIFY COLUMN user_name varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL COMMENT &apos;姓名&apos;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置Https证书后,API项目访问时POST请求变为GET请求]]></title>
    <url>%2F2019%2F08%2F07%2FNginx%E9%85%8D%E7%BD%AEHttps%E8%AF%81%E4%B9%A6%E5%90%8E%2CAPI%E9%A1%B9%E7%9B%AE%E8%AE%BF%E9%97%AE%E6%97%B6POST%E8%AF%B7%E6%B1%82%E5%8F%98%E4%B8%BAGET%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[Nginx下配置Https证书，之前的博客是: Nginx配置Https证书 Https证书配置完成后 admin模块可以正常跳转到HTTPS, API模块部署后,后台请求登录遇到异常,查看Nginx日志后发现从http跳转到https时,请求的api方法从POST变为了GET请求，日志如下: 123123.52.42.83 - - [05/Jun/2019:15:51:46 +0800] &quot;POST /ylzhy-api/api/wechat/user/login HTTP/1.1&quot; 301 185 &quot;-&quot; &quot;PostmanRuntime/7.13.0&quot;123.52.42.83 - - [05/Jun/2019:15:51:46 +0800] &quot;GET /ylzhy-api/api/wechat/user/login HTTP/1.1&quot; 200 65 &quot;http://www.sjjtcloud.com:80/ylzhy-api/api/wechat/user/login&quot; &quot;PostmanRuntime/7.13.0&quot; 查找相关资料后, 发现是由于 301引起的。换成307问题解决 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; #gzip on; server &#123; listen 443; server_name www.sjjtcloud.com; ssl on; ssl_certificate cert/2195340_www.sjjtcloud.com.pem; ssl_certificate_key cert/2195340_www.sjjtcloud.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; root D:/nginx-1.12.2/html; index index.html index.htm; try_files $uri $uri/ @router; &#125; location /api/ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8081; &#125; location /admin &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8083/admin; &#125; &#125; server &#123; listen 80; server_name www.sjjtcloud.com sjjtcloud.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; #rewrite ^(.*)$ https://$&#123;server_name&#125;$1 permanent; #这种写法是错误的 return 307 https://$server_name$request_uri; ###改为307 &#125;&#125; 301 Moved Permanently被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一 307 Temporary Redirect请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx匹配规则说明以及匹配的优先级]]></title>
    <url>%2F2019%2F08%2F07%2FNginx%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[location 匹配规则语法规则location [=|~|~*|^~] /uri/ { … } 模式 含义location = /uri = 表示精确匹配，只有完全匹配上才能生效location ^~ /uri ^~ 开头对URL路径进行前缀匹配，并且在正则之前。location ~ pattern 开头表示区分大小写的正则匹配location ~* pattern 开头表示不区分大小写的正则匹配location /uri 不带任何修饰符，也表示前缀匹配，但是在正则匹配之后location / 通用匹配，任何未匹配到其它location的请求都会匹配到，相当于switch中的default前缀匹配时，Nginx 不对 url 做编码，因此请求为 /static/20%/aa，可以被规则 ^~ /static/ /aa 匹配到（注意是空格） 多个 location 配置的情况下匹配顺序为（参考资料而来，还未实际验证，试试就知道了，不必拘泥，仅供参考）: 首先精确匹配 =其次前缀匹配 ^~其次是按文件中顺序的正则匹配然后匹配不带任何修饰的前缀匹配。最后是交给 / 通用匹配当有匹配成功时候，停止匹配，按当前匹配规则处理请求注意：前缀匹配，如果有包含关系时，按最大匹配原则进行匹配。比如在前缀匹配：location /dir01 与location /dir01/dir02，如有请求 http://localhost/dir01/dir02/file 将最终匹配到 location /dir01/dir02 例子，有如下匹配规则： location = / { echo “规则A”;}location = /login { echo “规则B”;}location ^~ /static/ { echo “规则C”;}location ^~ /static/files { echo “规则X”;}location ~ .(gif|jpg|png|js|css)$ { echo “规则D”;}location ~* .png$ { echo “规则E”;}location /img { echo “规则Y”;}location / { echo “规则F”;}那么产生的效果如下： 访问根目录 /，比如 http://localhost/ 将匹配 规则A访问 http://localhost/login 将匹配 规则B，http://localhost/register 则匹配 规则F访问 http://localhost/static/a.html 将匹配 规则C访问 http://localhost/static/files/a.exe 将匹配 规则X，虽然 规则C 也能匹配到，但因为最大匹配原则，最终选中了 规则X。你可以测试下，去掉规则 X ，则当前 URL 会匹配上 规则C。访问 http://localhost/a.gif, http://localhost/b.jpg 将匹配 规则D 和 规则 E ，但是 规则 D 顺序优先，规则 E 不起作用，而 http://localhost/static/c.png 则优先匹配到 规则 C访问 http://localhost/a.PNG 则匹配 规则 E ，而不会匹配 规则 D ，因为 规则 E 不区分大小写。访问 http://localhost/img/a.gif 会匹配上 规则D,虽然 规则Y 也可以匹配上，但是因为正则匹配优先，而忽略了 规则Y。访问 http://localhost/img/a.tiff 会匹配上 规则Y。访问 http://localhost/category/id/1111 则最终匹配到规则 F ，因为以上规则都不匹配，这个时候应该是 Nginx 转发请求给后端应用服务器，比如 FastCGI（php），tomcat（jsp），Nginx 作为反向代理服务器存在。 所以实际使用中，笔者觉得至少有三个匹配规则定义，如下： 直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。这里是直接转发给后端应用服务器了，也可以是一个静态首页第一个必选规则location = / { proxy_pass http://tomcat:8080/index} 第二个必选规则是处理静态文件请求，这是 nginx 作为 http 服务器的强项有两种配置模式，目录匹配或后缀匹配，任选其一或搭配使用location ^~ /static/ { root /webroot/static/;}location ~* .(gif|jpg|jpeg|png|css|js|ico)$ { root /webroot/res/;} 第三个规则就是通用规则，用来转发动态请求到后端应用服务器非静态文件请求就默认是动态请求，自己根据实际把握毕竟目前的一些框架的流行，带.php、.jsp后缀的情况很少了location / { proxy_pass http://tomcat:8080/} rewrite 语法作者：Gove_chan来源：CSDN原文：https://blog.csdn.net/qq_15766181/article/details/72829672版权声明：本文为博主原创文章，转载请附上博文链接！]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>NGINX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA IO总结]]></title>
    <url>%2F2019%2F08%2F07%2FJava-io%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[#JAVA IO总结 InputStream和OutputStream InputStream是所有字节输入流的父类 int read():读取一个字节以int形式返回,该int值的低8位有效，返回-1则表示EOF int read(byte[] b): 读取b.length字节到数组中，返回值为实际读取到的字节量 OutputStream是所有字节输出流的父类 void write(int d) 写出一个字节，写的是int的低8位 void write(byte[] d)将给定的字节数组中的所有字节全部写出 文件字节流 FileInputStream 是文件的字节输入流 int read() int read(byte[] b) FileOutputStream 是文件的字节输出流，FOS有两种模式一种是重写模式，一种是追加模式 void write(int d) void write(byte[] d) void write(byte[] d,int offset,int len)将字节数组d中 从偏移量offset开始的 len个字节写入文件输出流中 123456789101112131415161718192021222324252627282930313233343536373839/** * 文件流 * FileOutPutStream是字节输出流 */public class FosTest &#123; File f = new File(&quot;fileOut.txt&quot;); //测试FOS 追加模式 @Test @Ignore public void testFosAppendMode()&#123; try&#123; FileOutputStream fos = new FileOutputStream(f,true); fos.write(&quot;,Hello every one I am David&quot;.getBytes()); fos.flush(); fos.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; //测试FOS 重写模式 @Test @Ignore public void testFosOverrideMode()&#123; try&#123; FileOutputStream fos = new FileOutputStream(f); fos.write(&quot;You are good Boy&quot;.getBytes()); fos.flush(); fos.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 缓冲流 在读取数据时 若以字节为单位读取数据，会因为读取次数频繁而大大的降低读取效率缓冲流就是通过提高每次读写的字节数量,减少读写次数 从而提高读写效率 BufferedInputStream BufferedOutputStream 12345678910111213141516171819202122232425262728293031323334/** * BufferedOutputStream * 内部维护着一个缓冲区,当我们向该流写数据时，都会先将数据写入缓冲区, 当缓冲区已满时,缓冲流会一次性将数据写出 * 用途：在向硬件设备写出数据时, 使用缓冲流可以减小写出次数，从而提高了写出效率 * 注意: 有时我们在写出数据后希望 数据立即被写出，而不是存储在缓冲区中 直到缓冲区满后才真正写出，这时可以调用flush()强制写出 * * BufferedInputPutStream 处理流 * 内部也是维护一个缓冲区，当读取字节数据时会尽可能多的读取 然后存入缓冲区，然后逐一的返回缓存的字节数据，直到读取完毕 */public class BosBisTest &#123; @Test public void testBos()&#123; try&#123; byte[] d = new byte[100]; FileOutputStream fos = new FileOutputStream(&quot;fileOut.txt&quot;,true); BufferedOutputStream bos = new BufferedOutputStream(fos); bos.write(&quot;,I am from China&quot;.getBytes()); bos.close(); FileInputStream fio = new FileInputStream(&quot;fileOut.txt&quot;); BufferedInputStream bio = new BufferedInputStream(fio); int dd = -1; while((dd = bio.read())!=-1)&#123; //一个个字节的读取输出了， System.out.println(dd+&quot;,&quot;); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; Reader和Writer Reader是字符输入流的父类，当要读文本文件时最好使用Reader类，它为读取文本而设计 Writer是字符输出流的父类，当要写文本文件时最好使用Writer类，而不是直接写OutputStream；因为Writer类就是为写文本而设计的。 字符流是以char(字符)为单位读写数据的,一次处理一个Unicode 字符流的底层仍然是基本的字节流. Reader常用方法 int read(): 读取一个字符,返回int值 “低16位”有效 int read(char[] chs): 读取一个字符数组的length个字符并存入该数组,返回值为实际读取到的字符量 Writer常用方法 void write(int c): 写出一个字符,写出给定int值 “低16位”表示的字符。 void write(char[] chs):将给定字符数组中所有字符写出 void write(char[] chs,int offset,int len):将给定的字符数组中从offset处开始连续的len个字符写出 转换流###InputStreamReader: 字符输入流 使用该流可以设置字符集,并按照指定的字符集从流中按照该编码将字节数据转换为字符并读取 InputStreamReader(InputStream in, String charsetName) 根据指定字符集创建ISR InputStreamReader(InputStream in) 根据系统默认字符集创建ISR OutputStreamWriter:字符输出流使用该流可以设置字符集,并按照指定字符集 将字符转换为对应字节后通过流写出 OutputStreamWriter(OutputStream out,String charsetName) 基于指定的字节输出流和字符集创建OSW OutputStreamWriter(OutputStream out) 基于指定的字节输出流和系统默认字符集创建OSW 123456789101112131415161718192021222324252627/** * 测试InputStreamReader 和 OutputStreamWriter */public class OswTest &#123; @Test @Ignore public void testOsw() throws java.io.IOException&#123; FileOutputStream fos = new FileOutputStream(&quot;demo.txt&quot;); OutputStreamWriter osw = new OutputStreamWriter(fos,&quot;UTF-8&quot;); osw.write(&quot;中国人&quot;); osw.close(); &#125; @Test public void testIsr() throws java.io.IOException&#123; FileInputStream fis = new FileInputStream(&quot;demo.txt&quot;); InputStreamReader isr = new InputStreamReader(fis,&quot;utf-8&quot;); int data = -1; while ((data=isr.read())!=-1)&#123; System.out.println((char)data); &#125; isr.close(); &#125;&#125; 文件字符流 FileReader FileWriter 12345678910111213141516171819202122public class FileReaderWriterTest &#123; @Test public void test()&#123; try&#123; File f = new File(&quot;demo.txt&quot;); FileWriter fw = new FileWriter(f); fw.write(&quot;Hello\ndavid&quot;); fw.close(); FileReader fr = new FileReader(f); int res = 0; while ( (res=fr.read())!=-1)&#123; System.out.println((char)res); &#125; fr.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 字符缓冲流 BufferedReader 它是缓存字符输入流,内部提供了缓冲区 可以提交读取效率 12BufferedReader(Reader reader) 构造函数String readLine() 该方法连续读取一行字符串 BufferedWriter 12345BufferedWriter(Writer writer)构造函数void newLine() //写入一个行分隔符。 void write(char ch)void write(char[] cbuf)void write(char[] cbuf,int offset,int len) Demo代码 1234567891011121314151617181920212223242526272829303132333435 public class BufferedReaderWriter &#123; @Test @Ignore public void testReader()&#123; try &#123; BufferedReader br = new BufferedReader(new FileReader(&quot;demo.txt&quot;)); String str= &quot;&quot;; while((str=br.readLine())!=null)&#123; System.out.println(&quot;---&quot;+str); &#125; br.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; @Test public void testWriter()&#123; try&#123; BufferedWriter bw = new BufferedWriter(new FileWriter(&quot;demo.txt&quot;)); bw.write(&quot;Hello&quot;); bw.newLine(); bw.write(&quot;I am david&quot;); bw.newLine(); bw.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql主从复制原理及步骤]]></title>
    <url>%2F2019%2F08%2F07%2FMysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Mysql主从复制的原理 mysql内建有一种复制方式，即指定一台或多台服务器为主机master，另外一台或多台服务器作为从机slave。当master存在更新的时候，master将更新写入二进制文件，并维护了一个索引文件跟踪日志。当slave连接到主服务器之后，slave会通知master进行同步，master通过索引找日志文件上一次同步的位置，然后将这段时间内的更新数据发送给slave进行同步 主从配置的优缺点优点：高可用，提高容错率，数据分布，负载均衡。 缺点：单向同步，无法解决主机宕机问题 主从配置先决条件 Mysql版本必须一致 保证两台主机的mysql远程连接开启 目标主库从库均创建要给名为auth的数据库 主库ip:192.168.1.121 从库ip:192.168.1.107 主机(主库)配置1. 找到Mysql安装目录下的my.ini配置文件,在[mysqld]下增加如下配置1234server-id=66 #id唯一log-bin=E:/phpStudy/MySQL/log-bin #同步日志的文件存放路径binlog-do-db=auth #备份哪些些数据库的二进制日志#binlog-ignore-db=test #也可以直接设置哪些数据库不同步 2. 重启mysql服务,可以在上面配置的日志文件存储路径下找到索引文件,表示成功3. 登陆mysql，给从机配置登录名，登陆，密码和权限1grant replication slave,reload,super on *.* to slave@192.168.1.121 identified by 'changpan'; 4. 查看主库状态 配置从机时需要使用file和postion两个值1show master status; 从机(从库)配置1. 找到Mysql安装目录下的my.ini配置文件,在[mysqld]下增加如下配置12server-id=88 #保证整数唯一replicate-do-db=auth #同步哪一个数据库 跟主库一致 注意: 配置好之后重启数据库 2. 测试是否能够登陆到主库,校验之前主库的配置1mysql -uslave -h 192.168.1.121 -pchangpan 3.配置从库的同步链接信息,登陆从库,Navicat中执行下面命令12stop slave; 关闭从机同步连接change master to master_host = '192.168.1.121', master_user='slave', master_password ='changpan', master_log_file='mysql-bin.000001',master_log_pos=593; 【注意】master_log_file,master_log_pos是主库中通过命令show master status查询到的数据 4.开启同步,查看从库配置的有效性12start slave； 开启同步连接show slave status; 查看主从机连接信息 输入命令后查看下面的结果 当上面查看到的状态中出现以下 两个值都为YES时,表示成功Slave_IO_Running:YesSlave_SQL_Running:Yes 5. 测试,在主库中添加一个新表或表中插入新的数据，进行测试已有主库,怎样在此基础上进行主从同步呢？1.锁定或者阻断主库中的表进写操作,导出sql结构和数据123mysql&gt; FLUSH TABLES WITH READ LOCK;mysqldump -u root -p123456 --opt -R openser &gt; openser20121203.sql；mysql&gt; UNLOCK TABLES; 2.从库中关闭同步链接，然后导入sql、1stop slave; 3.关闭从库链接,重启从库链接即可1start slave; 4.进行测试OK]]></content>
      <categories>
        <category>DataBase</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>主从复制</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F08%2F07%2FMybatisPlus%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[###MybatisPlus总结 mybatisPlus中使用updateById和update 都不能更新某个字段为””问题解决方法： 修改mybatis-plus配置文件，如下： 12#字段策略 0:&quot;忽略判断&quot;,1:&quot;非 NULL 判断&quot;),2:&quot;非空判断&quot;field-strategy: 1]]></content>
  </entry>
  <entry>
    <title><![CDATA[IDEA快捷键]]></title>
    <url>%2F2019%2F08%2F07%2FIDEA%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[Ctrl 快捷键 介绍 Ctrl + F 在当前文件进行文本查找 （必备） Ctrl + R 在当前文件进行文本替换 （必备） Ctrl + Z 撤销 （必备） Ctrl + Y 删除光标所在行 或 删除选中的行 （必备） Ctrl + X 剪切光标所在行 或 剪切选择内容 Ctrl + C 复制光标所在行 或 复制选择内容 Ctrl + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 （必备） Ctrl + W 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 （必备） Ctrl + E 显示最近打开的文件记录列表 （必备） Ctrl + N 根据输入的 类名 查找类文件 （必备） Ctrl + G 在当前文件跳转到指定行处 Ctrl + J 插入自定义动态代码模板 （必备） Ctrl + P 方法参数提示显示 （必备） Ctrl + Q 光标所在的变量 / 类名 / 方法名等上面（也可以在提示补充的时候按），显示文档内容 Ctrl + U 前往当前光标所在的方法的父类的方法 / 接口定义 （必备） Ctrl + B 进入光标所在的方法/变量的接口或是定义处，等效于 Ctrl + 左键单击 （必备） Ctrl + K 版本控制提交项目，需要此项目有加入到版本控制才可用 Ctrl + T 版本控制更新项目，需要此项目有加入到版本控制才可用 Ctrl + H 显示当前类的层次结构 Ctrl + O 选择可重写的方法 Ctrl + I 选择可继承的方法 Ctrl + + 展开代码 Ctrl + - 折叠代码 Ctrl + / 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 （必备） Ctrl + [ 移动光标到当前所在代码的花括号开始位置 Ctrl + ] 移动光标到当前所在代码的花括号结束位置 Ctrl + F1 在光标所在的错误代码处显示错误信息 （必备） Ctrl + F3 调转到所选中的词的下一个引用位置 （必备） Ctrl + F4 关闭当前编辑文件 Ctrl + F8 在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点 Ctrl + F9 执行 Make Project 操作 Ctrl + F11 选中文件 / 文件夹，使用助记符设定 / 取消书签 （必备） Ctrl + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选 Ctrl + Tab 编辑窗口切换，如果在切换的过程又加按上delete，则是关闭对应选中的窗口 Ctrl + End 跳到文件尾 Ctrl + Home 跳到文件头 Ctrl + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl + 逗号`（必备）` Ctrl + Delete 删除光标后面的单词或是中文句 （必备） Ctrl + BackSpace 删除光标前面的单词或是中文句 （必备） Ctrl + 1,2,3…9 定位到对应数值的书签位置 （必备） Ctrl + 左键单击 在打开的文件标题上，弹出该文件路径 （必备） Ctrl + 光标定位 按 Ctrl 不要松开，会显示光标所在的类信息摘要 Ctrl + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 （必备） Ctrl + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 （必备） Ctrl + 前方向键 等效于鼠标滚轮向前效果 （必备） Ctrl + 后方向键 等效于鼠标滚轮向后效果 （必备） Alt 快捷键 介绍 Alt + ` 显示版本控制常用操作菜单弹出层 （必备） Alt + Q 弹出一个提示，显示当前类的声明 / 上下文信息 Alt + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 （必备） Alt + F2 对于前面页面，显示各类浏览器打开目标选择弹出层 Alt + F3 选中文本，逐个往下查找相同文本，并高亮显示 Alt + F7 查找光标所在的方法 / 变量 / 类被调用的地方 Alt + F8 在 Debug 的状态下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果 Alt + Home 定位 / 显示到当前文件的 Navigation Bar Alt + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同 （必备） Alt + Insert 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 （必备） Alt + 左方向键 切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 （必备） Alt + 右方向键 按切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 （必备） Alt + 前方向键 当前光标跳转到当前文件的前一个方法名位置 （必备） Alt + 后方向键 当前光标跳转到当前文件的后一个方法名位置 （必备） Alt + 1,2,3…9 显示对应数值的选项卡，其中 1 是 Project 用得最多 （必备） Shift 快捷键 介绍 Shift + F1 如果有外部文档可以连接外部文档 Shift + F2 跳转到上一个高亮错误 或 警告位置 Shift + F3 在查找模式下，查找匹配上一个 Shift + F4 对当前打开的文件，使用新Windows窗口打开，旧窗口保留 Shift + F6 对文件 / 文件夹 重命名 Shift + F7 在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法 Shift + F8 在 Debug 模式下，跳出，表现出来的效果跟 F9 一样 Shift + F9 等效于点击工具栏的 Debug 按钮 Shift + F10 等效于点击工具栏的 Run 按钮 Shift + F11 弹出书签显示层 （必备） Shift + Tab 取消缩进 （必备） Shift + ESC 隐藏当前 或 最后一个激活的工具窗口 Shift + End 选中光标到当前行尾位置 Shift + Home 选中光标到当前行头位置 Shift + Enter 开始新一行。光标所在行下空出一行，光标定位到新行位置 （必备） Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 （必备） Shift + 滚轮前后滚动 当前文件的横向滚动轴滚动 （必备） Ctrl + Alt 快捷键 介绍 Ctrl + Alt + L 格式化代码，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + O 优化导入的类，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + I 光标所在行 或 选中部分进行自动代码缩进，有点类似格式化 Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 （必备） Ctrl + Alt + J 弹出模板选择窗口，将选定的代码加入动态模板中 Ctrl + Alt + H 调用层次 Ctrl + Alt + B 在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 Ctrl + Alt + C 重构-快速提取常量 Ctrl + Alt + F 重构-快速提取成员变量 Ctrl + Alt + V 重构-快速提取变量 Ctrl + Alt + Y 同步、刷新 Ctrl + Alt + S 打开 IntelliJ IDEA 系统设置 （必备） Ctrl + Alt + F7 显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来 Ctrl + Alt + F11 切换全屏模式 Ctrl + Alt + Enter 光标所在行上空出一行，光标定位到新行 （必备） Ctrl + Alt + Home 弹出跟当前文件有关联的文件弹出层 Ctrl + Alt + Space 类名自动完成 Ctrl + Alt + 左方向键 退回到上一个操作的地方 （必备） Ctrl + Alt + 右方向键 前进到上一个操作的地方 （必备） Ctrl + Alt + 前方向键 在查找模式下，跳到上个查找的文件 Ctrl + Alt + 后方向键 在查找模式下，跳到下个查找的文件 Ctrl + Alt + 右括号（]） 在打开多个项目的情况下，切换下一个项目窗口 Ctrl + Alt + 左括号（[） 在打开多个项目的情况下，切换上一个项目窗口 Ctrl + Shift 快捷键 介绍 Ctrl + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 （必备） Ctrl + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 （必备） Ctrl + Shift + J 自动将下一行合并到当前行末尾 （必备） Ctrl + Shift + Z 取消撤销 （必备） Ctrl + Shift + W 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 （必备） Ctrl + Shift + N 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 （必备） Ctrl + Shift + U 对选中的代码进行大 / 小写轮流转换 （必备） Ctrl + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 （必备） Ctrl + Shift + C 复制当前文件磁盘路径到剪贴板 （必备） Ctrl + Shift + V 弹出缓存的最近拷贝的内容管理器弹出层 Ctrl + Shift + E 显示最近修改的文件列表的弹出层 Ctrl + Shift + H 显示方法层次结构 Ctrl + Shift + B 跳转到类型声明处 （必备） Ctrl + Shift + I 快速查看光标所在的方法 或 类的定义 Ctrl + Shift + A 查找动作 / 设置 Ctrl + Shift + / 代码块注释 （必备） Ctrl + Shift + [ 选中从光标所在位置到它的顶部中括号位置 （必备） Ctrl + Shift + ] 选中从光标所在位置到它的底部中括号位置 （必备） Ctrl + Shift + + 展开所有代码 （必备） Ctrl + Shift + - 折叠所有代码 （必备） Ctrl + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失 （必备） Ctrl + Shift + F8 在 Debug 模式下，指定断点进入条件 Ctrl + Shift + F9 编译选中的文件 / 包 / Module Ctrl + Shift + F12 编辑器最大化 （必备） Ctrl + Shift + Space 智能代码提示 Ctrl + Shift + Enter 自动结束代码，行末自动添加分号 （必备） Ctrl + Shift + Backspace 退回到上次修改的地方 （必备） Ctrl + Shift + 1,2,3…9 快速添加指定数值的书签 （必备） Ctrl + Shift + 左键单击 把光标放在某个类变量上，按此快捷键可以直接定位到该类中 （必备） Ctrl + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句 （必备） Ctrl + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句 （必备） Ctrl + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 （必备） Ctrl + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 （必备） Alt + Shift 快捷键 介绍 Alt + Shift + N 选择 / 添加 task （必备） Alt + Shift + F 显示添加到收藏夹弹出层 / 添加到收藏夹 Alt + Shift + C 查看最近操作项目的变化情况列表 Alt + Shift + I 查看项目当前文件 Alt + Shift + F7 在 Debug 模式下，下一步，进入当前方法体内，如果方法体还有方法，则会进入该内嵌的方法中，依此循环进入 Alt + Shift + F9 弹出 Debug 的可选择菜单 Alt + Shift + F10 弹出 Run 的可选择菜单 Alt + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 （必备） Alt + Shift + 前方向键 移动光标所在行向上移动 （必备） Alt + Shift + 后方向键 移动光标所在行向下移动 （必备） Ctrl + Shift + Alt 快捷键 介绍 Ctrl + Shift + Alt + V 无格式黏贴 （必备） Ctrl + Shift + Alt + N 前往指定的变量 / 方法 Ctrl + Shift + Alt + S 打开当前项目设置 （必备） Ctrl + Shift + Alt + C 复制参考信息 其他 快捷键 介绍 F2 跳转到下一个高亮错误 或 警告位置 （必备） F3 在查找模式下，定位到下一个匹配处 F4 编辑源 （必备） F7 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 F8 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F9 在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上 F11 添加书签 （必备） F12 回到前一个工具窗口 （必备） Tab 缩进 （必备） ESC 从工具窗口进入代码文件窗口 （必备） 连按两次Shift 弹出 Search Everywhere 弹出层]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch安装中文分词插件ik]]></title>
    <url>%2F2019%2F08%2F07%2FElasticsearch%E5%AE%89%E8%A3%85%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Elasticsearch自带standard分词只能把汉语分割成一个个字，而不能分词、分段，这就是我们需要分析器ik的地方了。 安装结果:http:`//{ip}:9200/_analyze?analyzer=standard&amp;pretty=true&amp;text=sojson中华人民共和国` 安装步骤访问浏览器（虚拟机IP:9200）查看你elasticsearch的版本号 一、下载ik的相应版本 查看版本和下载链接点击这里 这里提供5.0.0的ES及以前的版本对应的ik版本 二、下载的方式 我这里的ES是2.3.5，对应的ik版本是1.9.5 在版本里选择1.9.5，点击 【Download ZIP】右键选择 – 复制链接地址 wget https://github.com/medcl/elasticsearch-analysis-ik/archive/v1.9.5.zip 三、解包（如果没有unzip命令的使用 yum install zip unzip * 命令安装） unzip v1.9.5.zip 四、 打包 因为是java的源码，需要用maven打包 进入解压后的目录elasticsearch-analysis-ik-1.10.1里面，输入下面命令进行打包 cd elasticsearch-analysis-ik-1.9.5/ mvn clean package （注：如果没有mvn的可以直接使用 yum install java* 进行安装，把ES的环境也一起配置好） 五、配置 1、打包后，在当前目录下有target目录，进去，有一个releases目录，把里面的zip包复制到你安装ES目录下的plugins目录下的ik目录（ik目录需要手动添加） 查找ES插件路径可以使用命令whereis elasticsearch ES插件默认安装路径是：/usr/share/elasticsearch/plugins/ mkdir -p /usr/share/elasticsearch/plugins/ik cd target/releases/ mv elasticsearch-analysis-ik-1.9.5.zip /usr/share/elasticsearch/plugins/ik ; “复制代码”) 2、使用unzip命令解包，并把zip包删除了 12345cd /usr/share/elasticsearch/plugins/unzip elasticsearch-analysis-ik-1.9.5.ziprm -rf elasticsearch-analysis-ik-1.9.5.zip 六、测试 重启ES服务，查看ES的状态为（Active: active (running)）即可。 systemctl restart elasticsearch systemctl status elasticsearch 如果需要具体测试的话，可以在官网git的下面介绍有（点击查看），简单的方法可以使用下面命令在浏览器访问确认 1http://（虚拟机ip）:9200**/_analyze?analyzer=ik&amp;pretty=true&amp;text=helloworld,中华人民共和国&quot;]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker常用命令]]></title>
    <url>%2F2019%2F08%2F07%2FDocker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[镜像命令123456789101112131415161718查看本机的镜像,可通过该方法查看到镜像id等信息.docker images 获取镜像 name：镜像名 [:tag]：版本，默认为最新的（也就是会自己加上一个参数:latest）docker pull [options] name[:tag]删除镜像,需要删除其下所有容器docker rmi &lt;镜像id&gt;运行镜像,构建出一个容器. -d表示后台运行. docker run -d image -p 8080:80 进行端口映射，将nginx的80端口映射到主机的8080端口上，也就是别人访问8080，可以访问到自己的80查看目前正在运行的容器docker ps查看所有容器docker ps -a 容器命令12345678910111213141516171819202122232425262728293031323334重要:xx表示不同的命令如，pull、run等。可以查看该命令的帮助，所有参数docker xx --help停止容器docker stop &lt;容器id&gt;删除容器docker rm &lt;容器id&gt;启动一个运行(run)过的容器docker start &lt;容器id&gt;在运行的容器中执行命令 docker exec [options] container command [arg...]例如: docker exec -it &lt;容器id&gt; bash可以进入一个容器，和虚拟机中一样。也就是容器内部挂载目录:将宿主机的文件共享给容器docker run -d --name=test -v /opt/test:/usr/databases docker-test test是容器的名字，需唯一；-v表示创建一个数据卷并挂载到容器里，示例表示把宿主机的/opt/test目录挂载到容器的/usr/databases目录下；docker-test是镜像的名字查看容器当前信息,可在该命令的 Mounts信息中,找到挂载目录信息docker inspect &lt;容器id&gt;运行容器-d表示后台运行 -p表示设置端口映射， jpress是镜像名docker run -d -p 8888:8080 jpress运行mysql镜像docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -e MYSQL_DATABASE=xxx images(镜像名)]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7.5使用NGINX配置https证书]]></title>
    <url>%2F2019%2F08%2F07%2FCentos7.5%E9%85%8D%E7%BD%AEHTTPS%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[1. 下载安装NGINX2. 修改配置文件（nginx一般安装在/etc/nginx下,配置文件一般会有两个，一个是/etc/nginx/nginx.conf 另一个是/etc/nginx/config.d/default.conf,nginx.conf中包含了default.conf）,通常我们通过修改default.conf1vim /etc/nginx/config.d/defualt.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#负载均衡配置upstream webservers_api &#123; #weigth ip_hash; server 127.0.0.1:8086 max_fails=1 fail_timeout=10s; #server 127.0.0.1:8081 max_fails=1 fail_timeout=3600s;&#125;server &#123; listen 443; server_name localhost; ssl on; ssl_certificate /usr/local/TencentCloud/httpsCert/www.baidu.com.pem; ssl_certificate_key /usr/local/TencentCloud/httpsCert/www.baidu.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; access_log /usr/local/web/nginxLogs; #静态文件 location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; root /usr/local/web/dist; index index.html index.htm; try_files $uri $uri/ @router; &#125; #下载文件时把下载文件放在该目录下 location ~* \.(exe|apk|zip)$ &#123; root /usr/local/web/download; &#125; location @router &#123; rewrite ^.*$ /index.html last; &#125; location /hlwyy/api/ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://webservers_api; #跳转到api的负载均衡服务器 &#125;&#125;server &#123; listen 80; server_name www.nilaie.com nilaie.com; #多个域名以空格隔开（替换为自己的域名） rewrite ^(.*)$ https://$host$1 permanent; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; rewrite ^(.*)$ https://$&#123;server_name&#125;$1 permanent;&#125;]]></content>
      <categories>
        <category>LINUX</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装Mysql]]></title>
    <url>%2F2019%2F08%2F07%2FDocker%E5%AE%89%E8%A3%85Mysql%2F</url>
    <content type="text"><![CDATA[方法一、docker pull mysql1runoob@runoob:/mysql$ docker search mysql 2. 获取 docker pull mysql:5.6等待下载完成后，我们就可以在本地镜像列表里查到REPOSITORY为mysql,标签为5.7的镜像。 12[root@localhost ~]# docker images| grep mysqlmysql 5.7 a1aa4f76fab9 2 days ago 373MB 方法二、通过 Dockerfile构建1.首先创建目录mysql,用于存放后面的相关东西。 runoob@runoob:~$ mkdir -p ~/mysql/data ~/mysql/logs ~/mysql/conf data目录将映射为mysql容器配置的数据文件存放路径logs目录将映射为mysql容器的日志目录conf目录里的配置文件将映射为mysql容器的配置文件 2.进入创建的mysql目录，创建Dockerfile文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657FROM debian:jessie # add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get added RUN groupadd -r mysql &amp;&amp; useradd -r -g mysql mysql # add gosu for easy step-down from root ENV GOSU_VERSION 1.7 RUN set -x \ &amp;&amp; apt-get update &amp;&amp; apt-get install -y --no-install-recommends ca-certificates wget &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture)&quot; \ &amp;&amp; wget -O /usr/local/bin/gosu.asc &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture).asc&quot; \ &amp;&amp; export GNUPGHOME=&quot;$(mktemp -d)&quot; \ &amp;&amp; gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4 \ &amp;&amp; gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu \ &amp;&amp; rm -r &quot;$GNUPGHOME&quot; /usr/local/bin/gosu.asc \ &amp;&amp; chmod +x /usr/local/bin/gosu \ &amp;&amp; gosu nobody true \ &amp;&amp; apt-get purge -y --auto-remove ca-certificates wgetRUN mkdir /docker-entrypoint-initdb.d# FATAL ERROR: please install the following Perl modules before executing /usr/local/mysql/scripts/mysql_install_db:# File::Basename# File::Copy# Sys::Hostname# Data::DumperRUN apt-get update &amp;&amp; apt-get install -y perl pwgen --no-install-recommends &amp;&amp; rm -rf /var/lib/apt/lists/*# gpg: key 5072E1F5: public key &quot;MySQL Release Engineering &lt;mysql-build@oss.oracle.com&gt;&quot; importedRUN apt-key adv --keyserver ha.pool.sks-keyservers.net --recv-keys A4A9406876FCBD3C456770C88C718D3B5072E1F5ENV MYSQL_MAJOR 5.6ENV MYSQL_VERSION 5.6.31-1debian8RUN echo &quot;deb http://repo.mysql.com/apt/debian/ jessie mysql-$&#123;MYSQL_MAJOR&#125;&quot; &gt; /etc/apt/sources.list.d/mysql.list# the &quot;/var/lib/mysql&quot; stuff here is because the mysql-server postinst doesn&apos;t have an explicit way to disable the mysql_install_db codepath besides having a database already &quot;configured&quot; (ie, stuff in /var/lib/mysql/mysql)# also, we set debconf keys to make APT a little quieterRUN &#123; \ echo mysql-community-server mysql-community-server/data-dir select &apos;&apos;; \ echo mysql-community-server mysql-community-server/root-pass password &apos;&apos;; \ echo mysql-community-server mysql-community-server/re-root-pass password &apos;&apos;; \ echo mysql-community-server mysql-community-server/remove-test-db select false; \ &#125; | debconf-set-selections \ &amp;&amp; apt-get update &amp;&amp; apt-get install -y mysql-server=&quot;$&#123;MYSQL_VERSION&#125;&quot; &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; rm -rf /var/lib/mysql &amp;&amp; mkdir -p /var/lib/mysql /var/run/mysqld \ &amp;&amp; chown -R mysql:mysql /var/lib/mysql /var/run/mysqld \# ensure that /var/run/mysqld (used for socket and lock files) is writable regardless of the UID our mysqld instance ends up having at runtime &amp;&amp; chmod 777 /var/run/mysqld# comment out a few problematic configuration values# don&apos;t reverse lookup hostnames, they are usually another containerRUN sed -Ei &apos;s/^(bind-address|log)/#&amp;/&apos; /etc/mysql/my.cnf \ &amp;&amp; echo &apos;skip-host-cache\nskip-name-resolve&apos; | awk &apos;&#123; print &#125; $1 == &quot;[mysqld]&quot; &amp;&amp; c == 0 &#123; c = 1; system(&quot;cat&quot;) &#125;&apos; /etc/mysql/my.cnf &gt; /tmp/my.cnf \ &amp;&amp; mv /tmp/my.cnf /etc/mysql/my.cnfVOLUME /var/lib/mysqlCOPY docker-entrypoint.sh /usr/local/bin/RUN ln -s usr/local/bin/docker-entrypoint.sh /entrypoint.sh # backwards compatENTRYPOINT [&quot;docker-entrypoint.sh&quot;]EXPOSE 3306CMD [&quot;mysqld&quot;] 通过Dockerfile创建一个镜像，替换成你自己的名字 runoob@runoob:~/mysql$ docker build -t mysql . 创建完成后，我们可以在本地的镜像列表里查找到刚刚创建的镜像 12docker images |grep mysqlmysql 5.6 2c0964ec182a 3 weeks ago 329 MB 使用mysql镜像运行容器12docker run -p 13306:3306 --name mymysql -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 命令说明： –name mymysql：定义容器的别名。 -p 3306:3306：将容器的 3306 端口映射到主机的 13306 端口。 -v $PWD/conf:/etc/mysql/conf.d：将主机当前目录下的 conf/my.cnf 挂载到容器的 /etc/mysql/my.cnf。 -v $PWD/logs:/logs：将主机当前目录下的 logs 目录挂载到容器的 /logs。 -v $PWD/data:/var/lib/mysql ：将主机当前目录下的data目录挂载到容器的 /var/lib/mysql 。 -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。 查看容器启动情况[root@localhost ~]# docker ps 重启docker中的Mysql(可以通过CONTAINER ID 或者容器的Name)1[root@localhost ~]# docker restart mymysql 或者1[root@localhost ~]# docker restart f75c3467f92e]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7.5安装RocketMq]]></title>
    <url>%2F2019%2F08%2F07%2FCentos7.5%E5%AE%89%E8%A3%85RocketMq%2F</url>
    <content type="text"><![CDATA[1、下载apache最新rocketmq二进制压缩文件下载地址：https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.2.0/rocketmq-all-4.2.0-bin-release.zip 下载命令：wget https://mirrors.tuna.tsinghua.edu.cn/apache/rocketmq/4.2.0/rocketmq-all-4.2.0-bin-release.zip 2、解压安装解压命令：unzip -d /dirname rocketmq-all-4.2.0-bin-release.zip 3、环境变量nameserver环境变量：vi /etc/profile 添加：export NAMESRV_ADDR=127.0.0.1:9876 4、启动bin目录，启动nameserver和broker： nohup sh mqnamesrv &gt;mqname.log &amp; nohup sh mqbroker -n localhost:9876 &gt;mqbroker.log &amp; 查看进程：jps 启动broker时会卡顿，因为虚拟机内存和broker配置内存跟不上。 设置：给虚拟机预留1g的内存，这样启动时不太会卡：虚拟机设2g，nameserver和broker共用1g 5、启动失败查看启动日志：cat nohup.out 启动失败： Native memory allocation (malloc) failed to allocate 8589934592 bytes for committing reserved memory. 因为nameserver和broker的默认配置内存超过虚拟机的内存，需根据宿主机配置调整虚拟机内存，并调整nameserver和broker的默认内存配置。 bin目录： vi runserver.sh vi runbroker.sh 参考文章 [https://www.jianshu.com/p/04a98ba770a4][https://blog.csdn.net/paincupid/article/details/81333138]]]></content>
      <categories>
        <category>RocketMq</category>
      </categories>
      <tags>
        <tag>RocketMq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7.5增加swap分区]]></title>
    <url>%2F2019%2F08%2F07%2FCentos7.5%E8%B0%83%E6%95%B4swap%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[先用free -m查看一下swap的大小 1.添加swap分区 使用dd命令创建/home/swap这么一个分区文件。文件的大小是2048000 个block，一般情况下1个block为1K，所以这里空间是2G。 1dd if=/dev/zero of=/var/swapfile bs=1024 count=2048000 //添加交换文件并设置其大小为2G 2.执行完毕，对交换文件格式化并转换为swap分区： mkswap /var/swapfile 3.挂载并激活分区： 1swapon /var/swapfile 4 赋权限 1chmod -R 0600 /var/swapfile 现在再用free -m命令查看一下内存和swap分区大小，就发现增加了2G的空间了。 注意当计算机重启了以后，发现swap还是原来那么大，新的swap没有自动启动，还要手动启动。那我们需要修改/etc/fstab文件 5.设置开机自动挂载该分区：vi /etc/fstab在fstab文件末尾追加如下内容后:wq!保存即可： 1/var/swapfile swap swap defaults 0 0]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>swap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7.5安装Elasticsearch2.3.5]]></title>
    <url>%2F2019%2F08%2F07%2FCentos7.5%E5%AE%89%E8%A3%85Elasticsearch%2F</url>
    <content type="text"><![CDATA[Elasticsearch是一个基于Lucene的搜索服务器,它需要依赖于java环境,所以需要先安装了JDK 安装方法一（下载rpm包方式） 1.百度elasticsearch,点击官网网址 2.点击Downloads，选择past releases 3.找到2.3.5的版本，（由于elasticsearch更新太快，插件更新进度跟不上，2.3.5的版本插件最齐全） 4.右键点击RPM选择 – 复制连接地址 5.在根目录下载rmp包 wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/rpm/elasticsearch/2.3.5/elasticsearch-2.3.5.rpm 6.执行下面的命令,安装完成后按照提示操作,即可 rpm -ivh elasticsearch-2.3.5.rpm 7.启动并查看安装状态 123systemctl start elasticsearchsystemctl status elasticsearch 8.本地查看版本信息 curl http://127.0.0.1:9200 9.查找elasticsearch 安装路径与配置路径，并且配置 whereis elasticsearch vim /etc/elasticsearch/elasticsearch.yml 修改： 这样就可以在window系统用浏览器通过访问虚拟机的ip:port 保存退出后重启elasticsearch systemctl restart elasticsearch 在浏览器访问虚拟机ip:9200 安装方法二 (yum方式安装)一、ES的yum安装配置 由于ES不在yum的本地源，所以我们需要添加ES的yum配置。 1、下载并安装ES的yum公钥 rpm --import https:`//packages.elastic.co/GPG-KEY-elasticsearch` 2、配置ES的yum源vim /etc/yum.repos.d/elasticsearch.repo 输入下面的内容：123456[elasticsearch-2.x]name=Elasticsearch repository for 2.x packagesbaseurl=http://packages.elastic.co/elasticsearch/2.x/centosgpgcheck=1gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearchenabled=1 二、yum安装ES 1、更新yum的缓存yum makecache 2、安装ESyum install elasticsearch 三、测试ES 1、配置和启动ES服务器进程 /sbin/chkconfig --add elasticsearch systemctl start elasticsearch 2、查看状态 systemctl status elasticsearch 3、运行测试curl -X GET localhost:9200 返回的json结果如下：123456789101112&#123; &quot;name&quot; : &quot;Live Wire&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;2.3.5&quot;, &quot;build_hash&quot; : &quot;90f439ff60a3c0f497f91663701e64ccd01edbb4&quot;, &quot;build_timestamp&quot; : &quot;2016-07-27T10:36:52Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;5.5.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 四、通过IP访问ES的配置（同方法一配置方法一样）1、打开/etc/elasticsearch/elasticsearch.ymlvim /etc/elasticsearch/elasticsearch.yml network.host-&gt; 把后面改为0.0.0.0或者虚拟机ip地址， http.port-&gt; 去掉注释 这样就可以在window系统用浏览器通过访问虚拟机的ip:port 安装中文分词插件参考https://www.cnblogs.com/shifu204/p/6374234.html]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F08%2F07%2FCentos7%20%E5%AE%89%E8%A3%85Docker%2F</url>
    <content type="text"><![CDATA[Centos7 安装Docker安装参考：https://blog.csdn.net/u010046908/article/details/79553227安装最新版本 https://blog.csdn.net/kongxx/article/details/78361048 阿里云镜像仓库地址： https://dev.aliyun.com/search.html 常用命令docker pull centos 拉取centosdocker images 查看本地所有镜像docker run hello-world 运行实例 docker run -i -t -v /root/sortware/:/mnt/sortware/ 75835a67d134 /bin/bash 退出exit 关闭docker stop mycentos 重启docker start mycentos 重启后,在mycentos再打开/bin/bashdocker exec -ti mycentos /bin/bash 1、初步安装和启动dockeryum update -yyum -y install dockersystemctl start docker 2、设置镜像vi /etc/docker/daemon.json { “registry-mirrors”: [“https://aj2rgad5.mirror.aliyuncs.com&quot;]} 3、重启dockersystemctl daemon-reloadsystemctl restart docker.service 4、测试docker是否正常安装和运行docker run hello-world 5、查看结果Hello from Docker!]]></content>
  </entry>
  <entry>
    <title><![CDATA[Cenos7.5环境搭建目录]]></title>
    <url>%2F2019%2F08%2F07%2FCenos7.5%E6%90%AD%E5%BB%BA%E7%94%9F%E6%88%90%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[1.Linux 设置服务器时区:1、安装ntp服务软件包：yum install ntp2、将ntp设置为缺省启动：systemctl enable ntpd3、修改启动参数，增加-g -x参数，允许ntp服务在系统时间误差较大时也能正常工作：vi /etc/sysconfig/ntpd4、启动ntp服务：/bin/systemctl restart ntpd5、将系统时区改为上海时间（即CST时区）：ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime6、输入date命令查看时间是否正确 2. 搭建FTP(vsftp)https://blog.csdn.net/zy517863543/article/details/80028351 遇到的问题： 1.安装成功后, Filezilla可以正常上传下载文件，但是java程序中使用Ftp工具类无法上传成功？ 解决方法： 程序中需要指定使用被动模式 3.搭建SFTP参考博客(https://blog.csdn.net/fenglailea/article/details/78631760) 4.下载并安装redishttps://www.cnblogs.com/zuidongfeng/p/8032505.html 遇到的问题: https://blog.csdn.net/jexhen/article/details/76098622复制到etc下的配置/etc/redis/6379.conf (自动启动时生效的是这个,两个配置文件做好同步) 5.搭建java环境https://blog.csdn.net/sizhezhongnian/article/details/81142976JAVA根目录: /usr/java/jdk1.8 6.搭建并配置NGINX服务器安装第三方yum源 安装下载wgetyum install wget 下载wget http://www.atomicorp.com/installers/atomic 安装sh ./atomic 更新yum源yum check-update 开始安装nginx 删除系统自带的软件包yum remove httpd php 安装nginxyum install -y nginx 设置nginx开机启动chkconfig nginx on 启动nginxservice nginx start 7. 搭建TOMCAT及参数优化安装tomcat,并配置多tomcathttps://blog.csdn.net/w410589502/article/details/77988912https://blog.csdn.net/weixin_41004350/article/details/78492500 8. 安装MYSQL(5.7) 数据库参考博客: https://www.cnblogs.com/freely/p/8087885.html 添加用户,授权用户 https://www.cnblogs.com/xujishou/p/6306765.html 配置文件 vim /etc/my.cnf注意更改端口号为13306 需要加入防火墙 Mysql授权失败错误问题 执行命令: grant all on . to hospital@’%’ 授权只能访问某库 grant all privileges on ky.* to hospital@’%’ identified by ‘Fv6jl#cxhd3&amp;0vx8’ 执行完要刷新权限 flush privileges; ERROR 1819 (HY000): Your password does not satisfy the current policy requirements https://www.cnblogs.com/ivictor/p/5142809.html 9. 防火墙配置及管理CentOS7使用firewalld打开关闭防火墙与端口 1、firewalld的基本使用12345启动服务 systemctl start firewalld关闭服务 systemctl stop firewalld查看状态 systemctl status firewalld 开机禁用 systemctl disable firewalld开机启用 systemctl enable firewalld 2.systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。 123456789启动一个服务：systemctl start firewalld.service关闭一个服务：systemctl stop firewalld.service重启一个服务：systemctl restart firewalld.service显示一个服务的状态：systemctl status firewalld.service在开机时启用一个服务：systemctl enable firewalld.service在开机时禁用一个服务：systemctl disable firewalld.service查看服务是否开机启动：systemctl is-enabled firewalld.service查看已启动的服务列表：systemctl list-unit-files|grep enabled查看启动失败的服务列表：systemctl --failed 3.配置firewalld-cmd12345678910查看版本： firewall-cmd --version查看帮助： firewall-cmd --help显示状态： firewall-cmd --state查看所有打开的端口： firewall-cmd --zone=public --list-ports更新防火墙规则： firewall-cmd --reload查看区域信息: firewall-cmd --get-active-zones查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0拒绝所有包：firewall-cmd --panic-on取消拒绝状态： firewall-cmd --panic-off查看是否拒绝： firewall-cmd --query-panic 4.怎样在防火墙中开启一个端口呢？ 添加端口 12 firewall-cmd --zone=public --add-port=80/tcp --permanent （--permanent永久生效，没有此参数重启后失效） 重新载入 firewall-cmd --reload 查看 firewall-cmd --zone= public --query-port=80/tcp 删除 firewall-cmd --zone= public --remove-port=80/tcp --permanent ###10. centos7 常用命令 1、Apache 服务管理命令启动：1234systemctl start httpd 启动systemctl stop httpd 停止systemctl restart httpd 重启systemctl status httpd 状态 2、MySQL 服务管理命令启动：1234systemctl start mysqld关闭：systemctl stop mysqld重启：systemctl restart mysqld状态：systemctl status mysqld 3、FTP 服务管理命令启动：1234systemctl start vsftpd 启动systemctl stop vsftpd 停止systemctl restart vsftpd 重启systemctl status vsftpd 状态 Nginx服务管理命令启动123systemctl start nginx 启动systemctl status nginx 查看状态systemctl stop nginx 停止]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[studyEnglish]]></title>
    <url>%2F2018%2F04%2F12%2FstudyEnglish%2F</url>
    <content type="text"><![CDATA[2018-05-05The only wealth in this world is children. More than all the money and power on earth.孩子们是世上唯一的财富，远胜于金钱和权力。 2018-05-04As you make your bed, so you must lie on it.这是你自作自受 2018-05-03If you wanna change the world, start off by making your bed.改变世界，从整理床铺开始 解析 start off （by） doing XX 从…开始;从…着手 start/get off on the wrong/right foot 一开始就很顺利/不顺 make your bed 整理床铺 2018-04-29The more we try to understand one another, the more exceptional each of us will be 解析 try to do 尽力做没事，有难度，能不能做好，不确定 try doing 尝试做某事，不涉及难度，试试看做完结果能否更好 one another=each other彼此 2018-04-28Things happen the way they do. We may not know why at the time, but there must alway be a reason. 万物皆有准则 2018-04-26People make mistake.-It’s why they put rubbers on the ends of pencil. 人都会犯错，也因此铅笔头上会有橡皮 解析 make mistake犯错误 出岔子 rubbers橡皮 put rubbers on the ends of pencil在铅笔尾部放上橡皮 2018-04-25I want you to gain the intelligence of spending time wisely, because while you’re killing time, time is killing you. 你消磨时间的时候，时间也在耗你 解析 gain intelligence of doing 获得做。。。的智慧 spend your time wisely 明智的利用时间 kill time 打发时间，消遣 2018-04-20Every once in a while, you will find some who’s iridescent,and when you do,nothing will ever compare. 总有一天，你会遇到那个彩虹绚丽的/无与伦比的人 解析 irideacent彩虹色的，变色的 nothing will compare没有什么能比得上 every once in a while偶尔，每隔一阵子 2018-04-13Life is a roller coaster,but I am tall enough to ride你不可能凡是都成功。但是任何成功的愿景中都必须承认失败的存在 解析 * roller coaster 过山车 * roller 滚筒 * coaster 船 2018-04-12You can not be successful at everything.So any vision of success has to admit what it is losing out on.你不可能凡是都成功。但是任何成功的愿景中都必须承认失败的存在 解析 * be successful at 在什么事情上成功 * vision of success成功的愿景 * lose out 失败、失去 2018-04-11Sometimes we act, not for ourselves, but because we believe plainly and simply it is the right thing to do.有时我们行动不是为了自己，而是单纯相信那是正确的事 解析 * myself 复数-&gt; ourselves * act (for) (为了)行动/代表 * believe plainly and simply 单纯的相信 * plainly明显地、简单地、朴素地]]></content>
      <categories>
        <category>english</category>
      </categories>
      <tags>
        <tag>跟着lassie学英语</tag>
      </tags>
  </entry>
</search>
